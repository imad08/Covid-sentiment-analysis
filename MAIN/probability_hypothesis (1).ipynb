{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "probability_hypothesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC7z_2dy_5ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a35eafff-e5a1-489c-b0c8-55ea5175ba26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP_XCBVw4c0Z",
        "outputId": "65a8fd96-e4d4-4e7f-bece-69d24a81fb19"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# type d => <enter> => stopwords => <enter>\n",
        "# type d => <enter> => wordnet => <enter> => q"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx0Psjnw9FBi",
        "outputId": "07804e5a-cd7c-4978-ebe2-226c8bdd2fad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('gdrive/MyDrive/researchProjectIME/new_df_marked.csv')[:401]\n",
        "df.drop_duplicates(subset=['tweet'])\n",
        "print('Out of {} tweets, {} are demanding vaccines and {} are not.'.format(len(df), len(df[df['Imad'] == 1]), len(df[df['Imad'] == 0])))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 401 tweets, 146 are demanding vaccines and 255 are not.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIRri1ck_jCZ"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean(txt: str):\n",
        "  txt = re.sub(r'@[A-Za-z0-9_]+', '', txt)\n",
        "  txt = re.sub(r'&amp', 'and', txt)\n",
        "  txt = re.sub('#', '', txt)\n",
        "  txt = re.sub(r'RT', '', txt)\n",
        "  txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt)\n",
        "  txt = ''.join([c for c in txt if c not in string.punctuation])\n",
        "  txt = txt.lower()\n",
        "  #for c in string.punctuation:\n",
        "  #  txt = re.sub(c, '', txt)\n",
        "  return txt\n",
        "\n",
        "def tokenize(text: str):\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8cQJEPKB79g"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def removeStopwords(tokens):\n",
        "  ret = [token for token in tokens if token not in stopwords]\n",
        "  ret = [token for token in tokens if token != '']\n",
        "  return ret"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bco9NFbnClwD"
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(tokens):\n",
        "  ret = [wn.lemmatize(token) for token in tokens]\n",
        "  return ret\n",
        "\n",
        "def finalClean(txt: str):\n",
        "  return lemmatize(removeStopwords(tokenize(clean(txt))))\n",
        "\n",
        "dDict = open('gdrive/MyDrive/researchProjectIME/data_dictionary_prob.csv', 'r').read().split('\\n')\n",
        "df['Count'] = 0\n",
        "def dictPercent(words):\n",
        "  s = []\n",
        "  for word in words:\n",
        "    if word in dDict:\n",
        "      s += [word]\n",
        "  listToStr = ' '.join([str(elem) for elem in s])\n",
        "  return listToStr\n",
        "df['final'] = df['tweet'].apply(finalClean)\n",
        "df['Dict'] = df['final'].apply(dictPercent)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "lgrNJEVvlqd-",
        "outputId": "83f68fb6-bb64-434a-9bc6-a51b37cceb5f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nlikes.1</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Achint</th>\n",
              "      <th>Imad</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Count</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>22/03/2021 9:55</td>\n",
              "      <td>@ANI @LtGovDelhi @ArvindKejriwal Those stil un...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[those, stil, unable, to, go, to, vaccination,...</td>\n",
              "      <td>call do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>23/03/2021 23:14</td>\n",
              "      <td>#Mumbai: Actor Sanjay Dutt received his first ...</td>\n",
              "      <td>en</td>\n",
              "      <td>['mumbai']</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[mumbai, actor, sanjay, dutt, received, his, f...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>03/03/2021 15:28</td>\n",
              "      <td>It will be difficult for differently abled per...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[it, will, be, difficult, for, differently, ab...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31/03/2021 0:31</td>\n",
              "      <td>@priyankac19 But don’t you feel on door to doo...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[but, don, t, you, feel, on, door, to, door, v...</td>\n",
              "      <td>feel need reduce can should</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>16/01/2021 9:59</td>\n",
              "      <td>Dense fog at Max Hospital Saket, a COVID vacci...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[dense, fog, at, max, hospital, saket, a, covi...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                         Dict\n",
              "0           0  ...                      call do\n",
              "1           1  ...                             \n",
              "2           2  ...                             \n",
              "3           3  ...  feel need reduce can should\n",
              "4           4  ...                             \n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMDBoyNfiRb-"
      },
      "source": [
        "df.to_csv('new_df_marked_cleaned.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "18hj6E35EULv",
        "outputId": "9d9e7098-4322-494e-8b13-a70253108c38"
      },
      "source": [
        "!pip list | grep scikit-learn || pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import accuracy_score as acs\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X = df[['tweet']]\n",
        "y = df['Achint']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "countVect = CountVectorizer(analyzer=finalClean)\n",
        "count_fit_train = countVect.fit_transform(X_train['tweet'])\n",
        "count_fit_test = countVect.transform(X_test['tweet'])\n",
        "\n",
        "X_train_vec = pd.DataFrame(count_fit_train.toarray())\n",
        "X_test_vec = pd.DataFrame(count_fit_test.toarray())\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
        "rf_model = rf.fit(X_train_vec, y_train)\n",
        "y_pred = rf_model.predict(X_test_vec)\n",
        "\n",
        "precision, recall, fscore, train_support = score(y_test, y_pred, pos_label=1, average='binary')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "class_label = [\"no_demand\", \"demand\"]\n",
        "df_cm = pd.DataFrame(cm, index=class_label,columns=class_label)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scikit-learn                  0.22.2.post1       \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McDeQYtgkasb",
        "outputId": "569a9a49-6f1d-407a-8e9a-949327ca3723"
      },
      "source": [
        "print(precision, recall, fscore, acs(y_test, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333 0.7567567567567568 0.835820895522388 0.8910891089108911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "yUi42xxqokoB",
        "outputId": "2e7fd7de-6066-4ec9-83cc-3d36767c5bf6"
      },
      "source": [
        "df_pred.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Tweet_tokenized</th>\n",
              "      <th>Tweet_nonstop</th>\n",
              "      <th>Tweet_stemmed</th>\n",
              "      <th>Tweet_lemmatized</th>\n",
              "      <th>time</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "      <th>PredictDicted</th>\n",
              "      <th>total</th>\n",
              "      <th>predicted</th>\n",
              "      <th>sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Allowing private hospitals to vaccinate will b...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>824588996462338048</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'to', 'va...</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'vaccinat...</td>\n",
              "      <td>['allow', 'privat', 'hospit', 'vaccin', 'boost...</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'vaccinate...</td>\n",
              "      <td>02:24:40</td>\n",
              "      <td>8</td>\n",
              "      <td>[allowing, private, hospital, to, vaccinate, w...</td>\n",
              "      <td>allowing</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>238</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Of the mm vaccination shots that have been adm...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>502080208</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shots', 't...</td>\n",
              "      <td>['mm', 'vaccination', 'shots', 'administered',...</td>\n",
              "      <td>['mm', 'vaccin', 'shot', 'administ', 'worldwid...</td>\n",
              "      <td>['mm', 'vaccination', 'shot', 'administered', ...</td>\n",
              "      <td>02:53:37</td>\n",
              "      <td>7</td>\n",
              "      <td>[of, the, mm, vaccination, shot, that, have, b...</td>\n",
              "      <td>have do</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>237</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>[in, a, boost, for, covid, battle, pfizer, vac...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>[in, a, boost, for, covid, battle, pfizer, vac...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>ANI गर्मी बढ़ गई है पृथ्वी पर    GlobalWarming...</td>\n",
              "      <td>en</td>\n",
              "      <td>['globalwarming', 'primeminister']</td>\n",
              "      <td>88895954</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>03:15:07</td>\n",
              "      <td>8</td>\n",
              "      <td>[ani, गर, म, बढ, गई, ह, प, थ, व, पर, globalwar...</td>\n",
              "      <td>come can</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1        date  ... total predicted sum\n",
              "0           0           184  2021-02-25  ...     0       0.0   8\n",
              "1           1           238  2021-02-25  ...     0       0.0   7\n",
              "2           2           237  2021-02-25  ...     0       0.0  19\n",
              "3           3            33  2021-02-25  ...     0       0.0  31\n",
              "4           4            27  2021-02-25  ...     0       0.0  39\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXnZH4NdrOQL"
      },
      "source": [
        "df_pred = pd.read_csv('gdrive/MyDrive/researchProjectIME/event_modi.csv')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-NCqboNnJev"
      },
      "source": [
        "df_pred['PredictDict'] = 0"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xDz5Uf2AXJ"
      },
      "source": [
        "for word in df_pred['Tweet_lemmatized']:\n",
        "  if word in dDict:\n",
        "    print(word)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atUYz-mbmRDH"
      },
      "source": [
        "df_pred['final'] = df_pred['tweet'].apply(finalClean)\n",
        "df_pred['Dict'] = df_pred['final'].apply(dictPercent)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0cVc8gqr6Lu"
      },
      "source": [
        "cnt = []\n",
        "for i in range(574):\n",
        "  cnt.append(len(df_pred['Dict'][i]))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrtqqFqithEU"
      },
      "source": [
        "df_pred['PredictDict'] = cnt"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkiNtQH4sqy-",
        "outputId": "220bcfdc-f32d-4bbf-a54c-42e41f80c3e5"
      },
      "source": [
        "df_pred['PredictDict'].value_counts()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     244\n",
              "4      77\n",
              "3      46\n",
              "6      32\n",
              "7      27\n",
              "14     13\n",
              "11     12\n",
              "12     12\n",
              "13     12\n",
              "8      11\n",
              "5      10\n",
              "9       9\n",
              "10      9\n",
              "15      8\n",
              "22      7\n",
              "26      7\n",
              "17      6\n",
              "18      6\n",
              "28      5\n",
              "16      3\n",
              "21      3\n",
              "23      3\n",
              "19      2\n",
              "20      2\n",
              "24      2\n",
              "27      2\n",
              "2       2\n",
              "32      1\n",
              "38      1\n",
              "Name: PredictDict, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfi17ppmrBvf",
        "outputId": "484964ae-7481-40b1-c031-78326d0cc349"
      },
      "source": [
        "df_pred['PredictDict'].value_counts()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     244\n",
              "4      77\n",
              "3      46\n",
              "6      32\n",
              "7      27\n",
              "14     13\n",
              "11     12\n",
              "12     12\n",
              "13     12\n",
              "8      11\n",
              "5      10\n",
              "9       9\n",
              "10      9\n",
              "15      8\n",
              "22      7\n",
              "26      7\n",
              "17      6\n",
              "18      6\n",
              "28      5\n",
              "16      3\n",
              "21      3\n",
              "23      3\n",
              "19      2\n",
              "20      2\n",
              "24      2\n",
              "27      2\n",
              "2       2\n",
              "32      1\n",
              "38      1\n",
              "Name: PredictDict, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lpgGPODt5eJ"
      },
      "source": [
        "df_pred['PredictDicted'] = 0"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqES62H7o8nW",
        "outputId": "28e2505a-0241-4190-f8c2-fec5ab0c6e39"
      },
      "source": [
        "for i in range(574):\n",
        "  if df_pred['PredictDict'][i] > 5:\n",
        "    df_pred['PredictDicted'][i] = 1\n",
        "  else:\n",
        "    df_pred['PredictDicted'][i] = 0"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CHCjhj5ypv-D",
        "outputId": "f9e0ebbc-9d52-421a-a26a-287e2688a623"
      },
      "source": [
        "df_pred.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Tweet_tokenized</th>\n",
              "      <th>Tweet_nonstop</th>\n",
              "      <th>Tweet_stemmed</th>\n",
              "      <th>Tweet_lemmatized</th>\n",
              "      <th>time</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "      <th>PredictDicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Allowing private hospitals to vaccinate will b...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>824588996462338048</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'to', 'va...</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'vaccinat...</td>\n",
              "      <td>['allow', 'privat', 'hospit', 'vaccin', 'boost...</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'vaccinate...</td>\n",
              "      <td>02:24:40</td>\n",
              "      <td>8</td>\n",
              "      <td>[allowing, private, hospital, to, vaccinate, w...</td>\n",
              "      <td>allowing</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>238</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Of the mm vaccination shots that have been adm...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>502080208</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shots', 't...</td>\n",
              "      <td>['mm', 'vaccination', 'shots', 'administered',...</td>\n",
              "      <td>['mm', 'vaccin', 'shot', 'administ', 'worldwid...</td>\n",
              "      <td>['mm', 'vaccination', 'shot', 'administered', ...</td>\n",
              "      <td>02:53:37</td>\n",
              "      <td>7</td>\n",
              "      <td>[of, the, mm, vaccination, shot, that, have, b...</td>\n",
              "      <td>have do</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>237</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>[in, a, boost, for, covid, battle, pfizer, vac...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>[in, a, boost, for, covid, battle, pfizer, vac...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>ANI गर्मी बढ़ गई है पृथ्वी पर    GlobalWarming...</td>\n",
              "      <td>en</td>\n",
              "      <td>['globalwarming', 'primeminister']</td>\n",
              "      <td>88895954</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>03:15:07</td>\n",
              "      <td>8</td>\n",
              "      <td>[ani, गर, म, बढ, गई, ह, प, थ, व, पर, globalwar...</td>\n",
              "      <td>come can</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ...          Dict PredictDicted\n",
              "0           0           184  ...      allowing             1\n",
              "1           1           238  ...       have do             1\n",
              "2           2           237  ...  found should             1\n",
              "3           3            33  ...  found should             1\n",
              "4           4            27  ...      come can             1\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yijWbTbH1yts"
      },
      "source": [
        "X_to_pred = pd.DataFrame(countVect.transform(df_pred['tweet']).toarray())\n",
        "y_to_pred = rf_model.predict(X_to_pred)\n",
        "df_pred['predicted'] = y_to_pred"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSi1Mz2EpKC8"
      },
      "source": [
        "\n",
        "df_pred.to_csv('predict_1.csv')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L6qF6hzu1nn"
      },
      "source": [
        "df_pred['sum'] = 0"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_svVZwdusJA",
        "outputId": "0804ffa4-980c-4d6f-f684-8e8519b5995a"
      },
      "source": [
        "sum = 0\n",
        "df_pred['sum'][0] = df_pred['PredictDict'][0]\n",
        "for i in range(1,574):\n",
        "  if df_pred['date'][i] == df_pred['date'][i-1]:\n",
        "    sum += df_pred['PredictDict'][i]\n",
        "    df_pred['sum'][i] = sum\n",
        "  else:\n",
        "    sum = 0\n",
        "    df_pred['sum'][i] = df_pred['PredictDict'][i]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ekUraipPLN",
        "outputId": "ac29d790-1c9c-42cc-a28f-99fdd406a0d4"
      },
      "source": [
        "df_pred['total'] = 0\n",
        "for i in range(574):\n",
        "  if df_pred['PredictDict'][i] == 1 or df_pred['predicted'][i] == 1:\n",
        "    df_pred['total'][i] = 1"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW0rMPnuvZep",
        "outputId": "e3f8daf0-0a2b-4080-f762-c8326929c6d7"
      },
      "source": [
        "df_pred['sum'][44]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4I2h9ktvilP"
      },
      "source": [
        "df_pred.to_csv('predicted.csv')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "W1h57QLBv02S",
        "outputId": "3bcd2a27-971d-494e-fc96-0d844761d1ba"
      },
      "source": [
        "df_pred.describe()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>user_id</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>PredictDicted</th>\n",
              "      <th>predicted</th>\n",
              "      <th>sum</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>5.740000e+02</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>574.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>286.500000</td>\n",
              "      <td>75.851916</td>\n",
              "      <td>4.405972e+17</td>\n",
              "      <td>13.306620</td>\n",
              "      <td>0.484321</td>\n",
              "      <td>3.003484</td>\n",
              "      <td>5.209059</td>\n",
              "      <td>0.339721</td>\n",
              "      <td>0.078397</td>\n",
              "      <td>249.689895</td>\n",
              "      <td>0.078397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>165.843802</td>\n",
              "      <td>66.638516</td>\n",
              "      <td>5.546146e+17</td>\n",
              "      <td>110.180813</td>\n",
              "      <td>2.468425</td>\n",
              "      <td>14.274301</td>\n",
              "      <td>6.824772</td>\n",
              "      <td>0.474028</td>\n",
              "      <td>0.269030</td>\n",
              "      <td>217.376700</td>\n",
              "      <td>0.269030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.804482e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>143.250000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>2.855255e+08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>286.500000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>2.535595e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>182.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>429.750000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>1.017738e+18</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>333.750000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>573.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>1.367497e+18</td>\n",
              "      <td>2344.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>246.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>924.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1  ...         sum       total\n",
              "count  574.000000    574.000000  ...  574.000000  574.000000\n",
              "mean   286.500000     75.851916  ...  249.689895    0.078397\n",
              "std    165.843802     66.638516  ...  217.376700    0.269030\n",
              "min      0.000000      0.000000  ...    0.000000    0.000000\n",
              "25%    143.250000     19.000000  ...   89.250000    0.000000\n",
              "50%    286.500000     53.000000  ...  182.500000    0.000000\n",
              "75%    429.750000    127.000000  ...  333.750000    0.000000\n",
              "max    573.000000    238.000000  ...  924.000000    1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA7Vpq5O_gq7"
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIALnZVpzVpx"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_meevFGzbkL"
      },
      "source": [
        "df = pd.read_csv('predicted.csv')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "It3XpBYx3r7q",
        "outputId": "9f319224-6b4d-4dad-a2b0-ad5b2fcfa4b1"
      },
      "source": [
        "df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Tweet_tokenized</th>\n",
              "      <th>Tweet_nonstop</th>\n",
              "      <th>Tweet_stemmed</th>\n",
              "      <th>Tweet_lemmatized</th>\n",
              "      <th>time</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "      <th>PredictDicted</th>\n",
              "      <th>predicted</th>\n",
              "      <th>sum</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Allowing private hospitals to vaccinate will b...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>824588996462338048</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'to', 'va...</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'vaccinat...</td>\n",
              "      <td>['allow', 'privat', 'hospit', 'vaccin', 'boost...</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'vaccinate...</td>\n",
              "      <td>02:24:40</td>\n",
              "      <td>8</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'to', 'vac...</td>\n",
              "      <td>allowing</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>238</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Of the mm vaccination shots that have been adm...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>502080208</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shots', 't...</td>\n",
              "      <td>['mm', 'vaccination', 'shots', 'administered',...</td>\n",
              "      <td>['mm', 'vaccin', 'shot', 'administ', 'worldwid...</td>\n",
              "      <td>['mm', 'vaccination', 'shot', 'administered', ...</td>\n",
              "      <td>02:53:37</td>\n",
              "      <td>7</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shot', 'th...</td>\n",
              "      <td>have do</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>237</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>ANI गर्मी बढ़ गई है पृथ्वी पर    GlobalWarming...</td>\n",
              "      <td>en</td>\n",
              "      <td>['globalwarming', 'primeminister']</td>\n",
              "      <td>88895954</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>03:15:07</td>\n",
              "      <td>8</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>come can</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>569</td>\n",
              "      <td>569</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>Sebs testing helmet reminds me of this</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>102964560</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['sebs', 'testing', 'helmet', 'reminds', 'me',...</td>\n",
              "      <td>['sebs', 'testing', 'helmet', 'reminds']</td>\n",
              "      <td>['seb', 'test', 'helmet', 'remind']</td>\n",
              "      <td>['seb', 'testing', 'helmet', 'reminds']</td>\n",
              "      <td>19:36:28</td>\n",
              "      <td>0</td>\n",
              "      <td>['seb', 'testing', 'helmet', 'reminds', 'me', ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>259</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>570</td>\n",
              "      <td>570</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>Countries that have administered the most COVI...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19']</td>\n",
              "      <td>1353438953903370241</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['countries', 'that', 'have', 'administered', ...</td>\n",
              "      <td>['countries', 'administered', 'covid', 'vaccin...</td>\n",
              "      <td>['countri', 'administ', 'covid', 'vaccin', 'do...</td>\n",
              "      <td>['country', 'administered', 'covid', 'vaccine'...</td>\n",
              "      <td>19:49:21</td>\n",
              "      <td>4</td>\n",
              "      <td>['country', 'that', 'have', 'administered', 't...</td>\n",
              "      <td>have</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>571</td>\n",
              "      <td>571</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>Big jump in vaccination drive nearly  lakh dos...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covidvaccine']</td>\n",
              "      <td>1353438953903370241</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['big', 'jump', 'in', 'vaccination', 'drive', ...</td>\n",
              "      <td>['big', 'jump', 'vaccination', 'drive', 'nearl...</td>\n",
              "      <td>['big', 'jump', 'vaccin', 'drive', 'nearli', '...</td>\n",
              "      <td>['big', 'jump', 'vaccination', 'drive', 'nearl...</td>\n",
              "      <td>20:32:14</td>\n",
              "      <td>0</td>\n",
              "      <td>['big', 'jump', 'in', 'vaccination', 'drive', ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>572</td>\n",
              "      <td>572</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>Big jump in vaccination drive nearly  lakh dos...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covidvaccine']</td>\n",
              "      <td>1353438953903370241</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['big', 'jump', 'in', 'vaccination', 'drive', ...</td>\n",
              "      <td>['big', 'jump', 'vaccination', 'drive', 'nearl...</td>\n",
              "      <td>['big', 'jump', 'vaccin', 'drive', 'nearli', '...</td>\n",
              "      <td>['big', 'jump', 'vaccination', 'drive', 'nearl...</td>\n",
              "      <td>20:32:14</td>\n",
              "      <td>0</td>\n",
              "      <td>['big', 'jump', 'in', 'vaccination', 'drive', ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>573</td>\n",
              "      <td>573</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>Covaxin Trials What  Interim Efficacy Means  h...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>1734702540</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['covaxin', 'trials', 'what', 'interim', 'effi...</td>\n",
              "      <td>['covaxin', 'trials', 'interim', 'efficacy', '...</td>\n",
              "      <td>['covaxin', 'trial', 'interim', 'efficaci', 'm...</td>\n",
              "      <td>['covaxin', 'trial', 'interim', 'efficacy', 'm...</td>\n",
              "      <td>23:47:56</td>\n",
              "      <td>4</td>\n",
              "      <td>['covaxin', 'trial', 'what', 'interim', 'effic...</td>\n",
              "      <td>mean</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>267</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>574 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ... predicted  sum total\n",
              "0             0             0             184  ...       0.0    8     0\n",
              "1             1             1             238  ...       1.0    7     1\n",
              "2             2             2             237  ...       0.0   19     0\n",
              "3             3             3              33  ...       0.0   31     0\n",
              "4             4             4              27  ...       0.0   39     0\n",
              "..          ...           ...             ...  ...       ...  ...   ...\n",
              "569         569           569               0  ...       0.0  259     0\n",
              "570         570           570               1  ...       0.0  263     0\n",
              "571         571           571               0  ...       0.0  263     0\n",
              "572         572           572               0  ...       0.0  263     0\n",
              "573         573           573               0  ...       0.0  267     0\n",
              "\n",
              "[574 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q_5nCRL4ZO2",
        "outputId": "d6a5ca07-9be2-46b3-f65f-dd11001871e4"
      },
      "source": [
        "for i in range(574):\n",
        "  df['total'][i] = df['predicted'][i] or df['PredictDicted'][i] "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "HxHLSwT75FhF",
        "outputId": "4013f4e8-1dcb-4fea-dfa2-0b3ee3c9b564"
      },
      "source": [
        "df.head(100)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Tweet_tokenized</th>\n",
              "      <th>Tweet_nonstop</th>\n",
              "      <th>Tweet_stemmed</th>\n",
              "      <th>Tweet_lemmatized</th>\n",
              "      <th>time</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "      <th>PredictDicted</th>\n",
              "      <th>predicted</th>\n",
              "      <th>sum</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Allowing private hospitals to vaccinate will b...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>824588996462338048</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'to', 'va...</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'vaccinat...</td>\n",
              "      <td>['allow', 'privat', 'hospit', 'vaccin', 'boost...</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'vaccinate...</td>\n",
              "      <td>02:24:40</td>\n",
              "      <td>8</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'to', 'vac...</td>\n",
              "      <td>allowing</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>238</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Of the mm vaccination shots that have been adm...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>502080208</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shots', 't...</td>\n",
              "      <td>['mm', 'vaccination', 'shots', 'administered',...</td>\n",
              "      <td>['mm', 'vaccin', 'shot', 'administ', 'worldwid...</td>\n",
              "      <td>['mm', 'vaccination', 'shot', 'administered', ...</td>\n",
              "      <td>02:53:37</td>\n",
              "      <td>7</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shot', 'th...</td>\n",
              "      <td>have do</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>237</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>ANI गर्मी बढ़ गई है पृथ्वी पर    GlobalWarming...</td>\n",
              "      <td>en</td>\n",
              "      <td>['globalwarming', 'primeminister']</td>\n",
              "      <td>88895954</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>03:15:07</td>\n",
              "      <td>8</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>come can</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>149</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Patient   Baby Anshika  Hospital   AIIMS New D...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>31753018</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>['patient', 'babi', 'anshika', 'hospit', 'aiim...</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>13:19:46</td>\n",
              "      <td>6</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>please</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Centre fixes COVID vaccine price at Rs  per dose</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>122317608</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['centre', 'fixes', 'covid', 'vaccine', 'price...</td>\n",
              "      <td>['centre', 'fixes', 'covid', 'vaccine', 'price...</td>\n",
              "      <td>['centr', 'fix', 'covid', 'vaccin', 'price', '...</td>\n",
              "      <td>['centre', 'fix', 'covid', 'vaccine', 'price',...</td>\n",
              "      <td>14:05:32</td>\n",
              "      <td>0</td>\n",
              "      <td>['centre', 'fix', 'covid', 'vaccine', 'price',...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>ColRana ANI Col ur in the army then its free d...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>77789658</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'in', 'the', '...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'army', 'free'...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'armi', 'free'...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'army', 'free'...</td>\n",
              "      <td>14:50:18</td>\n",
              "      <td>4</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'in', 'the', '...</td>\n",
              "      <td>know</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>19</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Huge role and responsibility for all hospitals...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>1134423305790795776</td>\n",
              "      <td>False</td>\n",
              "      <td>86</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>['huge', 'role', 'and', 'responsibility', 'for...</td>\n",
              "      <td>['huge', 'role', 'responsibility', 'hospitals'...</td>\n",
              "      <td>['huge', 'role', 'respons', 'hospit', 'invit',...</td>\n",
              "      <td>['huge', 'role', 'responsibility', 'hospital',...</td>\n",
              "      <td>14:52:01</td>\n",
              "      <td>10</td>\n",
              "      <td>['huge', 'role', 'and', 'responsibility', 'for...</td>\n",
              "      <td>invite can</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>15</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>DR HARSH VARDHAN JI MINISTER FOR HEALTH AND FW...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>914795008376553472</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minist', 'he...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>15:08:12</td>\n",
              "      <td>4</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>help</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ... predicted  sum total\n",
              "0            0             0             184  ...       0.0    8     1\n",
              "1            1             1             238  ...       1.0    7     1\n",
              "2            2             2             237  ...       0.0   19     1\n",
              "3            3             3              33  ...       0.0   31     1\n",
              "4            4             4              27  ...       0.0   39     1\n",
              "..         ...           ...             ...  ...       ...  ...   ...\n",
              "95          95            95             149  ...       0.0   89     1\n",
              "96          96            96              58  ...       0.0   89     0\n",
              "97          97            97              57  ...       0.0   93     0\n",
              "98          98            98              19  ...       0.0  103     1\n",
              "99          99            99              15  ...       0.0  107     0\n",
              "\n",
              "[100 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZrg9p3z3spl"
      },
      "source": [
        "no_tweet = []\n",
        "d_tweet = []\n",
        "prob =  []\n",
        "nt = 1\n",
        "dt = 0\n",
        "for i in range(1,574):\n",
        "  if(df['date'][i]!=df['date'][i-1]):\n",
        "    no_tweet.append(nt)\n",
        "    d_tweet.append(dt)\n",
        "    temp = dt/nt\n",
        "    prob.append(temp)\n",
        "    dt = 0\n",
        "    nt = 0\n",
        "  else:\n",
        "    nt = nt + 1\n",
        "    if(df['total'][i]==1):\n",
        "      dt = dt + 1\n",
        "\n",
        "no_tweet.append(nt)\n",
        "d_tweet.append(dt)\n",
        "temp = dt/nt\n",
        "prob.append(temp)\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnQyH33u7uCX",
        "outputId": "ea66ab9f-1e38-4450-c131-f9677006e492"
      },
      "source": [
        "prob\n",
        "#no_tweet\n",
        "#test"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4883720930232558,\n",
              " 0.5882352941176471,\n",
              " 0.38461538461538464,\n",
              " 0.375,\n",
              " 0.3125,\n",
              " 0.3942307692307692,\n",
              " 0.26153846153846155,\n",
              " 0.18309859154929578]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbvNgq4S8WEX",
        "outputId": "ef244619-8c7b-41b0-89c8-4d7da52922cd"
      },
      "source": [
        "df['date'].value_counts()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2021-03-01    193\n",
              "2021-03-02    105\n",
              "2021-03-04     72\n",
              "2021-03-03     66\n",
              "2021-02-25     43\n",
              "2021-02-26     35\n",
              "2021-02-28     33\n",
              "2021-02-27     27\n",
              "Name: date, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDhOGprn8ttT",
        "outputId": "51c1afe2-3e4a-4546-9870-307ccd384657"
      },
      "source": [
        "prob[7]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18309859154929578"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBhFHHqO-w3s",
        "outputId": "1da60508-7aa8-4f87-bbc5-9327b119d293"
      },
      "source": [
        "df['dayprob'] = 0.0\n",
        "df['dayprob'][0] = prob[0]\n",
        "i = 0\n",
        "for j in range(1,574):\n",
        "    if(df['date'][j]!=df['date'][j-1]):\n",
        "      i = i + 1\n",
        "      df['dayprob'][j] = prob[i]\n",
        "    else:\n",
        "      df['dayprob'][j] = prob[i]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "yVewj3eX_qih",
        "outputId": "74222152-9512-4657-8e4f-81e1456cf4a1"
      },
      "source": [
        "df.head(100)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>Tweet_tokenized</th>\n",
              "      <th>Tweet_nonstop</th>\n",
              "      <th>Tweet_stemmed</th>\n",
              "      <th>Tweet_lemmatized</th>\n",
              "      <th>time</th>\n",
              "      <th>PredictDict</th>\n",
              "      <th>final</th>\n",
              "      <th>Dict</th>\n",
              "      <th>PredictDicted</th>\n",
              "      <th>predicted</th>\n",
              "      <th>sum</th>\n",
              "      <th>total</th>\n",
              "      <th>dayprob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Allowing private hospitals to vaccinate will b...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>824588996462338048</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'to', 'va...</td>\n",
              "      <td>['allowing', 'private', 'hospitals', 'vaccinat...</td>\n",
              "      <td>['allow', 'privat', 'hospit', 'vaccin', 'boost...</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'vaccinate...</td>\n",
              "      <td>02:24:40</td>\n",
              "      <td>8</td>\n",
              "      <td>['allowing', 'private', 'hospital', 'to', 'vac...</td>\n",
              "      <td>allowing</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>238</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>Of the mm vaccination shots that have been adm...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>502080208</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shots', 't...</td>\n",
              "      <td>['mm', 'vaccination', 'shots', 'administered',...</td>\n",
              "      <td>['mm', 'vaccin', 'shot', 'administ', 'worldwid...</td>\n",
              "      <td>['mm', 'vaccination', 'shot', 'administered', ...</td>\n",
              "      <td>02:53:37</td>\n",
              "      <td>7</td>\n",
              "      <td>['of', 'the', 'mm', 'vaccination', 'shot', 'th...</td>\n",
              "      <td>have do</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>237</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>In a boost for COVID battle Pfizer vaccine fou...</td>\n",
              "      <td>en</td>\n",
              "      <td>['covid19vaccine']</td>\n",
              "      <td>3187924020</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>['boost', 'covid', 'battl', 'pfizer', 'vaccin'...</td>\n",
              "      <td>['boost', 'covid', 'battle', 'pfizer', 'vaccin...</td>\n",
              "      <td>03:02:07</td>\n",
              "      <td>12</td>\n",
              "      <td>['in', 'a', 'boost', 'for', 'covid', 'battle',...</td>\n",
              "      <td>found should</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>2021-02-25</td>\n",
              "      <td>ANI गर्मी बढ़ गई है पृथ्वी पर    GlobalWarming...</td>\n",
              "      <td>en</td>\n",
              "      <td>['globalwarming', 'primeminister']</td>\n",
              "      <td>88895954</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>03:15:07</td>\n",
              "      <td>8</td>\n",
              "      <td>['ani', 'गर', 'म', 'बढ', 'गई', 'ह', 'प', 'थ', ...</td>\n",
              "      <td>come can</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.488372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>149</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Patient   Baby Anshika  Hospital   AIIMS New D...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>31753018</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>['patient', 'babi', 'anshika', 'hospit', 'aiim...</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>13:19:46</td>\n",
              "      <td>6</td>\n",
              "      <td>['patient', 'baby', 'anshika', 'hospital', 'ai...</td>\n",
              "      <td>please</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>58</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Centre fixes COVID vaccine price at Rs  per dose</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>122317608</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['centre', 'fixes', 'covid', 'vaccine', 'price...</td>\n",
              "      <td>['centre', 'fixes', 'covid', 'vaccine', 'price...</td>\n",
              "      <td>['centr', 'fix', 'covid', 'vaccin', 'price', '...</td>\n",
              "      <td>['centre', 'fix', 'covid', 'vaccine', 'price',...</td>\n",
              "      <td>14:05:32</td>\n",
              "      <td>0</td>\n",
              "      <td>['centre', 'fix', 'covid', 'vaccine', 'price',...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>57</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>ColRana ANI Col ur in the army then its free d...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>77789658</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'in', 'the', '...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'army', 'free'...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'armi', 'free'...</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'army', 'free'...</td>\n",
              "      <td>14:50:18</td>\n",
              "      <td>4</td>\n",
              "      <td>['colrana', 'ani', 'col', 'ur', 'in', 'the', '...</td>\n",
              "      <td>know</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>19</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>Huge role and responsibility for all hospitals...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>1134423305790795776</td>\n",
              "      <td>False</td>\n",
              "      <td>86</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>['huge', 'role', 'and', 'responsibility', 'for...</td>\n",
              "      <td>['huge', 'role', 'responsibility', 'hospitals'...</td>\n",
              "      <td>['huge', 'role', 'respons', 'hospit', 'invit',...</td>\n",
              "      <td>['huge', 'role', 'responsibility', 'hospital',...</td>\n",
              "      <td>14:52:01</td>\n",
              "      <td>10</td>\n",
              "      <td>['huge', 'role', 'and', 'responsibility', 'for...</td>\n",
              "      <td>invite can</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>15</td>\n",
              "      <td>2021-02-27</td>\n",
              "      <td>DR HARSH VARDHAN JI MINISTER FOR HEALTH AND FW...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>914795008376553472</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minist', 'he...</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>15:08:12</td>\n",
              "      <td>4</td>\n",
              "      <td>['dr', 'harsh', 'vardhan', 'ji', 'minister', '...</td>\n",
              "      <td>help</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>0.384615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ...  sum total   dayprob\n",
              "0            0             0             184  ...    8     1  0.488372\n",
              "1            1             1             238  ...    7     1  0.488372\n",
              "2            2             2             237  ...   19     1  0.488372\n",
              "3            3             3              33  ...   31     1  0.488372\n",
              "4            4             4              27  ...   39     1  0.488372\n",
              "..         ...           ...             ...  ...  ...   ...       ...\n",
              "95          95            95             149  ...   89     1  0.384615\n",
              "96          96            96              58  ...   89     0  0.384615\n",
              "97          97            97              57  ...   93     0  0.384615\n",
              "98          98            98              19  ...  103     1  0.384615\n",
              "99          99            99              15  ...  107     0  0.384615\n",
              "\n",
              "[100 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEC9PT9oAKQ2"
      },
      "source": [
        "no_iterations = 100 \n",
        "X = df[['sum','nlikes','nreplies','nretweets']]\n",
        "Y = df [['dayprob']]\n",
        "def weightInitialization(n_features):\n",
        "    w = np.zeros((1,n_features))\n",
        "    b = 0\n",
        "    return w,b\n",
        "def sigmoid_activation(result):\n",
        "    final_result = 1/(1+np.exp(-result))\n",
        "    return final_result\n",
        "\n",
        "def model_optimize(w, b, X, Y):\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    #Prediction\n",
        "    final_result = sigmoid_activation(np.dot(w,X.T)+b)\n",
        "    Y_T = Y.T\n",
        "    cost = (-1/m)*(np.sum((Y_T*np.log(final_result)) + ((1-Y_T)*(np.log(1-final_result)))))\n",
        "    #\n",
        "    \n",
        "    #Gradient calculation\n",
        "    dw = (1/m)*(np.dot(X.T, (final_result-Y.T).T))\n",
        "    db = (1/m)*(np.sum(final_result-Y.T))\n",
        "    \n",
        "    grads = {\"dw\": dw, \"db\": db}\n",
        "    \n",
        "    return grads, cost\n",
        "def model_predict(w, b, X, Y, learning_rate, no_iterations):\n",
        "    costs = []\n",
        "    for i in range(no_iterations):\n",
        "        #\n",
        "        grads, cost = model_optimize(w,b,X,Y)\n",
        "        #\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        #weight update\n",
        "        w = w - (learning_rate * (dw.T))\n",
        "        b = b - (learning_rate * db)\n",
        "        #\n",
        "        \n",
        "        if (i % 100 == 0):\n",
        "            costs.append(cost)\n",
        "            print(\"Cost after %i iteration is %f\" %(i, cost))\n",
        "    \n",
        "    #final parameters\n",
        "    coeff = {\"w\": w, \"b\": b}\n",
        "    gradient = {\"dw\": dw, \"db\": db}\n",
        "    \n",
        "    return coeff, gradient, costs\n",
        "def predict(final_pred, m):\n",
        "    y_pred = np.zeros((1,m))\n",
        "    for i in range(final_pred.shape[1]):\n",
        "        if final_pred[0][i] > 0.5:\n",
        "            y_pred[0][i] = 1\n",
        "    return y_pred\n",
        "\n",
        "no_iterations = 100 \n",
        "X = df[['sum','nlikes','nreplies','nretweets']]\n",
        "Y = df [['dayprob']]\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCb32WvWGzvP"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HOkvcdbG8zm"
      },
      "source": [
        "X = df[['sum','nlikes','nreplies','nretweets']][140:]\n",
        "Y = df [['dayprob']][140:]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2 ,  random_state = 2)\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRlxjlrlG9Pw"
      },
      "source": [
        "X_t=X_train.to_numpy()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pg0pAz-G9Ro"
      },
      "source": [
        "Y_t = Y_train.to_numpy()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTpM03PuG9TA"
      },
      "source": [
        "X_te = X_test.to_numpy()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-6AYLAtG9Uv"
      },
      "source": [
        "Y_te = Y_test.to_numpy()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHH9GODpJAfP"
      },
      "source": [
        "sc = MinMaxScaler()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uVmDsGCG9YH"
      },
      "source": [
        "X_t = (X_t - X_t.min(axis=0))/(X_t.max()-X_t.min(axis=0))\n",
        "X_te= (X_te - X_te.min())/(X_te.max()-X_te.min())\n",
        "#Y_t = sc.fit_transform(Y_t)\n",
        "X_t =  torch.from_numpy(X_t.astype(np.float32))\n",
        "Y_t =  torch.from_numpy(Y_t.astype(np.float32))\n",
        "Y_te =  torch.from_numpy(Y_te.astype(np.float32))\n",
        "X_te =  torch.from_numpy(X_te.astype(np.float32))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjXHdBD1CS3t",
        "outputId": "4cd11922-a1d7-4446-ae4d-9da6f16ac464"
      },
      "source": [
        "Y_t = Y_t.view(Y_t.shape[0],1)\n",
        "Y_te = Y_te.view(Y_te.shape[0],1)\n",
        "X_t"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0486, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0567, 0.0004, 0.0000, 0.0004],\n",
              "        [0.0427, 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.1254, 0.0013, 0.0000, 0.0000],\n",
              "        [0.0346, 0.1660, 0.0026, 0.0205],\n",
              "        [0.3375, 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbDqCin-LbwK"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = nn.Linear(n_features, 1)\n",
        "  def forward(self,x):\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    return y_pred"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l52PvTLMKz-",
        "outputId": "ab1b0f1f-1fd8-4e5f-819e-da1ac3de5c0d"
      },
      "source": [
        "n_features = 4\n",
        "model =  LogisticRegression(n_features)\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs):\n",
        "  y_pred = model(X_t)\n",
        "  loss = criterion(y_pred,Y_t)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  w,b =  model.parameters()\n",
        "  print(f'epoch : {epoch+1} loss : {loss.item()} weight {w}')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 1 loss : 0.6492639183998108 weight Parameter containing:\n",
            "tensor([[-0.4250, -0.0401, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 2 loss : 0.6490996479988098 weight Parameter containing:\n",
            "tensor([[-0.4252, -0.0401, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 3 loss : 0.6489362716674805 weight Parameter containing:\n",
            "tensor([[-0.4253, -0.0401, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 4 loss : 0.6487736105918884 weight Parameter containing:\n",
            "tensor([[-0.4254, -0.0401, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 5 loss : 0.6486117839813232 weight Parameter containing:\n",
            "tensor([[-0.4256, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 6 loss : 0.6484506726264954 weight Parameter containing:\n",
            "tensor([[-0.4257, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 7 loss : 0.6482905149459839 weight Parameter containing:\n",
            "tensor([[-0.4258, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 8 loss : 0.6481310725212097 weight Parameter containing:\n",
            "tensor([[-0.4260, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 9 loss : 0.6479724049568176 weight Parameter containing:\n",
            "tensor([[-0.4261, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 10 loss : 0.6478146314620972 weight Parameter containing:\n",
            "tensor([[-0.4262, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 11 loss : 0.6476575136184692 weight Parameter containing:\n",
            "tensor([[-0.4264, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 12 loss : 0.6475012302398682 weight Parameter containing:\n",
            "tensor([[-0.4265, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 13 loss : 0.6473456621170044 weight Parameter containing:\n",
            "tensor([[-0.4266, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 14 loss : 0.6471909284591675 weight Parameter containing:\n",
            "tensor([[-0.4268, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 15 loss : 0.6470369696617126 weight Parameter containing:\n",
            "tensor([[-0.4269, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 16 loss : 0.6468837261199951 weight Parameter containing:\n",
            "tensor([[-0.4270, -0.0402, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 17 loss : 0.6467312574386597 weight Parameter containing:\n",
            "tensor([[-0.4271, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 18 loss : 0.6465795636177063 weight Parameter containing:\n",
            "tensor([[-0.4273, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 19 loss : 0.646428644657135 weight Parameter containing:\n",
            "tensor([[-0.4274, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 20 loss : 0.646278440952301 weight Parameter containing:\n",
            "tensor([[-0.4275, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 21 loss : 0.6461290121078491 weight Parameter containing:\n",
            "tensor([[-0.4277, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 22 loss : 0.6459802985191345 weight Parameter containing:\n",
            "tensor([[-0.4278, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 23 loss : 0.645832359790802 weight Parameter containing:\n",
            "tensor([[-0.4279, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 24 loss : 0.6456851363182068 weight Parameter containing:\n",
            "tensor([[-0.4280, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 25 loss : 0.6455386281013489 weight Parameter containing:\n",
            "tensor([[-0.4282, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 26 loss : 0.6453928351402283 weight Parameter containing:\n",
            "tensor([[-0.4283, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 27 loss : 0.6452478170394897 weight Parameter containing:\n",
            "tensor([[-0.4284, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 28 loss : 0.6451034545898438 weight Parameter containing:\n",
            "tensor([[-0.4285, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 29 loss : 0.6449597477912903 weight Parameter containing:\n",
            "tensor([[-0.4287, -0.0403, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 30 loss : 0.6448168754577637 weight Parameter containing:\n",
            "tensor([[-0.4288, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 31 loss : 0.6446746587753296 weight Parameter containing:\n",
            "tensor([[-0.4289, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 32 loss : 0.6445331573486328 weight Parameter containing:\n",
            "tensor([[-0.4290, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 33 loss : 0.6443923115730286 weight Parameter containing:\n",
            "tensor([[-0.4292, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 34 loss : 0.6442523002624512 weight Parameter containing:\n",
            "tensor([[-0.4293, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 35 loss : 0.6441128253936768 weight Parameter containing:\n",
            "tensor([[-0.4294, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 36 loss : 0.6439741253852844 weight Parameter containing:\n",
            "tensor([[-0.4295, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 37 loss : 0.6438360214233398 weight Parameter containing:\n",
            "tensor([[-0.4296, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 38 loss : 0.6436986923217773 weight Parameter containing:\n",
            "tensor([[-0.4298, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 39 loss : 0.6435620188713074 weight Parameter containing:\n",
            "tensor([[-0.4299, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 40 loss : 0.6434260010719299 weight Parameter containing:\n",
            "tensor([[-0.4300, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 41 loss : 0.6432906985282898 weight Parameter containing:\n",
            "tensor([[-0.4301, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 42 loss : 0.6431560516357422 weight Parameter containing:\n",
            "tensor([[-0.4302, -0.0404, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 43 loss : 0.6430220007896423 weight Parameter containing:\n",
            "tensor([[-0.4304, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 44 loss : 0.642888605594635 weight Parameter containing:\n",
            "tensor([[-0.4305, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 45 loss : 0.642755925655365 weight Parameter containing:\n",
            "tensor([[-0.4306, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 46 loss : 0.6426239609718323 weight Parameter containing:\n",
            "tensor([[-0.4307, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 47 loss : 0.6424926519393921 weight Parameter containing:\n",
            "tensor([[-0.4308, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 48 loss : 0.6423618197441101 weight Parameter containing:\n",
            "tensor([[-0.4310, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 49 loss : 0.6422317624092102 weight Parameter containing:\n",
            "tensor([[-0.4311, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 50 loss : 0.6421023607254028 weight Parameter containing:\n",
            "tensor([[-0.4312, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 51 loss : 0.6419734954833984 weight Parameter containing:\n",
            "tensor([[-0.4313, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 52 loss : 0.6418454051017761 weight Parameter containing:\n",
            "tensor([[-0.4314, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 53 loss : 0.641717791557312 weight Parameter containing:\n",
            "tensor([[-0.4315, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 54 loss : 0.6415908932685852 weight Parameter containing:\n",
            "tensor([[-0.4317, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 55 loss : 0.6414646506309509 weight Parameter containing:\n",
            "tensor([[-0.4318, -0.0405, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 56 loss : 0.6413389444351196 weight Parameter containing:\n",
            "tensor([[-0.4319, -0.0406, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 57 loss : 0.6412138938903809 weight Parameter containing:\n",
            "tensor([[-0.4320, -0.0406, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 58 loss : 0.6410894989967346 weight Parameter containing:\n",
            "tensor([[-0.4321, -0.0406, -0.3276, -0.1170]], requires_grad=True)\n",
            "epoch : 59 loss : 0.6409656405448914 weight Parameter containing:\n",
            "tensor([[-0.4322, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 60 loss : 0.6408424377441406 weight Parameter containing:\n",
            "tensor([[-0.4323, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 61 loss : 0.6407198309898376 weight Parameter containing:\n",
            "tensor([[-0.4325, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 62 loss : 0.6405978798866272 weight Parameter containing:\n",
            "tensor([[-0.4326, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 63 loss : 0.6404764652252197 weight Parameter containing:\n",
            "tensor([[-0.4327, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 64 loss : 0.64035564661026 weight Parameter containing:\n",
            "tensor([[-0.4328, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 65 loss : 0.640235424041748 weight Parameter containing:\n",
            "tensor([[-0.4329, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 66 loss : 0.6401157975196838 weight Parameter containing:\n",
            "tensor([[-0.4330, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 67 loss : 0.6399967670440674 weight Parameter containing:\n",
            "tensor([[-0.4331, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 68 loss : 0.6398783922195435 weight Parameter containing:\n",
            "tensor([[-0.4332, -0.0406, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 69 loss : 0.6397604942321777 weight Parameter containing:\n",
            "tensor([[-0.4333, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 70 loss : 0.6396431922912598 weight Parameter containing:\n",
            "tensor([[-0.4335, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 71 loss : 0.6395264267921448 weight Parameter containing:\n",
            "tensor([[-0.4336, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 72 loss : 0.6394103765487671 weight Parameter containing:\n",
            "tensor([[-0.4337, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 73 loss : 0.6392948031425476 weight Parameter containing:\n",
            "tensor([[-0.4338, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 74 loss : 0.6391797661781311 weight Parameter containing:\n",
            "tensor([[-0.4339, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 75 loss : 0.6390653252601624 weight Parameter containing:\n",
            "tensor([[-0.4340, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 76 loss : 0.6389514207839966 weight Parameter containing:\n",
            "tensor([[-0.4341, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 77 loss : 0.6388381123542786 weight Parameter containing:\n",
            "tensor([[-0.4342, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 78 loss : 0.6387253999710083 weight Parameter containing:\n",
            "tensor([[-0.4343, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 79 loss : 0.638613224029541 weight Parameter containing:\n",
            "tensor([[-0.4344, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 80 loss : 0.6385015845298767 weight Parameter containing:\n",
            "tensor([[-0.4345, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 81 loss : 0.6383904218673706 weight Parameter containing:\n",
            "tensor([[-0.4346, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 82 loss : 0.6382797956466675 weight Parameter containing:\n",
            "tensor([[-0.4348, -0.0407, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 83 loss : 0.6381698250770569 weight Parameter containing:\n",
            "tensor([[-0.4349, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 84 loss : 0.6380603909492493 weight Parameter containing:\n",
            "tensor([[-0.4350, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 85 loss : 0.6379513740539551 weight Parameter containing:\n",
            "tensor([[-0.4351, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 86 loss : 0.6378429532051086 weight Parameter containing:\n",
            "tensor([[-0.4352, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 87 loss : 0.63773512840271 weight Parameter containing:\n",
            "tensor([[-0.4353, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 88 loss : 0.6376276612281799 weight Parameter containing:\n",
            "tensor([[-0.4354, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 89 loss : 0.6375209093093872 weight Parameter containing:\n",
            "tensor([[-0.4355, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 90 loss : 0.6374146342277527 weight Parameter containing:\n",
            "tensor([[-0.4356, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 91 loss : 0.6373088359832764 weight Parameter containing:\n",
            "tensor([[-0.4357, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 92 loss : 0.637203574180603 weight Parameter containing:\n",
            "tensor([[-0.4358, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 93 loss : 0.6370987296104431 weight Parameter containing:\n",
            "tensor([[-0.4359, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 94 loss : 0.6369945406913757 weight Parameter containing:\n",
            "tensor([[-0.4360, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 95 loss : 0.6368908286094666 weight Parameter containing:\n",
            "tensor([[-0.4361, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 96 loss : 0.6367875933647156 weight Parameter containing:\n",
            "tensor([[-0.4362, -0.0408, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 97 loss : 0.636684775352478 weight Parameter containing:\n",
            "tensor([[-0.4363, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 98 loss : 0.636582612991333 weight Parameter containing:\n",
            "tensor([[-0.4364, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 99 loss : 0.6364808678627014 weight Parameter containing:\n",
            "tensor([[-0.4365, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 100 loss : 0.636379599571228 weight Parameter containing:\n",
            "tensor([[-0.4366, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 101 loss : 0.6362788677215576 weight Parameter containing:\n",
            "tensor([[-0.4367, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 102 loss : 0.6361786723136902 weight Parameter containing:\n",
            "tensor([[-0.4368, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 103 loss : 0.6360788941383362 weight Parameter containing:\n",
            "tensor([[-0.4369, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 104 loss : 0.6359797120094299 weight Parameter containing:\n",
            "tensor([[-0.4370, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 105 loss : 0.6358808875083923 weight Parameter containing:\n",
            "tensor([[-0.4371, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 106 loss : 0.6357825398445129 weight Parameter containing:\n",
            "tensor([[-0.4372, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 107 loss : 0.6356847286224365 weight Parameter containing:\n",
            "tensor([[-0.4373, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 108 loss : 0.6355873942375183 weight Parameter containing:\n",
            "tensor([[-0.4374, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 109 loss : 0.6354905962944031 weight Parameter containing:\n",
            "tensor([[-0.4375, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 110 loss : 0.6353940963745117 weight Parameter containing:\n",
            "tensor([[-0.4376, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 111 loss : 0.6352982521057129 weight Parameter containing:\n",
            "tensor([[-0.4377, -0.0409, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 112 loss : 0.6352027654647827 weight Parameter containing:\n",
            "tensor([[-0.4378, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 113 loss : 0.6351077556610107 weight Parameter containing:\n",
            "tensor([[-0.4379, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 114 loss : 0.635013222694397 weight Parameter containing:\n",
            "tensor([[-0.4380, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 115 loss : 0.6349191069602966 weight Parameter containing:\n",
            "tensor([[-0.4381, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 116 loss : 0.6348255276679993 weight Parameter containing:\n",
            "tensor([[-0.4382, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 117 loss : 0.6347323656082153 weight Parameter containing:\n",
            "tensor([[-0.4383, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 118 loss : 0.6346396207809448 weight Parameter containing:\n",
            "tensor([[-0.4384, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 119 loss : 0.6345474123954773 weight Parameter containing:\n",
            "tensor([[-0.4385, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 120 loss : 0.6344555616378784 weight Parameter containing:\n",
            "tensor([[-0.4386, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 121 loss : 0.6343641877174377 weight Parameter containing:\n",
            "tensor([[-0.4386, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 122 loss : 0.6342733502388 weight Parameter containing:\n",
            "tensor([[-0.4387, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 123 loss : 0.634182870388031 weight Parameter containing:\n",
            "tensor([[-0.4388, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 124 loss : 0.6340928077697754 weight Parameter containing:\n",
            "tensor([[-0.4389, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 125 loss : 0.634003221988678 weight Parameter containing:\n",
            "tensor([[-0.4390, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 126 loss : 0.6339139938354492 weight Parameter containing:\n",
            "tensor([[-0.4391, -0.0410, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 127 loss : 0.6338252425193787 weight Parameter containing:\n",
            "tensor([[-0.4392, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 128 loss : 0.6337370276451111 weight Parameter containing:\n",
            "tensor([[-0.4393, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 129 loss : 0.6336491107940674 weight Parameter containing:\n",
            "tensor([[-0.4394, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 130 loss : 0.6335616707801819 weight Parameter containing:\n",
            "tensor([[-0.4395, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 131 loss : 0.6334746479988098 weight Parameter containing:\n",
            "tensor([[-0.4396, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 132 loss : 0.6333880424499512 weight Parameter containing:\n",
            "tensor([[-0.4397, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 133 loss : 0.633301854133606 weight Parameter containing:\n",
            "tensor([[-0.4398, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 134 loss : 0.6332160234451294 weight Parameter containing:\n",
            "tensor([[-0.4398, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 135 loss : 0.6331307291984558 weight Parameter containing:\n",
            "tensor([[-0.4399, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 136 loss : 0.6330457925796509 weight Parameter containing:\n",
            "tensor([[-0.4400, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 137 loss : 0.6329612731933594 weight Parameter containing:\n",
            "tensor([[-0.4401, -0.0411, -0.3276, -0.1171]], requires_grad=True)\n",
            "epoch : 138 loss : 0.6328771114349365 weight Parameter containing:\n",
            "tensor([[-0.4402, -0.0411, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 139 loss : 0.6327934861183167 weight Parameter containing:\n",
            "tensor([[-0.4403, -0.0411, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 140 loss : 0.6327101588249207 weight Parameter containing:\n",
            "tensor([[-0.4404, -0.0411, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 141 loss : 0.6326273083686829 weight Parameter containing:\n",
            "tensor([[-0.4405, -0.0411, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 142 loss : 0.6325448155403137 weight Parameter containing:\n",
            "tensor([[-0.4406, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 143 loss : 0.6324626803398132 weight Parameter containing:\n",
            "tensor([[-0.4406, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 144 loss : 0.632381021976471 weight Parameter containing:\n",
            "tensor([[-0.4407, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 145 loss : 0.6322996616363525 weight Parameter containing:\n",
            "tensor([[-0.4408, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 146 loss : 0.6322187781333923 weight Parameter containing:\n",
            "tensor([[-0.4409, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 147 loss : 0.6321383118629456 weight Parameter containing:\n",
            "tensor([[-0.4410, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 148 loss : 0.6320582032203674 weight Parameter containing:\n",
            "tensor([[-0.4411, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 149 loss : 0.6319783926010132 weight Parameter containing:\n",
            "tensor([[-0.4412, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 150 loss : 0.6318990588188171 weight Parameter containing:\n",
            "tensor([[-0.4413, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 151 loss : 0.631820023059845 weight Parameter containing:\n",
            "tensor([[-0.4413, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 152 loss : 0.631741464138031 weight Parameter containing:\n",
            "tensor([[-0.4414, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 153 loss : 0.6316632628440857 weight Parameter containing:\n",
            "tensor([[-0.4415, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 154 loss : 0.6315853595733643 weight Parameter containing:\n",
            "tensor([[-0.4416, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 155 loss : 0.631507933139801 weight Parameter containing:\n",
            "tensor([[-0.4417, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 156 loss : 0.6314308643341064 weight Parameter containing:\n",
            "tensor([[-0.4418, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 157 loss : 0.6313542127609253 weight Parameter containing:\n",
            "tensor([[-0.4418, -0.0412, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 158 loss : 0.6312777996063232 weight Parameter containing:\n",
            "tensor([[-0.4419, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 159 loss : 0.6312018632888794 weight Parameter containing:\n",
            "tensor([[-0.4420, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 160 loss : 0.6311262249946594 weight Parameter containing:\n",
            "tensor([[-0.4421, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 161 loss : 0.6310509443283081 weight Parameter containing:\n",
            "tensor([[-0.4422, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 162 loss : 0.630976140499115 weight Parameter containing:\n",
            "tensor([[-0.4423, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 163 loss : 0.630901575088501 weight Parameter containing:\n",
            "tensor([[-0.4423, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 164 loss : 0.6308274269104004 weight Parameter containing:\n",
            "tensor([[-0.4424, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 165 loss : 0.6307536363601685 weight Parameter containing:\n",
            "tensor([[-0.4425, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 166 loss : 0.6306802034378052 weight Parameter containing:\n",
            "tensor([[-0.4426, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 167 loss : 0.6306071281433105 weight Parameter containing:\n",
            "tensor([[-0.4427, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 168 loss : 0.6305343508720398 weight Parameter containing:\n",
            "tensor([[-0.4428, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 169 loss : 0.6304619908332825 weight Parameter containing:\n",
            "tensor([[-0.4428, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 170 loss : 0.630389928817749 weight Parameter containing:\n",
            "tensor([[-0.4429, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 171 loss : 0.6303181648254395 weight Parameter containing:\n",
            "tensor([[-0.4430, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 172 loss : 0.6302468776702881 weight Parameter containing:\n",
            "tensor([[-0.4431, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 173 loss : 0.6301758289337158 weight Parameter containing:\n",
            "tensor([[-0.4432, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 174 loss : 0.6301052570343018 weight Parameter containing:\n",
            "tensor([[-0.4432, -0.0413, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 175 loss : 0.630034863948822 weight Parameter containing:\n",
            "tensor([[-0.4433, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 176 loss : 0.6299648880958557 weight Parameter containing:\n",
            "tensor([[-0.4434, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 177 loss : 0.6298952698707581 weight Parameter containing:\n",
            "tensor([[-0.4435, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 178 loss : 0.6298258900642395 weight Parameter containing:\n",
            "tensor([[-0.4436, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 179 loss : 0.6297569274902344 weight Parameter containing:\n",
            "tensor([[-0.4436, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 180 loss : 0.6296882629394531 weight Parameter containing:\n",
            "tensor([[-0.4437, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 181 loss : 0.6296199560165405 weight Parameter containing:\n",
            "tensor([[-0.4438, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 182 loss : 0.6295519471168518 weight Parameter containing:\n",
            "tensor([[-0.4439, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 183 loss : 0.6294842958450317 weight Parameter containing:\n",
            "tensor([[-0.4439, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 184 loss : 0.6294169425964355 weight Parameter containing:\n",
            "tensor([[-0.4440, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 185 loss : 0.629349946975708 weight Parameter containing:\n",
            "tensor([[-0.4441, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 186 loss : 0.6292832493782043 weight Parameter containing:\n",
            "tensor([[-0.4442, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 187 loss : 0.6292169094085693 weight Parameter containing:\n",
            "tensor([[-0.4442, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 188 loss : 0.6291508078575134 weight Parameter containing:\n",
            "tensor([[-0.4443, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 189 loss : 0.6290850639343262 weight Parameter containing:\n",
            "tensor([[-0.4444, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 190 loss : 0.6290196776390076 weight Parameter containing:\n",
            "tensor([[-0.4445, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 191 loss : 0.6289544701576233 weight Parameter containing:\n",
            "tensor([[-0.4445, -0.0414, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 192 loss : 0.6288897395133972 weight Parameter containing:\n",
            "tensor([[-0.4446, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 193 loss : 0.6288251876831055 weight Parameter containing:\n",
            "tensor([[-0.4447, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 194 loss : 0.6287611126899719 weight Parameter containing:\n",
            "tensor([[-0.4448, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 195 loss : 0.6286972165107727 weight Parameter containing:\n",
            "tensor([[-0.4448, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 196 loss : 0.6286336183547974 weight Parameter containing:\n",
            "tensor([[-0.4449, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 197 loss : 0.6285703778266907 weight Parameter containing:\n",
            "tensor([[-0.4450, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 198 loss : 0.6285073757171631 weight Parameter containing:\n",
            "tensor([[-0.4451, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 199 loss : 0.6284447312355042 weight Parameter containing:\n",
            "tensor([[-0.4451, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 200 loss : 0.6283823251724243 weight Parameter containing:\n",
            "tensor([[-0.4452, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 201 loss : 0.6283202767372131 weight Parameter containing:\n",
            "tensor([[-0.4453, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 202 loss : 0.6282585263252258 weight Parameter containing:\n",
            "tensor([[-0.4454, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 203 loss : 0.6281970739364624 weight Parameter containing:\n",
            "tensor([[-0.4454, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 204 loss : 0.6281358599662781 weight Parameter containing:\n",
            "tensor([[-0.4455, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 205 loss : 0.6280750632286072 weight Parameter containing:\n",
            "tensor([[-0.4456, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 206 loss : 0.6280144453048706 weight Parameter containing:\n",
            "tensor([[-0.4457, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 207 loss : 0.6279541254043579 weight Parameter containing:\n",
            "tensor([[-0.4457, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 208 loss : 0.6278940439224243 weight Parameter containing:\n",
            "tensor([[-0.4458, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 209 loss : 0.6278343796730042 weight Parameter containing:\n",
            "tensor([[-0.4459, -0.0415, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 210 loss : 0.6277749538421631 weight Parameter containing:\n",
            "tensor([[-0.4459, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 211 loss : 0.6277158260345459 weight Parameter containing:\n",
            "tensor([[-0.4460, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 212 loss : 0.6276569366455078 weight Parameter containing:\n",
            "tensor([[-0.4461, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 213 loss : 0.6275982856750488 weight Parameter containing:\n",
            "tensor([[-0.4461, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 214 loss : 0.6275399923324585 weight Parameter containing:\n",
            "tensor([[-0.4462, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 215 loss : 0.627481997013092 weight Parameter containing:\n",
            "tensor([[-0.4463, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 216 loss : 0.6274241805076599 weight Parameter containing:\n",
            "tensor([[-0.4464, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 217 loss : 0.6273667216300964 weight Parameter containing:\n",
            "tensor([[-0.4464, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 218 loss : 0.6273095607757568 weight Parameter containing:\n",
            "tensor([[-0.4465, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 219 loss : 0.6272525191307068 weight Parameter containing:\n",
            "tensor([[-0.4466, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 220 loss : 0.6271959543228149 weight Parameter containing:\n",
            "tensor([[-0.4466, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 221 loss : 0.6271395087242126 weight Parameter containing:\n",
            "tensor([[-0.4467, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 222 loss : 0.6270833611488342 weight Parameter containing:\n",
            "tensor([[-0.4468, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 223 loss : 0.6270275115966797 weight Parameter containing:\n",
            "tensor([[-0.4468, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 224 loss : 0.626971960067749 weight Parameter containing:\n",
            "tensor([[-0.4469, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 225 loss : 0.6269166469573975 weight Parameter containing:\n",
            "tensor([[-0.4470, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 226 loss : 0.626861572265625 weight Parameter containing:\n",
            "tensor([[-0.4470, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 227 loss : 0.6268067359924316 weight Parameter containing:\n",
            "tensor([[-0.4471, -0.0416, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 228 loss : 0.6267521977424622 weight Parameter containing:\n",
            "tensor([[-0.4472, -0.0417, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 229 loss : 0.6266979575157166 weight Parameter containing:\n",
            "tensor([[-0.4472, -0.0417, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 230 loss : 0.6266438961029053 weight Parameter containing:\n",
            "tensor([[-0.4473, -0.0417, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 231 loss : 0.6265901327133179 weight Parameter containing:\n",
            "tensor([[-0.4474, -0.0417, -0.3277, -0.1172]], requires_grad=True)\n",
            "epoch : 232 loss : 0.6265366077423096 weight Parameter containing:\n",
            "tensor([[-0.4474, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 233 loss : 0.6264833807945251 weight Parameter containing:\n",
            "tensor([[-0.4475, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 234 loss : 0.6264303922653198 weight Parameter containing:\n",
            "tensor([[-0.4476, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 235 loss : 0.6263775825500488 weight Parameter containing:\n",
            "tensor([[-0.4476, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 236 loss : 0.6263251304626465 weight Parameter containing:\n",
            "tensor([[-0.4477, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 237 loss : 0.6262729167938232 weight Parameter containing:\n",
            "tensor([[-0.4478, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 238 loss : 0.6262208819389343 weight Parameter containing:\n",
            "tensor([[-0.4478, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 239 loss : 0.6261690855026245 weight Parameter containing:\n",
            "tensor([[-0.4479, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 240 loss : 0.6261175274848938 weight Parameter containing:\n",
            "tensor([[-0.4480, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 241 loss : 0.6260663270950317 weight Parameter containing:\n",
            "tensor([[-0.4480, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 242 loss : 0.626015305519104 weight Parameter containing:\n",
            "tensor([[-0.4481, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 243 loss : 0.6259645223617554 weight Parameter containing:\n",
            "tensor([[-0.4481, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 244 loss : 0.6259140372276306 weight Parameter containing:\n",
            "tensor([[-0.4482, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 245 loss : 0.6258636116981506 weight Parameter containing:\n",
            "tensor([[-0.4483, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 246 loss : 0.6258136630058289 weight Parameter containing:\n",
            "tensor([[-0.4483, -0.0417, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 247 loss : 0.6257638335227966 weight Parameter containing:\n",
            "tensor([[-0.4484, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 248 loss : 0.6257142424583435 weight Parameter containing:\n",
            "tensor([[-0.4485, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 249 loss : 0.6256649494171143 weight Parameter containing:\n",
            "tensor([[-0.4485, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 250 loss : 0.6256157755851746 weight Parameter containing:\n",
            "tensor([[-0.4486, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 251 loss : 0.6255668997764587 weight Parameter containing:\n",
            "tensor([[-0.4486, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 252 loss : 0.6255182027816772 weight Parameter containing:\n",
            "tensor([[-0.4487, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 253 loss : 0.6254698038101196 weight Parameter containing:\n",
            "tensor([[-0.4488, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 254 loss : 0.6254216432571411 weight Parameter containing:\n",
            "tensor([[-0.4488, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 255 loss : 0.6253736615180969 weight Parameter containing:\n",
            "tensor([[-0.4489, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 256 loss : 0.6253258585929871 weight Parameter containing:\n",
            "tensor([[-0.4490, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 257 loss : 0.6252784132957458 weight Parameter containing:\n",
            "tensor([[-0.4490, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 258 loss : 0.625231146812439 weight Parameter containing:\n",
            "tensor([[-0.4491, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 259 loss : 0.6251839995384216 weight Parameter containing:\n",
            "tensor([[-0.4491, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 260 loss : 0.6251372694969177 weight Parameter containing:\n",
            "tensor([[-0.4492, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 261 loss : 0.6250906586647034 weight Parameter containing:\n",
            "tensor([[-0.4493, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 262 loss : 0.6250442266464233 weight Parameter containing:\n",
            "tensor([[-0.4493, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 263 loss : 0.6249980926513672 weight Parameter containing:\n",
            "tensor([[-0.4494, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 264 loss : 0.6249520778656006 weight Parameter containing:\n",
            "tensor([[-0.4494, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 265 loss : 0.6249063611030579 weight Parameter containing:\n",
            "tensor([[-0.4495, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 266 loss : 0.6248607635498047 weight Parameter containing:\n",
            "tensor([[-0.4496, -0.0418, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 267 loss : 0.6248155236244202 weight Parameter containing:\n",
            "tensor([[-0.4496, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 268 loss : 0.6247704029083252 weight Parameter containing:\n",
            "tensor([[-0.4497, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 269 loss : 0.6247255206108093 weight Parameter containing:\n",
            "tensor([[-0.4497, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 270 loss : 0.6246808767318726 weight Parameter containing:\n",
            "tensor([[-0.4498, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 271 loss : 0.6246364116668701 weight Parameter containing:\n",
            "tensor([[-0.4498, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 272 loss : 0.624592125415802 weight Parameter containing:\n",
            "tensor([[-0.4499, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 273 loss : 0.624548077583313 weight Parameter containing:\n",
            "tensor([[-0.4500, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 274 loss : 0.6245042681694031 weight Parameter containing:\n",
            "tensor([[-0.4500, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 275 loss : 0.6244606375694275 weight Parameter containing:\n",
            "tensor([[-0.4501, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 276 loss : 0.624417245388031 weight Parameter containing:\n",
            "tensor([[-0.4501, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 277 loss : 0.6243739724159241 weight Parameter containing:\n",
            "tensor([[-0.4502, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 278 loss : 0.624330997467041 weight Parameter containing:\n",
            "tensor([[-0.4502, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 279 loss : 0.6242882609367371 weight Parameter containing:\n",
            "tensor([[-0.4503, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 280 loss : 0.6242455244064331 weight Parameter containing:\n",
            "tensor([[-0.4504, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 281 loss : 0.6242032051086426 weight Parameter containing:\n",
            "tensor([[-0.4504, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 282 loss : 0.6241609454154968 weight Parameter containing:\n",
            "tensor([[-0.4505, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 283 loss : 0.6241189241409302 weight Parameter containing:\n",
            "tensor([[-0.4505, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 284 loss : 0.6240772008895874 weight Parameter containing:\n",
            "tensor([[-0.4506, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 285 loss : 0.6240355372428894 weight Parameter containing:\n",
            "tensor([[-0.4506, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 286 loss : 0.6239940524101257 weight Parameter containing:\n",
            "tensor([[-0.4507, -0.0419, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 287 loss : 0.6239529252052307 weight Parameter containing:\n",
            "tensor([[-0.4507, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 288 loss : 0.6239118576049805 weight Parameter containing:\n",
            "tensor([[-0.4508, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 289 loss : 0.6238710284233093 weight Parameter containing:\n",
            "tensor([[-0.4509, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 290 loss : 0.6238303780555725 weight Parameter containing:\n",
            "tensor([[-0.4509, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 291 loss : 0.6237899661064148 weight Parameter containing:\n",
            "tensor([[-0.4510, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 292 loss : 0.6237496733665466 weight Parameter containing:\n",
            "tensor([[-0.4510, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 293 loss : 0.6237095594406128 weight Parameter containing:\n",
            "tensor([[-0.4511, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 294 loss : 0.6236697435379028 weight Parameter containing:\n",
            "tensor([[-0.4511, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 295 loss : 0.6236299872398376 weight Parameter containing:\n",
            "tensor([[-0.4512, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 296 loss : 0.6235905885696411 weight Parameter containing:\n",
            "tensor([[-0.4512, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 297 loss : 0.6235511898994446 weight Parameter containing:\n",
            "tensor([[-0.4513, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 298 loss : 0.6235120892524719 weight Parameter containing:\n",
            "tensor([[-0.4513, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 299 loss : 0.6234731078147888 weight Parameter containing:\n",
            "tensor([[-0.4514, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 300 loss : 0.62343430519104 weight Parameter containing:\n",
            "tensor([[-0.4514, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 301 loss : 0.6233957409858704 weight Parameter containing:\n",
            "tensor([[-0.4515, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 302 loss : 0.623357355594635 weight Parameter containing:\n",
            "tensor([[-0.4515, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 303 loss : 0.6233190894126892 weight Parameter containing:\n",
            "tensor([[-0.4516, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 304 loss : 0.6232810616493225 weight Parameter containing:\n",
            "tensor([[-0.4516, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 305 loss : 0.6232432126998901 weight Parameter containing:\n",
            "tensor([[-0.4517, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 306 loss : 0.6232054829597473 weight Parameter containing:\n",
            "tensor([[-0.4517, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 307 loss : 0.6231679916381836 weight Parameter containing:\n",
            "tensor([[-0.4518, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 308 loss : 0.6231306195259094 weight Parameter containing:\n",
            "tensor([[-0.4518, -0.0420, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 309 loss : 0.6230934262275696 weight Parameter containing:\n",
            "tensor([[-0.4519, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 310 loss : 0.6230564713478088 weight Parameter containing:\n",
            "tensor([[-0.4519, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 311 loss : 0.6230196356773376 weight Parameter containing:\n",
            "tensor([[-0.4520, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 312 loss : 0.6229829788208008 weight Parameter containing:\n",
            "tensor([[-0.4520, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 313 loss : 0.6229465007781982 weight Parameter containing:\n",
            "tensor([[-0.4521, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 314 loss : 0.6229102611541748 weight Parameter containing:\n",
            "tensor([[-0.4521, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 315 loss : 0.6228740811347961 weight Parameter containing:\n",
            "tensor([[-0.4522, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 316 loss : 0.6228381395339966 weight Parameter containing:\n",
            "tensor([[-0.4522, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 317 loss : 0.6228023767471313 weight Parameter containing:\n",
            "tensor([[-0.4523, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 318 loss : 0.6227667927742004 weight Parameter containing:\n",
            "tensor([[-0.4523, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 319 loss : 0.6227312684059143 weight Parameter containing:\n",
            "tensor([[-0.4524, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 320 loss : 0.6226959824562073 weight Parameter containing:\n",
            "tensor([[-0.4524, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 321 loss : 0.6226608753204346 weight Parameter containing:\n",
            "tensor([[-0.4525, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 322 loss : 0.6226258873939514 weight Parameter containing:\n",
            "tensor([[-0.4525, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 323 loss : 0.6225910186767578 weight Parameter containing:\n",
            "tensor([[-0.4526, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 324 loss : 0.6225565075874329 weight Parameter containing:\n",
            "tensor([[-0.4526, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 325 loss : 0.6225219964981079 weight Parameter containing:\n",
            "tensor([[-0.4527, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 326 loss : 0.6224876046180725 weight Parameter containing:\n",
            "tensor([[-0.4527, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 327 loss : 0.6224535703659058 weight Parameter containing:\n",
            "tensor([[-0.4528, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 328 loss : 0.6224194765090942 weight Parameter containing:\n",
            "tensor([[-0.4528, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 329 loss : 0.6223856806755066 weight Parameter containing:\n",
            "tensor([[-0.4529, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 330 loss : 0.6223520040512085 weight Parameter containing:\n",
            "tensor([[-0.4529, -0.0421, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 331 loss : 0.6223185062408447 weight Parameter containing:\n",
            "tensor([[-0.4530, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 332 loss : 0.6222851872444153 weight Parameter containing:\n",
            "tensor([[-0.4530, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 333 loss : 0.6222519874572754 weight Parameter containing:\n",
            "tensor([[-0.4531, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 334 loss : 0.622218906879425 weight Parameter containing:\n",
            "tensor([[-0.4531, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 335 loss : 0.622186005115509 weight Parameter containing:\n",
            "tensor([[-0.4532, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 336 loss : 0.6221532821655273 weight Parameter containing:\n",
            "tensor([[-0.4532, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 337 loss : 0.6221206188201904 weight Parameter containing:\n",
            "tensor([[-0.4532, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 338 loss : 0.6220881938934326 weight Parameter containing:\n",
            "tensor([[-0.4533, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 339 loss : 0.6220558881759644 weight Parameter containing:\n",
            "tensor([[-0.4533, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 340 loss : 0.6220238208770752 weight Parameter containing:\n",
            "tensor([[-0.4534, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 341 loss : 0.6219918131828308 weight Parameter containing:\n",
            "tensor([[-0.4534, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 342 loss : 0.6219599843025208 weight Parameter containing:\n",
            "tensor([[-0.4535, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 343 loss : 0.6219282746315002 weight Parameter containing:\n",
            "tensor([[-0.4535, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 344 loss : 0.6218967437744141 weight Parameter containing:\n",
            "tensor([[-0.4536, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 345 loss : 0.6218653917312622 weight Parameter containing:\n",
            "tensor([[-0.4536, -0.0422, -0.3277, -0.1173]], requires_grad=True)\n",
            "epoch : 346 loss : 0.6218340992927551 weight Parameter containing:\n",
            "tensor([[-0.4536, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 347 loss : 0.6218029856681824 weight Parameter containing:\n",
            "tensor([[-0.4537, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 348 loss : 0.6217721104621887 weight Parameter containing:\n",
            "tensor([[-0.4537, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 349 loss : 0.6217412352561951 weight Parameter containing:\n",
            "tensor([[-0.4538, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 350 loss : 0.6217105388641357 weight Parameter containing:\n",
            "tensor([[-0.4538, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 351 loss : 0.6216800212860107 weight Parameter containing:\n",
            "tensor([[-0.4539, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 352 loss : 0.6216496229171753 weight Parameter containing:\n",
            "tensor([[-0.4539, -0.0422, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 353 loss : 0.6216194033622742 weight Parameter containing:\n",
            "tensor([[-0.4540, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 354 loss : 0.6215893030166626 weight Parameter containing:\n",
            "tensor([[-0.4540, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 355 loss : 0.6215593218803406 weight Parameter containing:\n",
            "tensor([[-0.4540, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 356 loss : 0.6215295195579529 weight Parameter containing:\n",
            "tensor([[-0.4541, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 357 loss : 0.6214998364448547 weight Parameter containing:\n",
            "tensor([[-0.4541, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 358 loss : 0.6214702725410461 weight Parameter containing:\n",
            "tensor([[-0.4542, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 359 loss : 0.6214409470558167 weight Parameter containing:\n",
            "tensor([[-0.4542, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 360 loss : 0.6214115619659424 weight Parameter containing:\n",
            "tensor([[-0.4543, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 361 loss : 0.6213825345039368 weight Parameter containing:\n",
            "tensor([[-0.4543, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 362 loss : 0.6213534474372864 weight Parameter containing:\n",
            "tensor([[-0.4543, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 363 loss : 0.6213245987892151 weight Parameter containing:\n",
            "tensor([[-0.4544, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 364 loss : 0.6212958693504333 weight Parameter containing:\n",
            "tensor([[-0.4544, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 365 loss : 0.6212672591209412 weight Parameter containing:\n",
            "tensor([[-0.4545, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 366 loss : 0.6212388277053833 weight Parameter containing:\n",
            "tensor([[-0.4545, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 367 loss : 0.621210515499115 weight Parameter containing:\n",
            "tensor([[-0.4545, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 368 loss : 0.6211822628974915 weight Parameter containing:\n",
            "tensor([[-0.4546, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 369 loss : 0.6211541891098022 weight Parameter containing:\n",
            "tensor([[-0.4546, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 370 loss : 0.6211262345314026 weight Parameter containing:\n",
            "tensor([[-0.4547, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 371 loss : 0.621098518371582 weight Parameter containing:\n",
            "tensor([[-0.4547, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 372 loss : 0.6210708618164062 weight Parameter containing:\n",
            "tensor([[-0.4547, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 373 loss : 0.62104332447052 weight Parameter containing:\n",
            "tensor([[-0.4548, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 374 loss : 0.6210158467292786 weight Parameter containing:\n",
            "tensor([[-0.4548, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 375 loss : 0.6209885478019714 weight Parameter containing:\n",
            "tensor([[-0.4549, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 376 loss : 0.6209613680839539 weight Parameter containing:\n",
            "tensor([[-0.4549, -0.0423, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 377 loss : 0.6209343075752258 weight Parameter containing:\n",
            "tensor([[-0.4549, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 378 loss : 0.6209073662757874 weight Parameter containing:\n",
            "tensor([[-0.4550, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 379 loss : 0.6208806037902832 weight Parameter containing:\n",
            "tensor([[-0.4550, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 380 loss : 0.6208539605140686 weight Parameter containing:\n",
            "tensor([[-0.4551, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 381 loss : 0.6208273768424988 weight Parameter containing:\n",
            "tensor([[-0.4551, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 382 loss : 0.6208009719848633 weight Parameter containing:\n",
            "tensor([[-0.4551, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 383 loss : 0.6207746863365173 weight Parameter containing:\n",
            "tensor([[-0.4552, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 384 loss : 0.6207484602928162 weight Parameter containing:\n",
            "tensor([[-0.4552, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 385 loss : 0.6207224130630493 weight Parameter containing:\n",
            "tensor([[-0.4553, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 386 loss : 0.6206965446472168 weight Parameter containing:\n",
            "tensor([[-0.4553, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 387 loss : 0.6206706762313843 weight Parameter containing:\n",
            "tensor([[-0.4553, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 388 loss : 0.6206449866294861 weight Parameter containing:\n",
            "tensor([[-0.4554, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 389 loss : 0.6206194162368774 weight Parameter containing:\n",
            "tensor([[-0.4554, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 390 loss : 0.6205939650535583 weight Parameter containing:\n",
            "tensor([[-0.4554, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 391 loss : 0.620568573474884 weight Parameter containing:\n",
            "tensor([[-0.4555, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 392 loss : 0.6205434203147888 weight Parameter containing:\n",
            "tensor([[-0.4555, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 393 loss : 0.6205183267593384 weight Parameter containing:\n",
            "tensor([[-0.4556, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 394 loss : 0.6204932332038879 weight Parameter containing:\n",
            "tensor([[-0.4556, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 395 loss : 0.6204683780670166 weight Parameter containing:\n",
            "tensor([[-0.4556, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 396 loss : 0.62044358253479 weight Parameter containing:\n",
            "tensor([[-0.4557, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 397 loss : 0.620418906211853 weight Parameter containing:\n",
            "tensor([[-0.4557, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 398 loss : 0.6203944683074951 weight Parameter containing:\n",
            "tensor([[-0.4557, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 399 loss : 0.6203700304031372 weight Parameter containing:\n",
            "tensor([[-0.4558, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 400 loss : 0.6203457117080688 weight Parameter containing:\n",
            "tensor([[-0.4558, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 401 loss : 0.6203215718269348 weight Parameter containing:\n",
            "tensor([[-0.4558, -0.0424, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 402 loss : 0.6202974915504456 weight Parameter containing:\n",
            "tensor([[-0.4559, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 403 loss : 0.6202734112739563 weight Parameter containing:\n",
            "tensor([[-0.4559, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 404 loss : 0.6202495694160461 weight Parameter containing:\n",
            "tensor([[-0.4560, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 405 loss : 0.6202257871627808 weight Parameter containing:\n",
            "tensor([[-0.4560, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 406 loss : 0.6202022433280945 weight Parameter containing:\n",
            "tensor([[-0.4560, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 407 loss : 0.6201786398887634 weight Parameter containing:\n",
            "tensor([[-0.4561, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 408 loss : 0.6201552748680115 weight Parameter containing:\n",
            "tensor([[-0.4561, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 409 loss : 0.6201320290565491 weight Parameter containing:\n",
            "tensor([[-0.4561, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 410 loss : 0.6201087236404419 weight Parameter containing:\n",
            "tensor([[-0.4562, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 411 loss : 0.620085597038269 weight Parameter containing:\n",
            "tensor([[-0.4562, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 412 loss : 0.6200626492500305 weight Parameter containing:\n",
            "tensor([[-0.4562, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 413 loss : 0.6200398206710815 weight Parameter containing:\n",
            "tensor([[-0.4563, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 414 loss : 0.6200169920921326 weight Parameter containing:\n",
            "tensor([[-0.4563, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 415 loss : 0.6199943423271179 weight Parameter containing:\n",
            "tensor([[-0.4563, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 416 loss : 0.619971752166748 weight Parameter containing:\n",
            "tensor([[-0.4564, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 417 loss : 0.619949221611023 weight Parameter containing:\n",
            "tensor([[-0.4564, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 418 loss : 0.6199268698692322 weight Parameter containing:\n",
            "tensor([[-0.4564, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 419 loss : 0.619904637336731 weight Parameter containing:\n",
            "tensor([[-0.4565, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 420 loss : 0.6198824644088745 weight Parameter containing:\n",
            "tensor([[-0.4565, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 421 loss : 0.6198603510856628 weight Parameter containing:\n",
            "tensor([[-0.4565, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 422 loss : 0.6198384165763855 weight Parameter containing:\n",
            "tensor([[-0.4566, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 423 loss : 0.6198166012763977 weight Parameter containing:\n",
            "tensor([[-0.4566, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 424 loss : 0.6197948455810547 weight Parameter containing:\n",
            "tensor([[-0.4566, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 425 loss : 0.6197732090950012 weight Parameter containing:\n",
            "tensor([[-0.4567, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 426 loss : 0.6197515726089478 weight Parameter containing:\n",
            "tensor([[-0.4567, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 427 loss : 0.6197301745414734 weight Parameter containing:\n",
            "tensor([[-0.4567, -0.0425, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 428 loss : 0.6197088360786438 weight Parameter containing:\n",
            "tensor([[-0.4568, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 429 loss : 0.619687557220459 weight Parameter containing:\n",
            "tensor([[-0.4568, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 430 loss : 0.6196663975715637 weight Parameter containing:\n",
            "tensor([[-0.4568, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 431 loss : 0.6196452975273132 weight Parameter containing:\n",
            "tensor([[-0.4569, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 432 loss : 0.6196243762969971 weight Parameter containing:\n",
            "tensor([[-0.4569, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 433 loss : 0.6196035146713257 weight Parameter containing:\n",
            "tensor([[-0.4569, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 434 loss : 0.6195827126502991 weight Parameter containing:\n",
            "tensor([[-0.4570, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 435 loss : 0.619562029838562 weight Parameter containing:\n",
            "tensor([[-0.4570, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 436 loss : 0.6195414662361145 weight Parameter containing:\n",
            "tensor([[-0.4570, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 437 loss : 0.6195210218429565 weight Parameter containing:\n",
            "tensor([[-0.4570, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 438 loss : 0.6195005774497986 weight Parameter containing:\n",
            "tensor([[-0.4571, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 439 loss : 0.6194802522659302 weight Parameter containing:\n",
            "tensor([[-0.4571, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 440 loss : 0.6194599866867065 weight Parameter containing:\n",
            "tensor([[-0.4571, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 441 loss : 0.6194398999214172 weight Parameter containing:\n",
            "tensor([[-0.4572, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 442 loss : 0.6194198727607727 weight Parameter containing:\n",
            "tensor([[-0.4572, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 443 loss : 0.6193999648094177 weight Parameter containing:\n",
            "tensor([[-0.4572, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 444 loss : 0.6193801760673523 weight Parameter containing:\n",
            "tensor([[-0.4573, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 445 loss : 0.6193603277206421 weight Parameter containing:\n",
            "tensor([[-0.4573, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 446 loss : 0.619340717792511 weight Parameter containing:\n",
            "tensor([[-0.4573, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 447 loss : 0.6193211078643799 weight Parameter containing:\n",
            "tensor([[-0.4573, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 448 loss : 0.6193016767501831 weight Parameter containing:\n",
            "tensor([[-0.4574, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 449 loss : 0.6192822456359863 weight Parameter containing:\n",
            "tensor([[-0.4574, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 450 loss : 0.6192629337310791 weight Parameter containing:\n",
            "tensor([[-0.4574, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 451 loss : 0.6192438006401062 weight Parameter containing:\n",
            "tensor([[-0.4575, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 452 loss : 0.6192246675491333 weight Parameter containing:\n",
            "tensor([[-0.4575, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 453 loss : 0.6192055940628052 weight Parameter containing:\n",
            "tensor([[-0.4575, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 454 loss : 0.6191866993904114 weight Parameter containing:\n",
            "tensor([[-0.4576, -0.0426, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 455 loss : 0.6191678047180176 weight Parameter containing:\n",
            "tensor([[-0.4576, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 456 loss : 0.6191489696502686 weight Parameter containing:\n",
            "tensor([[-0.4576, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 457 loss : 0.6191303133964539 weight Parameter containing:\n",
            "tensor([[-0.4576, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 458 loss : 0.6191117167472839 weight Parameter containing:\n",
            "tensor([[-0.4577, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 459 loss : 0.6190932393074036 weight Parameter containing:\n",
            "tensor([[-0.4577, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 460 loss : 0.619074821472168 weight Parameter containing:\n",
            "tensor([[-0.4577, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 461 loss : 0.6190564036369324 weight Parameter containing:\n",
            "tensor([[-0.4577, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 462 loss : 0.6190381646156311 weight Parameter containing:\n",
            "tensor([[-0.4578, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 463 loss : 0.6190199851989746 weight Parameter containing:\n",
            "tensor([[-0.4578, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 464 loss : 0.6190018653869629 weight Parameter containing:\n",
            "tensor([[-0.4578, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 465 loss : 0.6189838647842407 weight Parameter containing:\n",
            "tensor([[-0.4579, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 466 loss : 0.6189659833908081 weight Parameter containing:\n",
            "tensor([[-0.4579, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 467 loss : 0.6189481019973755 weight Parameter containing:\n",
            "tensor([[-0.4579, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 468 loss : 0.6189302802085876 weight Parameter containing:\n",
            "tensor([[-0.4579, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 469 loss : 0.6189126372337341 weight Parameter containing:\n",
            "tensor([[-0.4580, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 470 loss : 0.6188949942588806 weight Parameter containing:\n",
            "tensor([[-0.4580, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 471 loss : 0.6188774704933167 weight Parameter containing:\n",
            "tensor([[-0.4580, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 472 loss : 0.6188600063323975 weight Parameter containing:\n",
            "tensor([[-0.4580, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 473 loss : 0.6188426613807678 weight Parameter containing:\n",
            "tensor([[-0.4581, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 474 loss : 0.6188253164291382 weight Parameter containing:\n",
            "tensor([[-0.4581, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 475 loss : 0.6188081502914429 weight Parameter containing:\n",
            "tensor([[-0.4581, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 476 loss : 0.6187910437583923 weight Parameter containing:\n",
            "tensor([[-0.4582, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 477 loss : 0.6187739968299866 weight Parameter containing:\n",
            "tensor([[-0.4582, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 478 loss : 0.6187569499015808 weight Parameter containing:\n",
            "tensor([[-0.4582, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 479 loss : 0.6187400817871094 weight Parameter containing:\n",
            "tensor([[-0.4582, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 480 loss : 0.6187233328819275 weight Parameter containing:\n",
            "tensor([[-0.4583, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 481 loss : 0.6187065839767456 weight Parameter containing:\n",
            "tensor([[-0.4583, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 482 loss : 0.6186898946762085 weight Parameter containing:\n",
            "tensor([[-0.4583, -0.0427, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 483 loss : 0.6186732649803162 weight Parameter containing:\n",
            "tensor([[-0.4583, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 484 loss : 0.6186567544937134 weight Parameter containing:\n",
            "tensor([[-0.4584, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 485 loss : 0.6186403632164001 weight Parameter containing:\n",
            "tensor([[-0.4584, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 486 loss : 0.6186240315437317 weight Parameter containing:\n",
            "tensor([[-0.4584, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 487 loss : 0.6186076402664185 weight Parameter containing:\n",
            "tensor([[-0.4584, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 488 loss : 0.6185914278030396 weight Parameter containing:\n",
            "tensor([[-0.4585, -0.0428, -0.3277, -0.1174]], requires_grad=True)\n",
            "epoch : 489 loss : 0.6185752749443054 weight Parameter containing:\n",
            "tensor([[-0.4585, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 490 loss : 0.6185592412948608 weight Parameter containing:\n",
            "tensor([[-0.4585, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 491 loss : 0.618543267250061 weight Parameter containing:\n",
            "tensor([[-0.4585, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 492 loss : 0.618527352809906 weight Parameter containing:\n",
            "tensor([[-0.4586, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 493 loss : 0.618511438369751 weight Parameter containing:\n",
            "tensor([[-0.4586, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 494 loss : 0.6184956431388855 weight Parameter containing:\n",
            "tensor([[-0.4586, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 495 loss : 0.6184800267219543 weight Parameter containing:\n",
            "tensor([[-0.4586, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 496 loss : 0.6184643507003784 weight Parameter containing:\n",
            "tensor([[-0.4587, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 497 loss : 0.618448793888092 weight Parameter containing:\n",
            "tensor([[-0.4587, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 498 loss : 0.6184332966804504 weight Parameter containing:\n",
            "tensor([[-0.4587, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 499 loss : 0.6184178590774536 weight Parameter containing:\n",
            "tensor([[-0.4587, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 500 loss : 0.6184025406837463 weight Parameter containing:\n",
            "tensor([[-0.4587, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 501 loss : 0.6183872222900391 weight Parameter containing:\n",
            "tensor([[-0.4588, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 502 loss : 0.6183720231056213 weight Parameter containing:\n",
            "tensor([[-0.4588, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 503 loss : 0.6183568835258484 weight Parameter containing:\n",
            "tensor([[-0.4588, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 504 loss : 0.618341863155365 weight Parameter containing:\n",
            "tensor([[-0.4588, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 505 loss : 0.6183267831802368 weight Parameter containing:\n",
            "tensor([[-0.4589, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 506 loss : 0.618311882019043 weight Parameter containing:\n",
            "tensor([[-0.4589, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 507 loss : 0.6182969212532043 weight Parameter containing:\n",
            "tensor([[-0.4589, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 508 loss : 0.6182821989059448 weight Parameter containing:\n",
            "tensor([[-0.4589, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 509 loss : 0.6182674169540405 weight Parameter containing:\n",
            "tensor([[-0.4590, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 510 loss : 0.6182527542114258 weight Parameter containing:\n",
            "tensor([[-0.4590, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 511 loss : 0.6182381510734558 weight Parameter containing:\n",
            "tensor([[-0.4590, -0.0428, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 512 loss : 0.6182236075401306 weight Parameter containing:\n",
            "tensor([[-0.4590, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 513 loss : 0.6182092428207397 weight Parameter containing:\n",
            "tensor([[-0.4590, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 514 loss : 0.6181946992874146 weight Parameter containing:\n",
            "tensor([[-0.4591, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 515 loss : 0.6181803941726685 weight Parameter containing:\n",
            "tensor([[-0.4591, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 516 loss : 0.6181661486625671 weight Parameter containing:\n",
            "tensor([[-0.4591, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 517 loss : 0.6181519031524658 weight Parameter containing:\n",
            "tensor([[-0.4591, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 518 loss : 0.6181378364562988 weight Parameter containing:\n",
            "tensor([[-0.4591, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 519 loss : 0.6181237101554871 weight Parameter containing:\n",
            "tensor([[-0.4592, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 520 loss : 0.6181097030639648 weight Parameter containing:\n",
            "tensor([[-0.4592, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 521 loss : 0.6180957555770874 weight Parameter containing:\n",
            "tensor([[-0.4592, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 522 loss : 0.6180819272994995 weight Parameter containing:\n",
            "tensor([[-0.4592, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 523 loss : 0.6180680394172668 weight Parameter containing:\n",
            "tensor([[-0.4593, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 524 loss : 0.6180543303489685 weight Parameter containing:\n",
            "tensor([[-0.4593, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 525 loss : 0.6180406212806702 weight Parameter containing:\n",
            "tensor([[-0.4593, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 526 loss : 0.6180269718170166 weight Parameter containing:\n",
            "tensor([[-0.4593, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 527 loss : 0.6180133819580078 weight Parameter containing:\n",
            "tensor([[-0.4593, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 528 loss : 0.6179998517036438 weight Parameter containing:\n",
            "tensor([[-0.4594, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 529 loss : 0.6179865002632141 weight Parameter containing:\n",
            "tensor([[-0.4594, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 530 loss : 0.6179730296134949 weight Parameter containing:\n",
            "tensor([[-0.4594, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 531 loss : 0.61795973777771 weight Parameter containing:\n",
            "tensor([[-0.4594, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 532 loss : 0.6179463267326355 weight Parameter containing:\n",
            "tensor([[-0.4594, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 533 loss : 0.6179332733154297 weight Parameter containing:\n",
            "tensor([[-0.4595, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 534 loss : 0.6179200410842896 weight Parameter containing:\n",
            "tensor([[-0.4595, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 535 loss : 0.617906928062439 weight Parameter containing:\n",
            "tensor([[-0.4595, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 536 loss : 0.6178938746452332 weight Parameter containing:\n",
            "tensor([[-0.4595, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 537 loss : 0.6178809404373169 weight Parameter containing:\n",
            "tensor([[-0.4595, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 538 loss : 0.6178680062294006 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 539 loss : 0.6178551912307739 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 540 loss : 0.617842435836792 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 541 loss : 0.6178296804428101 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 542 loss : 0.6178169846534729 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0429, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 543 loss : 0.6178042888641357 weight Parameter containing:\n",
            "tensor([[-0.4596, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 544 loss : 0.6177917718887329 weight Parameter containing:\n",
            "tensor([[-0.4597, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 545 loss : 0.6177792549133301 weight Parameter containing:\n",
            "tensor([[-0.4597, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 546 loss : 0.617766797542572 weight Parameter containing:\n",
            "tensor([[-0.4597, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 547 loss : 0.6177543997764587 weight Parameter containing:\n",
            "tensor([[-0.4597, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 548 loss : 0.6177420616149902 weight Parameter containing:\n",
            "tensor([[-0.4597, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 549 loss : 0.6177298426628113 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 550 loss : 0.6177175641059875 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 551 loss : 0.6177053451538086 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 552 loss : 0.6176932454109192 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 553 loss : 0.6176812052726746 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 554 loss : 0.6176691651344299 weight Parameter containing:\n",
            "tensor([[-0.4598, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 555 loss : 0.6176572442054749 weight Parameter containing:\n",
            "tensor([[-0.4599, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 556 loss : 0.617645263671875 weight Parameter containing:\n",
            "tensor([[-0.4599, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 557 loss : 0.6176334619522095 weight Parameter containing:\n",
            "tensor([[-0.4599, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 558 loss : 0.6176216006278992 weight Parameter containing:\n",
            "tensor([[-0.4599, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 559 loss : 0.6176099181175232 weight Parameter containing:\n",
            "tensor([[-0.4599, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 560 loss : 0.6175981760025024 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 561 loss : 0.617586612701416 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 562 loss : 0.6175749897956848 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 563 loss : 0.6175634264945984 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 564 loss : 0.6175519824028015 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 565 loss : 0.6175405383110046 weight Parameter containing:\n",
            "tensor([[-0.4600, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 566 loss : 0.6175291538238525 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 567 loss : 0.6175177693367004 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 568 loss : 0.6175066232681274 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 569 loss : 0.6174953579902649 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 570 loss : 0.6174842119216919 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 571 loss : 0.6174730658531189 weight Parameter containing:\n",
            "tensor([[-0.4601, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 572 loss : 0.6174619793891907 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 573 loss : 0.6174509525299072 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 574 loss : 0.6174399852752686 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0430, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 575 loss : 0.6174290180206299 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 576 loss : 0.6174181699752808 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 577 loss : 0.6174073815345764 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 578 loss : 0.6173965334892273 weight Parameter containing:\n",
            "tensor([[-0.4602, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 579 loss : 0.6173858046531677 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 580 loss : 0.6173751354217529 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 581 loss : 0.6173645257949829 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 582 loss : 0.6173539161682129 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 583 loss : 0.6173433661460876 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 584 loss : 0.617332935333252 weight Parameter containing:\n",
            "tensor([[-0.4603, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 585 loss : 0.6173224449157715 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 586 loss : 0.6173120737075806 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 587 loss : 0.6173017621040344 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 588 loss : 0.6172914505004883 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 589 loss : 0.6172811985015869 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 590 loss : 0.6172709465026855 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 591 loss : 0.6172608137130737 weight Parameter containing:\n",
            "tensor([[-0.4604, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 592 loss : 0.6172506809234619 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 593 loss : 0.6172406673431396 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 594 loss : 0.6172305345535278 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 595 loss : 0.6172206401824951 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 596 loss : 0.6172106266021729 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 597 loss : 0.6172007322311401 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 598 loss : 0.617190957069397 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 599 loss : 0.6171810626983643 weight Parameter containing:\n",
            "tensor([[-0.4605, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 600 loss : 0.6171714067459106 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 601 loss : 0.6171616315841675 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 602 loss : 0.6171519756317139 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 603 loss : 0.617142379283905 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 604 loss : 0.6171327233314514 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 605 loss : 0.6171232461929321 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 606 loss : 0.6171137690544128 weight Parameter containing:\n",
            "tensor([[-0.4606, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 607 loss : 0.6171042919158936 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 608 loss : 0.617094874382019 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0431, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 609 loss : 0.6170854568481445 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 610 loss : 0.6170761585235596 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 611 loss : 0.6170668601989746 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 612 loss : 0.6170576214790344 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 613 loss : 0.6170483827590942 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 614 loss : 0.6170392036437988 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 615 loss : 0.6170300841331482 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 616 loss : 0.6170210242271423 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 617 loss : 0.6170120239257812 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 618 loss : 0.6170029640197754 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 619 loss : 0.6169940233230591 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 620 loss : 0.6169851422309875 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 621 loss : 0.6169761419296265 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 622 loss : 0.6169673800468445 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 623 loss : 0.6169585585594177 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 624 loss : 0.6169497966766357 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 625 loss : 0.6169410943984985 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 626 loss : 0.6169323921203613 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 627 loss : 0.6169237494468689 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 628 loss : 0.6169151067733765 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 629 loss : 0.6169065833091736 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 630 loss : 0.6168980598449707 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 631 loss : 0.6168895959854126 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 632 loss : 0.6168810725212097 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 633 loss : 0.6168726682662964 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 634 loss : 0.6168643236160278 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 635 loss : 0.6168559789657593 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 636 loss : 0.6168476939201355 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 637 loss : 0.6168394088745117 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 638 loss : 0.6168311238288879 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 639 loss : 0.6168229579925537 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 640 loss : 0.6168147921562195 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 641 loss : 0.61680668592453 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 642 loss : 0.6167985796928406 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 643 loss : 0.6167905926704407 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0432, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 644 loss : 0.616782546043396 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 645 loss : 0.6167745590209961 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 646 loss : 0.6167666912078857 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 647 loss : 0.6167587041854858 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 648 loss : 0.6167508959770203 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 649 loss : 0.6167430281639099 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 650 loss : 0.6167352199554443 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 651 loss : 0.6167274713516235 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 652 loss : 0.6167197823524475 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 653 loss : 0.6167120337486267 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 654 loss : 0.6167043447494507 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 655 loss : 0.6166967153549194 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 656 loss : 0.6166892051696777 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 657 loss : 0.6166815757751465 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 658 loss : 0.6166740655899048 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 659 loss : 0.6166666150093079 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 660 loss : 0.6166590452194214 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 661 loss : 0.6166516542434692 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 662 loss : 0.6166442632675171 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 663 loss : 0.6166369318962097 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 664 loss : 0.6166295409202576 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 665 loss : 0.6166223287582397 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 666 loss : 0.6166151165962219 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 667 loss : 0.6166077852249146 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 668 loss : 0.6166006326675415 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 669 loss : 0.6165934205055237 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 670 loss : 0.6165863275527954 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1175]], requires_grad=True)\n",
            "epoch : 671 loss : 0.6165792346000671 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 672 loss : 0.6165721416473389 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 673 loss : 0.6165651679039001 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 674 loss : 0.6165581345558167 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 675 loss : 0.6165511608123779 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 676 loss : 0.6165441870689392 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 677 loss : 0.61653733253479 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 678 loss : 0.6165303587913513 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 679 loss : 0.6165235638618469 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 680 loss : 0.6165167093276978 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0433, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 681 loss : 0.6165098547935486 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 682 loss : 0.616503119468689 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 683 loss : 0.6164963841438293 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 684 loss : 0.6164897084236145 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 685 loss : 0.6164830327033997 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 686 loss : 0.6164763569831848 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 687 loss : 0.6164698600769043 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 688 loss : 0.6164632439613342 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 689 loss : 0.6164566278457642 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 690 loss : 0.6164501309394836 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 691 loss : 0.6164436340332031 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 692 loss : 0.6164371967315674 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 693 loss : 0.6164306998252869 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 694 loss : 0.6164243221282959 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 695 loss : 0.6164179444313049 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 696 loss : 0.6164115071296692 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 697 loss : 0.616405189037323 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 698 loss : 0.6163988709449768 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 699 loss : 0.6163926720619202 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 700 loss : 0.6163864135742188 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 701 loss : 0.6163802146911621 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 702 loss : 0.6163740158081055 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 703 loss : 0.6163678169250488 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 704 loss : 0.616361677646637 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 705 loss : 0.6163556575775146 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 706 loss : 0.6163495182991028 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 707 loss : 0.6163434386253357 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 708 loss : 0.6163374185562134 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 709 loss : 0.6163314580917358 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 710 loss : 0.6163254976272583 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 711 loss : 0.6163195371627808 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 712 loss : 0.616313636302948 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 713 loss : 0.6163076758384705 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 714 loss : 0.6163018941879272 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 715 loss : 0.6162959933280945 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 716 loss : 0.6162901520729065 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 717 loss : 0.6162843704223633 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 718 loss : 0.6162786483764648 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 719 loss : 0.6162728667259216 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0434, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 720 loss : 0.616267204284668 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 721 loss : 0.6162614822387695 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 722 loss : 0.6162558794021606 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 723 loss : 0.616250216960907 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 724 loss : 0.6162446141242981 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 725 loss : 0.6162390112876892 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 726 loss : 0.6162334680557251 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 727 loss : 0.616227924823761 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 728 loss : 0.6162223815917969 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 729 loss : 0.6162168979644775 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 730 loss : 0.6162113547325134 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 731 loss : 0.6162059903144836 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 732 loss : 0.6162005662918091 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 733 loss : 0.6161952018737793 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 734 loss : 0.6161897778511047 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 735 loss : 0.616184413433075 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 736 loss : 0.6161791682243347 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 737 loss : 0.6161738038063049 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 738 loss : 0.6161685585975647 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 739 loss : 0.6161633729934692 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 740 loss : 0.6161580681800842 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 741 loss : 0.6161528825759888 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 742 loss : 0.6161476373672485 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 743 loss : 0.6161425113677979 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 744 loss : 0.6161373853683472 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 745 loss : 0.6161323189735413 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 746 loss : 0.6161271929740906 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 747 loss : 0.6161220669746399 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 748 loss : 0.6161170601844788 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 749 loss : 0.6161120533943176 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 750 loss : 0.6161071062088013 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 751 loss : 0.6161020398139954 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 752 loss : 0.6160971522331238 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 753 loss : 0.6160921454429626 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 754 loss : 0.6160872578620911 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 755 loss : 0.6160823106765747 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 756 loss : 0.6160774827003479 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 757 loss : 0.6160726547241211 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 758 loss : 0.6160677671432495 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 759 loss : 0.6160629987716675 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 760 loss : 0.6160581707954407 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0435, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 761 loss : 0.6160534024238586 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 762 loss : 0.6160486936569214 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 763 loss : 0.6160439252853394 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 764 loss : 0.6160392761230469 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 765 loss : 0.6160346269607544 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 766 loss : 0.6160299181938171 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 767 loss : 0.6160252094268799 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 768 loss : 0.6160206198692322 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 769 loss : 0.6160160303115845 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 770 loss : 0.6160115003585815 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 771 loss : 0.6160069108009338 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 772 loss : 0.6160023212432861 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 773 loss : 0.6159977912902832 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 774 loss : 0.6159933805465698 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 775 loss : 0.6159888505935669 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 776 loss : 0.6159843802452087 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 777 loss : 0.6159799098968506 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 778 loss : 0.615975558757782 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 779 loss : 0.6159710884094238 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 780 loss : 0.6159667372703552 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 781 loss : 0.6159623265266418 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 782 loss : 0.6159579753875732 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 783 loss : 0.6159537434577942 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 784 loss : 0.6159493923187256 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 785 loss : 0.6159451007843018 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 786 loss : 0.6159407496452332 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 787 loss : 0.6159365177154541 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 788 loss : 0.6159323453903198 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 789 loss : 0.6159281134605408 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 790 loss : 0.6159239411354065 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 791 loss : 0.6159197092056274 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 792 loss : 0.6159155368804932 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 793 loss : 0.6159114241600037 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 794 loss : 0.6159073114395142 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 795 loss : 0.6159031987190247 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 796 loss : 0.6158990859985352 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 797 loss : 0.6158950328826904 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 798 loss : 0.6158909797668457 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 799 loss : 0.6158869862556458 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 800 loss : 0.615882933139801 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 801 loss : 0.6158789396286011 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 802 loss : 0.6158750057220459 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0436, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 803 loss : 0.6158709526062012 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 804 loss : 0.6158670783042908 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 805 loss : 0.6158630847930908 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 806 loss : 0.6158592104911804 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 807 loss : 0.61585533618927 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 808 loss : 0.6158514022827148 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 809 loss : 0.6158475279808044 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 810 loss : 0.6158437132835388 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 811 loss : 0.6158398389816284 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 812 loss : 0.6158360838890076 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 813 loss : 0.6158322095870972 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 814 loss : 0.6158285737037659 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 815 loss : 0.6158246994018555 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 816 loss : 0.6158210039138794 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 817 loss : 0.6158171892166138 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 818 loss : 0.6158135533332825 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 819 loss : 0.6158098578453064 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 820 loss : 0.6158062219619751 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 821 loss : 0.615802526473999 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 822 loss : 0.6157988905906677 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 823 loss : 0.6157952547073364 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 824 loss : 0.6157916784286499 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 825 loss : 0.6157879829406738 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 826 loss : 0.6157844066619873 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 827 loss : 0.6157808899879456 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 828 loss : 0.6157772541046143 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 829 loss : 0.6157737374305725 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 830 loss : 0.6157702207565308 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 831 loss : 0.615766704082489 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 832 loss : 0.615763247013092 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 833 loss : 0.6157597899436951 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 834 loss : 0.6157562732696533 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 835 loss : 0.6157528758049011 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 836 loss : 0.6157494783401489 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 837 loss : 0.615746021270752 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 838 loss : 0.615742564201355 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 839 loss : 0.6157391667366028 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 840 loss : 0.6157358288764954 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 841 loss : 0.6157324910163879 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 842 loss : 0.6157290935516357 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 843 loss : 0.6157257556915283 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 844 loss : 0.6157225370407104 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 845 loss : 0.615719199180603 weight Parameter containing:\n",
            "tensor([[-0.4617, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 846 loss : 0.6157158613204956 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 847 loss : 0.6157126426696777 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0437, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 848 loss : 0.6157093644142151 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 849 loss : 0.6157061457633972 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 850 loss : 0.6157029271125793 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 851 loss : 0.6156997084617615 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 852 loss : 0.6156964302062988 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 853 loss : 0.6156932711601257 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 854 loss : 0.6156901121139526 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 855 loss : 0.6156870126724243 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 856 loss : 0.6156838536262512 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 857 loss : 0.6156806945800781 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 858 loss : 0.615677535533905 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 859 loss : 0.6156744360923767 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 860 loss : 0.6156713962554932 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 861 loss : 0.6156682968139648 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 862 loss : 0.6156651973724365 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 863 loss : 0.615662157535553 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 864 loss : 0.6156591176986694 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 865 loss : 0.6156561374664307 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 866 loss : 0.6156530976295471 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 867 loss : 0.6156501173973083 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 868 loss : 0.6156470775604248 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 869 loss : 0.615644097328186 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 870 loss : 0.6156412363052368 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 871 loss : 0.615638256072998 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 872 loss : 0.6156352758407593 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 873 loss : 0.6156324148178101 weight Parameter containing:\n",
            "tensor([[-0.4616, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 874 loss : 0.6156294345855713 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 875 loss : 0.6156265139579773 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 876 loss : 0.6156236529350281 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 877 loss : 0.6156208515167236 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 878 loss : 0.6156179308891296 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 879 loss : 0.6156150698661804 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 880 loss : 0.615612268447876 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 881 loss : 0.6156094074249268 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 882 loss : 0.6156065464019775 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 883 loss : 0.6156038641929626 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 884 loss : 0.6156010627746582 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 885 loss : 0.6155983209609985 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 886 loss : 0.6155954599380493 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 887 loss : 0.6155927181243896 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 888 loss : 0.6155900359153748 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 889 loss : 0.6155872941017151 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 890 loss : 0.6155845522880554 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 891 loss : 0.6155818700790405 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 892 loss : 0.6155791878700256 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 893 loss : 0.6155765056610107 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 894 loss : 0.6155737638473511 weight Parameter containing:\n",
            "tensor([[-0.4615, -0.0438, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 895 loss : 0.615571141242981 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 896 loss : 0.6155684590339661 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 897 loss : 0.615565836429596 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 898 loss : 0.6155632734298706 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 899 loss : 0.6155605912208557 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 900 loss : 0.6155580878257751 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 901 loss : 0.615555465221405 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 902 loss : 0.6155529022216797 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 903 loss : 0.6155503392219543 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 904 loss : 0.6155477166175842 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 905 loss : 0.6155451536178589 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 906 loss : 0.6155427098274231 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 907 loss : 0.6155401468276978 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 908 loss : 0.6155375838279724 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 909 loss : 0.6155351400375366 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1176]], requires_grad=True)\n",
            "epoch : 910 loss : 0.6155325770378113 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 911 loss : 0.6155301332473755 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 912 loss : 0.6155277490615845 weight Parameter containing:\n",
            "tensor([[-0.4614, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 913 loss : 0.6155251860618591 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 914 loss : 0.6155228614807129 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 915 loss : 0.6155203580856323 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 916 loss : 0.6155179142951965 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 917 loss : 0.6155155301094055 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 918 loss : 0.615513026714325 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 919 loss : 0.6155107021331787 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 920 loss : 0.6155083179473877 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 921 loss : 0.6155059337615967 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 922 loss : 0.6155036091804504 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 923 loss : 0.6155012249946594 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 924 loss : 0.6154989004135132 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 925 loss : 0.6154965162277222 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 926 loss : 0.6154941916465759 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 927 loss : 0.6154918670654297 weight Parameter containing:\n",
            "tensor([[-0.4613, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 928 loss : 0.6154896020889282 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 929 loss : 0.6154873371124268 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 930 loss : 0.6154849529266357 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 931 loss : 0.615482747554779 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 932 loss : 0.6154804229736328 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 933 loss : 0.6154782772064209 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 934 loss : 0.6154758930206299 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 935 loss : 0.6154736876487732 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 936 loss : 0.6154714822769165 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 937 loss : 0.6154692769050598 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 938 loss : 0.6154670715332031 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 939 loss : 0.6154648661613464 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 940 loss : 0.6154626607894897 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 941 loss : 0.6154605150222778 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 942 loss : 0.6154583096504211 weight Parameter containing:\n",
            "tensor([[-0.4612, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 943 loss : 0.6154561042785645 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0439, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 944 loss : 0.6154539585113525 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 945 loss : 0.6154518127441406 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 946 loss : 0.6154496669769287 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 947 loss : 0.6154475808143616 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 948 loss : 0.6154454946517944 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 949 loss : 0.6154433488845825 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 950 loss : 0.6154413223266602 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 951 loss : 0.6154391765594482 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 952 loss : 0.6154370307922363 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 953 loss : 0.615435004234314 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 954 loss : 0.6154329776763916 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 955 loss : 0.6154308915138245 weight Parameter containing:\n",
            "tensor([[-0.4611, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 956 loss : 0.6154289245605469 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 957 loss : 0.6154268383979797 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 958 loss : 0.6154248118400574 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 959 loss : 0.615422785282135 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 960 loss : 0.6154207587242126 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 961 loss : 0.6154188513755798 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 962 loss : 0.6154167056083679 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 963 loss : 0.6154147386550903 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 964 loss : 0.6154127717018127 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 965 loss : 0.6154108643531799 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 966 loss : 0.6154088973999023 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 967 loss : 0.6154069304466248 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 968 loss : 0.6154049634933472 weight Parameter containing:\n",
            "tensor([[-0.4610, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 969 loss : 0.6154030561447144 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 970 loss : 0.6154011487960815 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 971 loss : 0.6153992414474487 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 972 loss : 0.6153973340988159 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 973 loss : 0.6153954267501831 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 974 loss : 0.6153935194015503 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 975 loss : 0.6153915524482727 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 976 loss : 0.6153897047042847 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 977 loss : 0.6153878569602966 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 978 loss : 0.6153860688209534 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 979 loss : 0.6153842210769653 weight Parameter containing:\n",
            "tensor([[-0.4609, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 980 loss : 0.6153823137283325 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 981 loss : 0.6153804063796997 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 982 loss : 0.6153786778450012 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 983 loss : 0.6153768301010132 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 984 loss : 0.6153749823570251 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 985 loss : 0.6153731942176819 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 986 loss : 0.6153714656829834 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 987 loss : 0.6153696179389954 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 988 loss : 0.6153677701950073 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 989 loss : 0.6153659820556641 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 990 loss : 0.6153642535209656 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 991 loss : 0.6153625249862671 weight Parameter containing:\n",
            "tensor([[-0.4608, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 992 loss : 0.6153607368469238 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 993 loss : 0.6153590679168701 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 994 loss : 0.6153572797775269 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 995 loss : 0.6153555512428284 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0440, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 996 loss : 0.6153537631034851 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0441, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 997 loss : 0.6153520345687866 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0441, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 998 loss : 0.6153504252433777 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0441, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 999 loss : 0.6153486371040344 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0441, -0.3277, -0.1177]], requires_grad=True)\n",
            "epoch : 1000 loss : 0.6153469681739807 weight Parameter containing:\n",
            "tensor([[-0.4607, -0.0441, -0.3277, -0.1177]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMhF3m0zMOje"
      },
      "source": [
        "X = df[['sum','nlikes','nreplies','nretweets']][:139]\n",
        "Y = df [['dayprob']][:139]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2 ,  random_state = 2)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_LxKp4cRtPw"
      },
      "source": [
        "X_t=X_train.to_numpy()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9x-zdE0RtPw"
      },
      "source": [
        "Y_t = Y_train.to_numpy()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr5_u1gRRtPx"
      },
      "source": [
        "X_te = X_test.to_numpy()"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YV03L5xRtPx"
      },
      "source": [
        "Y_te = Y_test.to_numpy()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVZvlLCnRtPx"
      },
      "source": [
        "sc = MinMaxScaler()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMlctFy4RtPx"
      },
      "source": [
        "X_t = (X_t - X_t.min(axis=0))/(X_t.max()-X_t.min(axis=0))\n",
        "X_te= (X_te - X_te.min())/(X_te.max()-X_te.min())\n",
        "#Y_t = sc.fit_transform(Y_t)\n",
        "X_t =  torch.from_numpy(X_t.astype(np.float32))\n",
        "Y_t =  torch.from_numpy(Y_t.astype(np.float32))\n",
        "Y_te =  torch.from_numpy(Y_te.astype(np.float32))\n",
        "X_te =  torch.from_numpy(X_te.astype(np.float32))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAn4FvhRtPx",
        "outputId": "15a3f5d9-56d7-4f23-fb30-0d45b4a32a60"
      },
      "source": [
        "Y_t = Y_t.view(Y_t.shape[0],1)\n",
        "Y_te = Y_te.view(Y_te.shape[0],1)\n",
        "X_t"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2586, 0.0031, 0.0000, 0.0000],\n",
              "        [0.1698, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1511, 0.0093, 0.0000, 0.0109],\n",
              "        [0.0779, 0.0000, 0.0000, 0.0016],\n",
              "        [0.2508, 0.0031, 0.0000, 0.0000],\n",
              "        [0.0078, 0.0062, 0.0000, 0.0000],\n",
              "        [0.0545, 0.0078, 0.0031, 0.0016],\n",
              "        [0.2773, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1184, 0.0016, 0.0000, 0.0000],\n",
              "        [0.1277, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1698, 0.0047, 0.0016, 0.0078],\n",
              "        [0.2819, 0.0016, 0.0000, 0.0000],\n",
              "        [0.0670, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0576, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0452, 0.0031, 0.0000, 0.0016],\n",
              "        [0.0717, 0.0047, 0.0000, 0.0016],\n",
              "        [0.0826, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2056, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0670, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2664, 0.0016, 0.0000, 0.0000],\n",
              "        [0.1931, 0.0062, 0.0000, 0.0016],\n",
              "        [0.1776, 0.0124, 0.0000, 0.0171],\n",
              "        [0.1698, 0.0047, 0.0000, 0.0078],\n",
              "        [0.0062, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2508, 0.0016, 0.0000, 0.0000],\n",
              "        [0.3037, 0.0016, 0.0000, 0.0000],\n",
              "        [0.1620, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1402, 0.0047, 0.0000, 0.0000],\n",
              "        [0.2523, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2009, 0.0016, 0.0000, 0.0000],\n",
              "        [0.1558, 0.1333, 0.0047, 0.0419],\n",
              "        [0.0841, 0.0062, 0.0000, 0.0016],\n",
              "        [0.1542, 0.0000, 0.0016, 0.0000],\n",
              "        [0.2040, 0.0605, 0.0016, 0.0465],\n",
              "        [0.4439, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2196, 0.0000, 0.0016, 0.0000],\n",
              "        [0.1698, 0.0000, 0.0031, 0.0016],\n",
              "        [0.2399, 0.0202, 0.0016, 0.0016],\n",
              "        [0.4081, 0.0016, 0.0000, 0.0000],\n",
              "        [0.0062, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1713, 0.0000, 0.0000, 0.0016],\n",
              "        [0.1776, 0.0047, 0.0016, 0.1163],\n",
              "        [0.2586, 0.0124, 0.0000, 0.0047],\n",
              "        [0.1153, 0.0062, 0.0000, 0.0109],\n",
              "        [0.2072, 0.0093, 0.0016, 0.0016],\n",
              "        [0.3037, 0.0093, 0.0000, 0.0124],\n",
              "        [0.3364, 0.0202, 0.0031, 0.0093],\n",
              "        [0.1324, 0.0171, 0.0016, 0.0357],\n",
              "        [0.0576, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2336, 0.0016, 0.0000, 0.0016],\n",
              "        [0.3037, 0.0031, 0.0000, 0.0000],\n",
              "        [0.2726, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2399, 0.0031, 0.0000, 0.0000],\n",
              "        [0.1713, 0.0000, 0.0000, 0.1101],\n",
              "        [0.4081, 0.0047, 0.0000, 0.0031],\n",
              "        [0.2773, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1698, 0.0047, 0.0000, 0.0000],\n",
              "        [0.2009, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0358, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1340, 0.0031, 0.0000, 0.0000],\n",
              "        [0.0950, 0.0000, 0.0016, 0.0000],\n",
              "        [0.0187, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1916, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0498, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0156, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2321, 0.0000, 0.0031, 0.0000],\n",
              "        [0.2196, 0.0000, 0.0016, 0.0000],\n",
              "        [0.1231, 0.0000, 0.0016, 0.0000],\n",
              "        [0.0561, 0.0233, 0.0000, 0.0062],\n",
              "        [0.4439, 0.0155, 0.0047, 0.0062],\n",
              "        [0.0779, 0.0000, 0.0000, 0.0016],\n",
              "        [0.0358, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3115, 0.0000, 0.0000, 0.0016],\n",
              "        [0.2259, 0.0000, 0.0031, 0.0000],\n",
              "        [0.0514, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2523, 0.0171, 0.0000, 0.0031],\n",
              "        [0.3676, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0078, 0.0000, 0.0016, 0.0000],\n",
              "        [0.3583, 0.0062, 0.0016, 0.0000],\n",
              "        [0.0717, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3676, 0.0124, 0.0000, 0.0000],\n",
              "        [0.1854, 0.0000, 0.0016, 0.0000],\n",
              "        [0.1713, 0.0000, 0.0000, 0.1101],\n",
              "        [0.3037, 0.0016, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3364, 0.0047, 0.0078, 0.1101],\n",
              "        [0.2835, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0561, 0.0000, 0.0000, 0.0016],\n",
              "        [0.0000, 0.0403, 0.0016, 0.0062],\n",
              "        [0.3520, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0561, 0.0047, 0.0000, 0.0016],\n",
              "        [0.2555, 0.0093, 0.0000, 0.0000],\n",
              "        [0.3349, 0.0062, 0.0016, 0.0000],\n",
              "        [0.3364, 0.0047, 0.0078, 0.1101],\n",
              "        [0.3364, 0.0140, 0.0000, 0.0031],\n",
              "        [0.1184, 0.0078, 0.0000, 0.0031],\n",
              "        [0.2118, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1776, 0.0124, 0.0000, 0.0171],\n",
              "        [0.0779, 0.0031, 0.0000, 0.0016],\n",
              "        [0.2928, 0.0031, 0.0000, 0.0000],\n",
              "        [0.2492, 1.0000, 0.0047, 0.0930],\n",
              "        [0.0436, 0.0016, 0.0000, 0.0000],\n",
              "        [0.2586, 0.0031, 0.0000, 0.0000],\n",
              "        [0.1340, 0.0000, 0.0000, 0.0047],\n",
              "        [0.0888, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2882, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4346, 0.0000, 0.0000, 0.0016],\n",
              "        [0.0296, 0.0016, 0.0000, 0.0000],\n",
              "        [0.1978, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3832, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1698, 0.0078, 0.0000, 0.0078]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnULbvKnRtPy"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = nn.Linear(n_features, 1)\n",
        "  def forward(self,x):\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    return y_pred"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvISpk9tReoR",
        "outputId": "24d7aa04-7904-42ed-a0a2-e58ebcc59575"
      },
      "source": [
        "n_features = 4\n",
        "model =  LogisticRegression(n_features)\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs):\n",
        "  y_pred = model(X_t)\n",
        "  loss = criterion(y_pred,Y_t)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  w,b =  model.parameters()\n",
        "  print(f'epoch : {epoch+1} loss : {loss.item()} weight {w}')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 1 loss : 0.7017167806625366 weight Parameter containing:\n",
            "tensor([[-0.4575,  0.1404,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 2 loss : 0.7016692161560059 weight Parameter containing:\n",
            "tensor([[-0.4573,  0.1404,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 3 loss : 0.7016220092773438 weight Parameter containing:\n",
            "tensor([[-0.4572,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 4 loss : 0.7015749216079712 weight Parameter containing:\n",
            "tensor([[-0.4570,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 5 loss : 0.7015280723571777 weight Parameter containing:\n",
            "tensor([[-0.4568,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 6 loss : 0.7014814615249634 weight Parameter containing:\n",
            "tensor([[-0.4567,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 7 loss : 0.7014351487159729 weight Parameter containing:\n",
            "tensor([[-0.4565,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 8 loss : 0.701388955116272 weight Parameter containing:\n",
            "tensor([[-0.4563,  0.1405,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 9 loss : 0.7013429999351501 weight Parameter containing:\n",
            "tensor([[-0.4562,  0.1406,  0.3991, -0.0843]], requires_grad=True)\n",
            "epoch : 10 loss : 0.701297402381897 weight Parameter containing:\n",
            "tensor([[-0.4560,  0.1406,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 11 loss : 0.7012519240379333 weight Parameter containing:\n",
            "tensor([[-0.4558,  0.1406,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 12 loss : 0.7012068033218384 weight Parameter containing:\n",
            "tensor([[-0.4556,  0.1406,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 13 loss : 0.7011616826057434 weight Parameter containing:\n",
            "tensor([[-0.4555,  0.1406,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 14 loss : 0.7011170387268066 weight Parameter containing:\n",
            "tensor([[-0.4553,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 15 loss : 0.7010723948478699 weight Parameter containing:\n",
            "tensor([[-0.4551,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 16 loss : 0.7010279893875122 weight Parameter containing:\n",
            "tensor([[-0.4550,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 17 loss : 0.7009838819503784 weight Parameter containing:\n",
            "tensor([[-0.4548,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 18 loss : 0.7009400129318237 weight Parameter containing:\n",
            "tensor([[-0.4546,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 19 loss : 0.7008963227272034 weight Parameter containing:\n",
            "tensor([[-0.4545,  0.1407,  0.3991, -0.0842]], requires_grad=True)\n",
            "epoch : 20 loss : 0.7008528709411621 weight Parameter containing:\n",
            "tensor([[-0.4543,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 21 loss : 0.7008095979690552 weight Parameter containing:\n",
            "tensor([[-0.4542,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 22 loss : 0.7007665038108826 weight Parameter containing:\n",
            "tensor([[-0.4540,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 23 loss : 0.7007237076759338 weight Parameter containing:\n",
            "tensor([[-0.4538,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 24 loss : 0.7006810903549194 weight Parameter containing:\n",
            "tensor([[-0.4537,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 25 loss : 0.7006387114524841 weight Parameter containing:\n",
            "tensor([[-0.4535,  0.1408,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 26 loss : 0.7005965113639832 weight Parameter containing:\n",
            "tensor([[-0.4533,  0.1409,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 27 loss : 0.7005544900894165 weight Parameter containing:\n",
            "tensor([[-0.4532,  0.1409,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 28 loss : 0.700512707233429 weight Parameter containing:\n",
            "tensor([[-0.4530,  0.1409,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 29 loss : 0.7004711627960205 weight Parameter containing:\n",
            "tensor([[-0.4528,  0.1409,  0.3991, -0.0841]], requires_grad=True)\n",
            "epoch : 30 loss : 0.7004297375679016 weight Parameter containing:\n",
            "tensor([[-0.4527,  0.1409,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 31 loss : 0.7003886103630066 weight Parameter containing:\n",
            "tensor([[-0.4525,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 32 loss : 0.7003476023674011 weight Parameter containing:\n",
            "tensor([[-0.4524,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 33 loss : 0.7003069519996643 weight Parameter containing:\n",
            "tensor([[-0.4522,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 34 loss : 0.7002663016319275 weight Parameter containing:\n",
            "tensor([[-0.4520,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 35 loss : 0.7002260088920593 weight Parameter containing:\n",
            "tensor([[-0.4519,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 36 loss : 0.7001858353614807 weight Parameter containing:\n",
            "tensor([[-0.4517,  0.1410,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 37 loss : 0.7001459002494812 weight Parameter containing:\n",
            "tensor([[-0.4515,  0.1411,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 38 loss : 0.700106143951416 weight Parameter containing:\n",
            "tensor([[-0.4514,  0.1411,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 39 loss : 0.7000665068626404 weight Parameter containing:\n",
            "tensor([[-0.4512,  0.1411,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 40 loss : 0.7000272870063782 weight Parameter containing:\n",
            "tensor([[-0.4511,  0.1411,  0.3991, -0.0840]], requires_grad=True)\n",
            "epoch : 41 loss : 0.6999880075454712 weight Parameter containing:\n",
            "tensor([[-0.4509,  0.1411,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 42 loss : 0.6999490261077881 weight Parameter containing:\n",
            "tensor([[-0.4508,  0.1411,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 43 loss : 0.6999102234840393 weight Parameter containing:\n",
            "tensor([[-0.4506,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 44 loss : 0.6998717188835144 weight Parameter containing:\n",
            "tensor([[-0.4504,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 45 loss : 0.699833333492279 weight Parameter containing:\n",
            "tensor([[-0.4503,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 46 loss : 0.699795126914978 weight Parameter containing:\n",
            "tensor([[-0.4501,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 47 loss : 0.6997570395469666 weight Parameter containing:\n",
            "tensor([[-0.4500,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 48 loss : 0.699719250202179 weight Parameter containing:\n",
            "tensor([[-0.4498,  0.1412,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 49 loss : 0.6996815800666809 weight Parameter containing:\n",
            "tensor([[-0.4496,  0.1413,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 50 loss : 0.699644148349762 weight Parameter containing:\n",
            "tensor([[-0.4495,  0.1413,  0.3991, -0.0839]], requires_grad=True)\n",
            "epoch : 51 loss : 0.6996068954467773 weight Parameter containing:\n",
            "tensor([[-0.4493,  0.1413,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 52 loss : 0.6995697617530823 weight Parameter containing:\n",
            "tensor([[-0.4492,  0.1413,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 53 loss : 0.6995328664779663 weight Parameter containing:\n",
            "tensor([[-0.4490,  0.1413,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 54 loss : 0.6994961500167847 weight Parameter containing:\n",
            "tensor([[-0.4489,  0.1413,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 55 loss : 0.6994596719741821 weight Parameter containing:\n",
            "tensor([[-0.4487,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 56 loss : 0.6994233131408691 weight Parameter containing:\n",
            "tensor([[-0.4486,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 57 loss : 0.6993870735168457 weight Parameter containing:\n",
            "tensor([[-0.4484,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 58 loss : 0.6993510723114014 weight Parameter containing:\n",
            "tensor([[-0.4482,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 59 loss : 0.6993152499198914 weight Parameter containing:\n",
            "tensor([[-0.4481,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 60 loss : 0.6992796063423157 weight Parameter containing:\n",
            "tensor([[-0.4479,  0.1414,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 61 loss : 0.6992442011833191 weight Parameter containing:\n",
            "tensor([[-0.4478,  0.1415,  0.3991, -0.0838]], requires_grad=True)\n",
            "epoch : 62 loss : 0.6992088556289673 weight Parameter containing:\n",
            "tensor([[-0.4476,  0.1415,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 63 loss : 0.6991738080978394 weight Parameter containing:\n",
            "tensor([[-0.4475,  0.1415,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 64 loss : 0.699138879776001 weight Parameter containing:\n",
            "tensor([[-0.4473,  0.1415,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 65 loss : 0.6991041302680969 weight Parameter containing:\n",
            "tensor([[-0.4472,  0.1415,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 66 loss : 0.6990694403648376 weight Parameter containing:\n",
            "tensor([[-0.4470,  0.1415,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 67 loss : 0.6990350484848022 weight Parameter containing:\n",
            "tensor([[-0.4469,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 68 loss : 0.6990007758140564 weight Parameter containing:\n",
            "tensor([[-0.4467,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 69 loss : 0.6989666819572449 weight Parameter containing:\n",
            "tensor([[-0.4466,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 70 loss : 0.6989328265190125 weight Parameter containing:\n",
            "tensor([[-0.4464,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 71 loss : 0.6988991498947144 weight Parameter containing:\n",
            "tensor([[-0.4463,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 72 loss : 0.6988654732704163 weight Parameter containing:\n",
            "tensor([[-0.4461,  0.1416,  0.3991, -0.0837]], requires_grad=True)\n",
            "epoch : 73 loss : 0.6988321542739868 weight Parameter containing:\n",
            "tensor([[-0.4460,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 74 loss : 0.6987988352775574 weight Parameter containing:\n",
            "tensor([[-0.4458,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 75 loss : 0.6987658143043518 weight Parameter containing:\n",
            "tensor([[-0.4457,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 76 loss : 0.698732852935791 weight Parameter containing:\n",
            "tensor([[-0.4455,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 77 loss : 0.6987001299858093 weight Parameter containing:\n",
            "tensor([[-0.4454,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 78 loss : 0.698667585849762 weight Parameter containing:\n",
            "tensor([[-0.4452,  0.1417,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 79 loss : 0.6986351609230042 weight Parameter containing:\n",
            "tensor([[-0.4451,  0.1418,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 80 loss : 0.6986028552055359 weight Parameter containing:\n",
            "tensor([[-0.4449,  0.1418,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 81 loss : 0.698570728302002 weight Parameter containing:\n",
            "tensor([[-0.4448,  0.1418,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 82 loss : 0.6985387802124023 weight Parameter containing:\n",
            "tensor([[-0.4446,  0.1418,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 83 loss : 0.6985069513320923 weight Parameter containing:\n",
            "tensor([[-0.4445,  0.1418,  0.3991, -0.0836]], requires_grad=True)\n",
            "epoch : 84 loss : 0.6984754800796509 weight Parameter containing:\n",
            "tensor([[-0.4443,  0.1418,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 85 loss : 0.6984439492225647 weight Parameter containing:\n",
            "tensor([[-0.4442,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 86 loss : 0.6984125971794128 weight Parameter containing:\n",
            "tensor([[-0.4440,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 87 loss : 0.6983816027641296 weight Parameter containing:\n",
            "tensor([[-0.4439,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 88 loss : 0.6983504295349121 weight Parameter containing:\n",
            "tensor([[-0.4437,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 89 loss : 0.6983195543289185 weight Parameter containing:\n",
            "tensor([[-0.4436,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 90 loss : 0.6982889175415039 weight Parameter containing:\n",
            "tensor([[-0.4434,  0.1419,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 91 loss : 0.6982583999633789 weight Parameter containing:\n",
            "tensor([[-0.4433,  0.1420,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 92 loss : 0.6982280015945435 weight Parameter containing:\n",
            "tensor([[-0.4432,  0.1420,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 93 loss : 0.6981977224349976 weight Parameter containing:\n",
            "tensor([[-0.4430,  0.1420,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 94 loss : 0.6981676816940308 weight Parameter containing:\n",
            "tensor([[-0.4429,  0.1420,  0.3991, -0.0835]], requires_grad=True)\n",
            "epoch : 95 loss : 0.6981377601623535 weight Parameter containing:\n",
            "tensor([[-0.4427,  0.1420,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 96 loss : 0.6981079578399658 weight Parameter containing:\n",
            "tensor([[-0.4426,  0.1420,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 97 loss : 0.6980783343315125 weight Parameter containing:\n",
            "tensor([[-0.4424,  0.1420,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 98 loss : 0.6980487704277039 weight Parameter containing:\n",
            "tensor([[-0.4423,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 99 loss : 0.6980195045471191 weight Parameter containing:\n",
            "tensor([[-0.4421,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 100 loss : 0.6979902386665344 weight Parameter containing:\n",
            "tensor([[-0.4420,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 101 loss : 0.6979612112045288 weight Parameter containing:\n",
            "tensor([[-0.4419,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 102 loss : 0.6979323625564575 weight Parameter containing:\n",
            "tensor([[-0.4417,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 103 loss : 0.6979034543037415 weight Parameter containing:\n",
            "tensor([[-0.4416,  0.1421,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 104 loss : 0.697874903678894 weight Parameter containing:\n",
            "tensor([[-0.4414,  0.1422,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 105 loss : 0.6978463530540466 weight Parameter containing:\n",
            "tensor([[-0.4413,  0.1422,  0.3991, -0.0834]], requires_grad=True)\n",
            "epoch : 106 loss : 0.6978180408477783 weight Parameter containing:\n",
            "tensor([[-0.4411,  0.1422,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 107 loss : 0.6977899074554443 weight Parameter containing:\n",
            "tensor([[-0.4410,  0.1422,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 108 loss : 0.6977618932723999 weight Parameter containing:\n",
            "tensor([[-0.4409,  0.1422,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 109 loss : 0.6977338790893555 weight Parameter containing:\n",
            "tensor([[-0.4407,  0.1422,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 110 loss : 0.6977061629295349 weight Parameter containing:\n",
            "tensor([[-0.4406,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 111 loss : 0.6976785063743591 weight Parameter containing:\n",
            "tensor([[-0.4404,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 112 loss : 0.6976509690284729 weight Parameter containing:\n",
            "tensor([[-0.4403,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 113 loss : 0.697623610496521 weight Parameter containing:\n",
            "tensor([[-0.4402,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 114 loss : 0.6975963711738586 weight Parameter containing:\n",
            "tensor([[-0.4400,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 115 loss : 0.6975693106651306 weight Parameter containing:\n",
            "tensor([[-0.4399,  0.1423,  0.3991, -0.0833]], requires_grad=True)\n",
            "epoch : 116 loss : 0.6975423693656921 weight Parameter containing:\n",
            "tensor([[-0.4397,  0.1423,  0.3992, -0.0833]], requires_grad=True)\n",
            "epoch : 117 loss : 0.6975155472755432 weight Parameter containing:\n",
            "tensor([[-0.4396,  0.1424,  0.3992, -0.0833]], requires_grad=True)\n",
            "epoch : 118 loss : 0.6974887251853943 weight Parameter containing:\n",
            "tensor([[-0.4395,  0.1424,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 119 loss : 0.697462260723114 weight Parameter containing:\n",
            "tensor([[-0.4393,  0.1424,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 120 loss : 0.6974357962608337 weight Parameter containing:\n",
            "tensor([[-0.4392,  0.1424,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 121 loss : 0.6974095702171326 weight Parameter containing:\n",
            "tensor([[-0.4390,  0.1424,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 122 loss : 0.6973833441734314 weight Parameter containing:\n",
            "tensor([[-0.4389,  0.1424,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 123 loss : 0.6973573565483093 weight Parameter containing:\n",
            "tensor([[-0.4388,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 124 loss : 0.697331428527832 weight Parameter containing:\n",
            "tensor([[-0.4386,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 125 loss : 0.6973056197166443 weight Parameter containing:\n",
            "tensor([[-0.4385,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 126 loss : 0.6972799897193909 weight Parameter containing:\n",
            "tensor([[-0.4384,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 127 loss : 0.697254478931427 weight Parameter containing:\n",
            "tensor([[-0.4382,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 128 loss : 0.6972291469573975 weight Parameter containing:\n",
            "tensor([[-0.4381,  0.1425,  0.3992, -0.0832]], requires_grad=True)\n",
            "epoch : 129 loss : 0.6972038149833679 weight Parameter containing:\n",
            "tensor([[-0.4379,  0.1425,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 130 loss : 0.6971786618232727 weight Parameter containing:\n",
            "tensor([[-0.4378,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 131 loss : 0.6971537470817566 weight Parameter containing:\n",
            "tensor([[-0.4377,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 132 loss : 0.6971288323402405 weight Parameter containing:\n",
            "tensor([[-0.4375,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 133 loss : 0.6971040368080139 weight Parameter containing:\n",
            "tensor([[-0.4374,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 134 loss : 0.6970794200897217 weight Parameter containing:\n",
            "tensor([[-0.4373,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 135 loss : 0.6970549821853638 weight Parameter containing:\n",
            "tensor([[-0.4371,  0.1426,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 136 loss : 0.6970305442810059 weight Parameter containing:\n",
            "tensor([[-0.4370,  0.1427,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 137 loss : 0.6970061659812927 weight Parameter containing:\n",
            "tensor([[-0.4369,  0.1427,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 138 loss : 0.6969820857048035 weight Parameter containing:\n",
            "tensor([[-0.4367,  0.1427,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 139 loss : 0.6969579458236694 weight Parameter containing:\n",
            "tensor([[-0.4366,  0.1427,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 140 loss : 0.6969341039657593 weight Parameter containing:\n",
            "tensor([[-0.4365,  0.1427,  0.3992, -0.0831]], requires_grad=True)\n",
            "epoch : 141 loss : 0.6969103217124939 weight Parameter containing:\n",
            "tensor([[-0.4363,  0.1427,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 142 loss : 0.6968865394592285 weight Parameter containing:\n",
            "tensor([[-0.4362,  0.1427,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 143 loss : 0.6968631148338318 weight Parameter containing:\n",
            "tensor([[-0.4361,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 144 loss : 0.6968396306037903 weight Parameter containing:\n",
            "tensor([[-0.4359,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 145 loss : 0.6968163847923279 weight Parameter containing:\n",
            "tensor([[-0.4358,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 146 loss : 0.6967931389808655 weight Parameter containing:\n",
            "tensor([[-0.4357,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 147 loss : 0.6967700719833374 weight Parameter containing:\n",
            "tensor([[-0.4355,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 148 loss : 0.6967471241950989 weight Parameter containing:\n",
            "tensor([[-0.4354,  0.1428,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 149 loss : 0.6967242360115051 weight Parameter containing:\n",
            "tensor([[-0.4353,  0.1429,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 150 loss : 0.6967014670372009 weight Parameter containing:\n",
            "tensor([[-0.4351,  0.1429,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 151 loss : 0.6966787576675415 weight Parameter containing:\n",
            "tensor([[-0.4350,  0.1429,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 152 loss : 0.6966562867164612 weight Parameter containing:\n",
            "tensor([[-0.4349,  0.1429,  0.3992, -0.0830]], requires_grad=True)\n",
            "epoch : 153 loss : 0.6966338157653809 weight Parameter containing:\n",
            "tensor([[-0.4347,  0.1429,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 154 loss : 0.6966116428375244 weight Parameter containing:\n",
            "tensor([[-0.4346,  0.1429,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 155 loss : 0.6965894103050232 weight Parameter containing:\n",
            "tensor([[-0.4345,  0.1429,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 156 loss : 0.6965673565864563 weight Parameter containing:\n",
            "tensor([[-0.4343,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 157 loss : 0.696545422077179 weight Parameter containing:\n",
            "tensor([[-0.4342,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 158 loss : 0.6965234279632568 weight Parameter containing:\n",
            "tensor([[-0.4341,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 159 loss : 0.6965018510818481 weight Parameter containing:\n",
            "tensor([[-0.4340,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 160 loss : 0.6964801549911499 weight Parameter containing:\n",
            "tensor([[-0.4338,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 161 loss : 0.696458637714386 weight Parameter containing:\n",
            "tensor([[-0.4337,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 162 loss : 0.6964371800422668 weight Parameter containing:\n",
            "tensor([[-0.4336,  0.1430,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 163 loss : 0.696415901184082 weight Parameter containing:\n",
            "tensor([[-0.4334,  0.1431,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 164 loss : 0.696394681930542 weight Parameter containing:\n",
            "tensor([[-0.4333,  0.1431,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 165 loss : 0.6963735818862915 weight Parameter containing:\n",
            "tensor([[-0.4332,  0.1431,  0.3992, -0.0829]], requires_grad=True)\n",
            "epoch : 166 loss : 0.6963526010513306 weight Parameter containing:\n",
            "tensor([[-0.4331,  0.1431,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 167 loss : 0.6963317394256592 weight Parameter containing:\n",
            "tensor([[-0.4329,  0.1431,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 168 loss : 0.6963109374046326 weight Parameter containing:\n",
            "tensor([[-0.4328,  0.1431,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 169 loss : 0.6962900757789612 weight Parameter containing:\n",
            "tensor([[-0.4327,  0.1431,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 170 loss : 0.6962696313858032 weight Parameter containing:\n",
            "tensor([[-0.4325,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 171 loss : 0.6962491869926453 weight Parameter containing:\n",
            "tensor([[-0.4324,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 172 loss : 0.6962288022041321 weight Parameter containing:\n",
            "tensor([[-0.4323,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 173 loss : 0.6962084174156189 weight Parameter containing:\n",
            "tensor([[-0.4322,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 174 loss : 0.6961882710456848 weight Parameter containing:\n",
            "tensor([[-0.4320,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 175 loss : 0.6961682438850403 weight Parameter containing:\n",
            "tensor([[-0.4319,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 176 loss : 0.6961482763290405 weight Parameter containing:\n",
            "tensor([[-0.4318,  0.1432,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 177 loss : 0.6961284279823303 weight Parameter containing:\n",
            "tensor([[-0.4317,  0.1433,  0.3992, -0.0828]], requires_grad=True)\n",
            "epoch : 178 loss : 0.6961086392402649 weight Parameter containing:\n",
            "tensor([[-0.4315,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 179 loss : 0.696088969707489 weight Parameter containing:\n",
            "tensor([[-0.4314,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 180 loss : 0.6960694193840027 weight Parameter containing:\n",
            "tensor([[-0.4313,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 181 loss : 0.6960498690605164 weight Parameter containing:\n",
            "tensor([[-0.4312,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 182 loss : 0.6960305571556091 weight Parameter containing:\n",
            "tensor([[-0.4310,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 183 loss : 0.6960112452507019 weight Parameter containing:\n",
            "tensor([[-0.4309,  0.1433,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 184 loss : 0.6959920525550842 weight Parameter containing:\n",
            "tensor([[-0.4308,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 185 loss : 0.6959729790687561 weight Parameter containing:\n",
            "tensor([[-0.4307,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 186 loss : 0.6959539651870728 weight Parameter containing:\n",
            "tensor([[-0.4305,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 187 loss : 0.695935070514679 weight Parameter containing:\n",
            "tensor([[-0.4304,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 188 loss : 0.6959162354469299 weight Parameter containing:\n",
            "tensor([[-0.4303,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 189 loss : 0.6958975791931152 weight Parameter containing:\n",
            "tensor([[-0.4302,  0.1434,  0.3992, -0.0827]], requires_grad=True)\n",
            "epoch : 190 loss : 0.6958789229393005 weight Parameter containing:\n",
            "tensor([[-0.4300,  0.1434,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 191 loss : 0.6958603858947754 weight Parameter containing:\n",
            "tensor([[-0.4299,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 192 loss : 0.6958419680595398 weight Parameter containing:\n",
            "tensor([[-0.4298,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 193 loss : 0.695823609828949 weight Parameter containing:\n",
            "tensor([[-0.4297,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 194 loss : 0.6958053112030029 weight Parameter containing:\n",
            "tensor([[-0.4296,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 195 loss : 0.6957871913909912 weight Parameter containing:\n",
            "tensor([[-0.4294,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 196 loss : 0.695769190788269 weight Parameter containing:\n",
            "tensor([[-0.4293,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 197 loss : 0.6957511305809021 weight Parameter containing:\n",
            "tensor([[-0.4292,  0.1435,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 198 loss : 0.6957331895828247 weight Parameter containing:\n",
            "tensor([[-0.4291,  0.1436,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 199 loss : 0.6957154870033264 weight Parameter containing:\n",
            "tensor([[-0.4289,  0.1436,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 200 loss : 0.6956976652145386 weight Parameter containing:\n",
            "tensor([[-0.4288,  0.1436,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 201 loss : 0.6956800818443298 weight Parameter containing:\n",
            "tensor([[-0.4287,  0.1436,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 202 loss : 0.6956625580787659 weight Parameter containing:\n",
            "tensor([[-0.4286,  0.1436,  0.3992, -0.0826]], requires_grad=True)\n",
            "epoch : 203 loss : 0.6956451535224915 weight Parameter containing:\n",
            "tensor([[-0.4285,  0.1436,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 204 loss : 0.6956278085708618 weight Parameter containing:\n",
            "tensor([[-0.4283,  0.1436,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 205 loss : 0.6956104040145874 weight Parameter containing:\n",
            "tensor([[-0.4282,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 206 loss : 0.6955933570861816 weight Parameter containing:\n",
            "tensor([[-0.4281,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 207 loss : 0.6955762505531311 weight Parameter containing:\n",
            "tensor([[-0.4280,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 208 loss : 0.6955591440200806 weight Parameter containing:\n",
            "tensor([[-0.4279,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 209 loss : 0.6955422759056091 weight Parameter containing:\n",
            "tensor([[-0.4277,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 210 loss : 0.6955254077911377 weight Parameter containing:\n",
            "tensor([[-0.4276,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 211 loss : 0.695508599281311 weight Parameter containing:\n",
            "tensor([[-0.4275,  0.1437,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 212 loss : 0.6954919695854187 weight Parameter containing:\n",
            "tensor([[-0.4274,  0.1438,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 213 loss : 0.6954753398895264 weight Parameter containing:\n",
            "tensor([[-0.4273,  0.1438,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 214 loss : 0.6954588890075684 weight Parameter containing:\n",
            "tensor([[-0.4271,  0.1438,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 215 loss : 0.6954425573348999 weight Parameter containing:\n",
            "tensor([[-0.4270,  0.1438,  0.3992, -0.0825]], requires_grad=True)\n",
            "epoch : 216 loss : 0.6954260468482971 weight Parameter containing:\n",
            "tensor([[-0.4269,  0.1438,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 217 loss : 0.6954098343849182 weight Parameter containing:\n",
            "tensor([[-0.4268,  0.1438,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 218 loss : 0.6953937411308289 weight Parameter containing:\n",
            "tensor([[-0.4267,  0.1438,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 219 loss : 0.6953775882720947 weight Parameter containing:\n",
            "tensor([[-0.4266,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 220 loss : 0.6953615546226501 weight Parameter containing:\n",
            "tensor([[-0.4264,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 221 loss : 0.6953455805778503 weight Parameter containing:\n",
            "tensor([[-0.4263,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 222 loss : 0.6953296661376953 weight Parameter containing:\n",
            "tensor([[-0.4262,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 223 loss : 0.6953138709068298 weight Parameter containing:\n",
            "tensor([[-0.4261,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 224 loss : 0.6952981948852539 weight Parameter containing:\n",
            "tensor([[-0.4260,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 225 loss : 0.695282518863678 weight Parameter containing:\n",
            "tensor([[-0.4259,  0.1439,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 226 loss : 0.6952670216560364 weight Parameter containing:\n",
            "tensor([[-0.4257,  0.1440,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 227 loss : 0.6952515244483948 weight Parameter containing:\n",
            "tensor([[-0.4256,  0.1440,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 228 loss : 0.6952362060546875 weight Parameter containing:\n",
            "tensor([[-0.4255,  0.1440,  0.3992, -0.0824]], requires_grad=True)\n",
            "epoch : 229 loss : 0.6952208280563354 weight Parameter containing:\n",
            "tensor([[-0.4254,  0.1440,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 230 loss : 0.695205569267273 weight Parameter containing:\n",
            "tensor([[-0.4253,  0.1440,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 231 loss : 0.6951904296875 weight Parameter containing:\n",
            "tensor([[-0.4252,  0.1440,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 232 loss : 0.695175290107727 weight Parameter containing:\n",
            "tensor([[-0.4250,  0.1440,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 233 loss : 0.6951603293418884 weight Parameter containing:\n",
            "tensor([[-0.4249,  0.1440,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 234 loss : 0.6951453685760498 weight Parameter containing:\n",
            "tensor([[-0.4248,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 235 loss : 0.695130467414856 weight Parameter containing:\n",
            "tensor([[-0.4247,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 236 loss : 0.6951157450675964 weight Parameter containing:\n",
            "tensor([[-0.4246,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 237 loss : 0.6951010227203369 weight Parameter containing:\n",
            "tensor([[-0.4245,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 238 loss : 0.6950863599777222 weight Parameter containing:\n",
            "tensor([[-0.4244,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 239 loss : 0.695071816444397 weight Parameter containing:\n",
            "tensor([[-0.4242,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 240 loss : 0.695057213306427 weight Parameter containing:\n",
            "tensor([[-0.4241,  0.1441,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 241 loss : 0.6950429081916809 weight Parameter containing:\n",
            "tensor([[-0.4240,  0.1442,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 242 loss : 0.6950284838676453 weight Parameter containing:\n",
            "tensor([[-0.4239,  0.1442,  0.3992, -0.0823]], requires_grad=True)\n",
            "epoch : 243 loss : 0.6950141787528992 weight Parameter containing:\n",
            "tensor([[-0.4238,  0.1442,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 244 loss : 0.6949999928474426 weight Parameter containing:\n",
            "tensor([[-0.4237,  0.1442,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 245 loss : 0.6949858665466309 weight Parameter containing:\n",
            "tensor([[-0.4236,  0.1442,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 246 loss : 0.6949718594551086 weight Parameter containing:\n",
            "tensor([[-0.4235,  0.1442,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 247 loss : 0.6949577927589417 weight Parameter containing:\n",
            "tensor([[-0.4233,  0.1442,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 248 loss : 0.694943904876709 weight Parameter containing:\n",
            "tensor([[-0.4232,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 249 loss : 0.6949300169944763 weight Parameter containing:\n",
            "tensor([[-0.4231,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 250 loss : 0.6949162483215332 weight Parameter containing:\n",
            "tensor([[-0.4230,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 251 loss : 0.6949024796485901 weight Parameter containing:\n",
            "tensor([[-0.4229,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 252 loss : 0.6948889493942261 weight Parameter containing:\n",
            "tensor([[-0.4228,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 253 loss : 0.6948752403259277 weight Parameter containing:\n",
            "tensor([[-0.4227,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 254 loss : 0.694861650466919 weight Parameter containing:\n",
            "tensor([[-0.4226,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 255 loss : 0.6948482990264893 weight Parameter containing:\n",
            "tensor([[-0.4224,  0.1443,  0.3992, -0.0822]], requires_grad=True)\n",
            "epoch : 256 loss : 0.6948349475860596 weight Parameter containing:\n",
            "tensor([[-0.4223,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 257 loss : 0.6948215961456299 weight Parameter containing:\n",
            "tensor([[-0.4222,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 258 loss : 0.6948083639144897 weight Parameter containing:\n",
            "tensor([[-0.4221,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 259 loss : 0.6947951316833496 weight Parameter containing:\n",
            "tensor([[-0.4220,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 260 loss : 0.694782018661499 weight Parameter containing:\n",
            "tensor([[-0.4219,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 261 loss : 0.6947689056396484 weight Parameter containing:\n",
            "tensor([[-0.4218,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 262 loss : 0.694756031036377 weight Parameter containing:\n",
            "tensor([[-0.4217,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 263 loss : 0.6947430372238159 weight Parameter containing:\n",
            "tensor([[-0.4216,  0.1444,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 264 loss : 0.6947301626205444 weight Parameter containing:\n",
            "tensor([[-0.4215,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 265 loss : 0.6947174668312073 weight Parameter containing:\n",
            "tensor([[-0.4213,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 266 loss : 0.6947047114372253 weight Parameter containing:\n",
            "tensor([[-0.4212,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 267 loss : 0.6946921348571777 weight Parameter containing:\n",
            "tensor([[-0.4211,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 268 loss : 0.6946794390678406 weight Parameter containing:\n",
            "tensor([[-0.4210,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 269 loss : 0.694666862487793 weight Parameter containing:\n",
            "tensor([[-0.4209,  0.1445,  0.3992, -0.0821]], requires_grad=True)\n",
            "epoch : 270 loss : 0.6946544051170349 weight Parameter containing:\n",
            "tensor([[-0.4208,  0.1445,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 271 loss : 0.6946420669555664 weight Parameter containing:\n",
            "tensor([[-0.4207,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 272 loss : 0.6946297287940979 weight Parameter containing:\n",
            "tensor([[-0.4206,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 273 loss : 0.6946173310279846 weight Parameter containing:\n",
            "tensor([[-0.4205,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 274 loss : 0.6946051120758057 weight Parameter containing:\n",
            "tensor([[-0.4204,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 275 loss : 0.6945929527282715 weight Parameter containing:\n",
            "tensor([[-0.4203,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 276 loss : 0.6945808529853821 weight Parameter containing:\n",
            "tensor([[-0.4202,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 277 loss : 0.6945688128471375 weight Parameter containing:\n",
            "tensor([[-0.4200,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 278 loss : 0.6945567727088928 weight Parameter containing:\n",
            "tensor([[-0.4199,  0.1446,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 279 loss : 0.6945449709892273 weight Parameter containing:\n",
            "tensor([[-0.4198,  0.1447,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 280 loss : 0.6945329904556274 weight Parameter containing:\n",
            "tensor([[-0.4197,  0.1447,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 281 loss : 0.6945212483406067 weight Parameter containing:\n",
            "tensor([[-0.4196,  0.1447,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 282 loss : 0.6945094466209412 weight Parameter containing:\n",
            "tensor([[-0.4195,  0.1447,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 283 loss : 0.6944977641105652 weight Parameter containing:\n",
            "tensor([[-0.4194,  0.1447,  0.3992, -0.0820]], requires_grad=True)\n",
            "epoch : 284 loss : 0.694486141204834 weight Parameter containing:\n",
            "tensor([[-0.4193,  0.1447,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 285 loss : 0.6944745182991028 weight Parameter containing:\n",
            "tensor([[-0.4192,  0.1447,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 286 loss : 0.6944630146026611 weight Parameter containing:\n",
            "tensor([[-0.4191,  0.1447,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 287 loss : 0.6944515705108643 weight Parameter containing:\n",
            "tensor([[-0.4190,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 288 loss : 0.6944401860237122 weight Parameter containing:\n",
            "tensor([[-0.4189,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 289 loss : 0.6944288015365601 weight Parameter containing:\n",
            "tensor([[-0.4188,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 290 loss : 0.6944175362586975 weight Parameter containing:\n",
            "tensor([[-0.4187,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 291 loss : 0.6944063305854797 weight Parameter containing:\n",
            "tensor([[-0.4186,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 292 loss : 0.694395124912262 weight Parameter containing:\n",
            "tensor([[-0.4185,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 293 loss : 0.694383978843689 weight Parameter containing:\n",
            "tensor([[-0.4184,  0.1448,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 294 loss : 0.6943728923797607 weight Parameter containing:\n",
            "tensor([[-0.4182,  0.1449,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 295 loss : 0.6943619251251221 weight Parameter containing:\n",
            "tensor([[-0.4181,  0.1449,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 296 loss : 0.6943510174751282 weight Parameter containing:\n",
            "tensor([[-0.4180,  0.1449,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 297 loss : 0.6943400502204895 weight Parameter containing:\n",
            "tensor([[-0.4179,  0.1449,  0.3992, -0.0819]], requires_grad=True)\n",
            "epoch : 298 loss : 0.6943292021751404 weight Parameter containing:\n",
            "tensor([[-0.4178,  0.1449,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 299 loss : 0.694318413734436 weight Parameter containing:\n",
            "tensor([[-0.4177,  0.1449,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 300 loss : 0.6943076848983765 weight Parameter containing:\n",
            "tensor([[-0.4176,  0.1449,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 301 loss : 0.6942969560623169 weight Parameter containing:\n",
            "tensor([[-0.4175,  0.1449,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 302 loss : 0.6942864060401917 weight Parameter containing:\n",
            "tensor([[-0.4174,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 303 loss : 0.6942757964134216 weight Parameter containing:\n",
            "tensor([[-0.4173,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 304 loss : 0.6942653059959412 weight Parameter containing:\n",
            "tensor([[-0.4172,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 305 loss : 0.6942547559738159 weight Parameter containing:\n",
            "tensor([[-0.4171,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 306 loss : 0.694244384765625 weight Parameter containing:\n",
            "tensor([[-0.4170,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 307 loss : 0.6942340135574341 weight Parameter containing:\n",
            "tensor([[-0.4169,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 308 loss : 0.6942236423492432 weight Parameter containing:\n",
            "tensor([[-0.4168,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 309 loss : 0.6942134499549866 weight Parameter containing:\n",
            "tensor([[-0.4167,  0.1450,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 310 loss : 0.6942031979560852 weight Parameter containing:\n",
            "tensor([[-0.4166,  0.1451,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 311 loss : 0.6941929459571838 weight Parameter containing:\n",
            "tensor([[-0.4165,  0.1451,  0.3992, -0.0818]], requires_grad=True)\n",
            "epoch : 312 loss : 0.6941829323768616 weight Parameter containing:\n",
            "tensor([[-0.4164,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 313 loss : 0.6941728591918945 weight Parameter containing:\n",
            "tensor([[-0.4163,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 314 loss : 0.6941627860069275 weight Parameter containing:\n",
            "tensor([[-0.4162,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 315 loss : 0.69415283203125 weight Parameter containing:\n",
            "tensor([[-0.4161,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 316 loss : 0.6941429376602173 weight Parameter containing:\n",
            "tensor([[-0.4160,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 317 loss : 0.6941330432891846 weight Parameter containing:\n",
            "tensor([[-0.4159,  0.1451,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 318 loss : 0.6941232681274414 weight Parameter containing:\n",
            "tensor([[-0.4158,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 319 loss : 0.6941134929656982 weight Parameter containing:\n",
            "tensor([[-0.4157,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 320 loss : 0.6941037774085999 weight Parameter containing:\n",
            "tensor([[-0.4156,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 321 loss : 0.6940940618515015 weight Parameter containing:\n",
            "tensor([[-0.4155,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 322 loss : 0.6940844655036926 weight Parameter containing:\n",
            "tensor([[-0.4154,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 323 loss : 0.694074809551239 weight Parameter containing:\n",
            "tensor([[-0.4153,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 324 loss : 0.6940653920173645 weight Parameter containing:\n",
            "tensor([[-0.4152,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 325 loss : 0.6940559148788452 weight Parameter containing:\n",
            "tensor([[-0.4151,  0.1452,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 326 loss : 0.6940464973449707 weight Parameter containing:\n",
            "tensor([[-0.4150,  0.1453,  0.3992, -0.0817]], requires_grad=True)\n",
            "epoch : 327 loss : 0.6940370798110962 weight Parameter containing:\n",
            "tensor([[-0.4149,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 328 loss : 0.6940276622772217 weight Parameter containing:\n",
            "tensor([[-0.4148,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 329 loss : 0.6940183639526367 weight Parameter containing:\n",
            "tensor([[-0.4147,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 330 loss : 0.6940091848373413 weight Parameter containing:\n",
            "tensor([[-0.4146,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 331 loss : 0.6939999461174011 weight Parameter containing:\n",
            "tensor([[-0.4145,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 332 loss : 0.6939908266067505 weight Parameter containing:\n",
            "tensor([[-0.4144,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 333 loss : 0.6939817070960999 weight Parameter containing:\n",
            "tensor([[-0.4143,  0.1453,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 334 loss : 0.6939725875854492 weight Parameter containing:\n",
            "tensor([[-0.4142,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 335 loss : 0.6939637064933777 weight Parameter containing:\n",
            "tensor([[-0.4141,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 336 loss : 0.6939546465873718 weight Parameter containing:\n",
            "tensor([[-0.4140,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 337 loss : 0.6939456462860107 weight Parameter containing:\n",
            "tensor([[-0.4139,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 338 loss : 0.6939368844032288 weight Parameter containing:\n",
            "tensor([[-0.4138,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 339 loss : 0.6939280033111572 weight Parameter containing:\n",
            "tensor([[-0.4137,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 340 loss : 0.6939191818237305 weight Parameter containing:\n",
            "tensor([[-0.4136,  0.1454,  0.3992, -0.0816]], requires_grad=True)\n",
            "epoch : 341 loss : 0.6939104795455933 weight Parameter containing:\n",
            "tensor([[-0.4135,  0.1454,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 342 loss : 0.6939016580581665 weight Parameter containing:\n",
            "tensor([[-0.4134,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 343 loss : 0.6938930749893188 weight Parameter containing:\n",
            "tensor([[-0.4133,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 344 loss : 0.6938844323158264 weight Parameter containing:\n",
            "tensor([[-0.4132,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 345 loss : 0.6938758492469788 weight Parameter containing:\n",
            "tensor([[-0.4131,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 346 loss : 0.6938673853874207 weight Parameter containing:\n",
            "tensor([[-0.4130,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 347 loss : 0.693858802318573 weight Parameter containing:\n",
            "tensor([[-0.4129,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 348 loss : 0.6938503384590149 weight Parameter containing:\n",
            "tensor([[-0.4128,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 349 loss : 0.6938419342041016 weight Parameter containing:\n",
            "tensor([[-0.4127,  0.1455,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 350 loss : 0.6938336491584778 weight Parameter containing:\n",
            "tensor([[-0.4126,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 351 loss : 0.6938252449035645 weight Parameter containing:\n",
            "tensor([[-0.4125,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 352 loss : 0.6938170194625854 weight Parameter containing:\n",
            "tensor([[-0.4124,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 353 loss : 0.6938087344169617 weight Parameter containing:\n",
            "tensor([[-0.4123,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 354 loss : 0.6938005089759827 weight Parameter containing:\n",
            "tensor([[-0.4122,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 355 loss : 0.6937923431396484 weight Parameter containing:\n",
            "tensor([[-0.4121,  0.1456,  0.3992, -0.0815]], requires_grad=True)\n",
            "epoch : 356 loss : 0.6937842965126038 weight Parameter containing:\n",
            "tensor([[-0.4120,  0.1456,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 357 loss : 0.6937762498855591 weight Parameter containing:\n",
            "tensor([[-0.4120,  0.1456,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 358 loss : 0.6937681436538696 weight Parameter containing:\n",
            "tensor([[-0.4119,  0.1456,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 359 loss : 0.6937601566314697 weight Parameter containing:\n",
            "tensor([[-0.4118,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 360 loss : 0.693752110004425 weight Parameter containing:\n",
            "tensor([[-0.4117,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 361 loss : 0.6937443017959595 weight Parameter containing:\n",
            "tensor([[-0.4116,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 362 loss : 0.6937363743782043 weight Parameter containing:\n",
            "tensor([[-0.4115,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 363 loss : 0.6937284469604492 weight Parameter containing:\n",
            "tensor([[-0.4114,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 364 loss : 0.6937206983566284 weight Parameter containing:\n",
            "tensor([[-0.4113,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 365 loss : 0.6937129497528076 weight Parameter containing:\n",
            "tensor([[-0.4112,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 366 loss : 0.6937052607536316 weight Parameter containing:\n",
            "tensor([[-0.4111,  0.1457,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 367 loss : 0.693697452545166 weight Parameter containing:\n",
            "tensor([[-0.4110,  0.1458,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 368 loss : 0.6936898231506348 weight Parameter containing:\n",
            "tensor([[-0.4109,  0.1458,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 369 loss : 0.6936821341514587 weight Parameter containing:\n",
            "tensor([[-0.4108,  0.1458,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 370 loss : 0.6936745643615723 weight Parameter containing:\n",
            "tensor([[-0.4107,  0.1458,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 371 loss : 0.6936671137809753 weight Parameter containing:\n",
            "tensor([[-0.4106,  0.1458,  0.3992, -0.0814]], requires_grad=True)\n",
            "epoch : 372 loss : 0.6936596035957336 weight Parameter containing:\n",
            "tensor([[-0.4105,  0.1458,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 373 loss : 0.6936520338058472 weight Parameter containing:\n",
            "tensor([[-0.4104,  0.1458,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 374 loss : 0.693644642829895 weight Parameter containing:\n",
            "tensor([[-0.4103,  0.1458,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 375 loss : 0.6936373114585876 weight Parameter containing:\n",
            "tensor([[-0.4103,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 376 loss : 0.6936299800872803 weight Parameter containing:\n",
            "tensor([[-0.4102,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 377 loss : 0.6936226487159729 weight Parameter containing:\n",
            "tensor([[-0.4101,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 378 loss : 0.6936153769493103 weight Parameter containing:\n",
            "tensor([[-0.4100,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 379 loss : 0.6936081051826477 weight Parameter containing:\n",
            "tensor([[-0.4099,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 380 loss : 0.6936008930206299 weight Parameter containing:\n",
            "tensor([[-0.4098,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 381 loss : 0.6935937404632568 weight Parameter containing:\n",
            "tensor([[-0.4097,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 382 loss : 0.6935865879058838 weight Parameter containing:\n",
            "tensor([[-0.4096,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 383 loss : 0.6935795545578003 weight Parameter containing:\n",
            "tensor([[-0.4095,  0.1459,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 384 loss : 0.693572461605072 weight Parameter containing:\n",
            "tensor([[-0.4094,  0.1460,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 385 loss : 0.6935654282569885 weight Parameter containing:\n",
            "tensor([[-0.4093,  0.1460,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 386 loss : 0.6935583353042603 weight Parameter containing:\n",
            "tensor([[-0.4092,  0.1460,  0.3992, -0.0813]], requires_grad=True)\n",
            "epoch : 387 loss : 0.6935514211654663 weight Parameter containing:\n",
            "tensor([[-0.4091,  0.1460,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 388 loss : 0.6935445666313171 weight Parameter containing:\n",
            "tensor([[-0.4091,  0.1460,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 389 loss : 0.6935375928878784 weight Parameter containing:\n",
            "tensor([[-0.4090,  0.1460,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 390 loss : 0.6935306787490845 weight Parameter containing:\n",
            "tensor([[-0.4089,  0.1460,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 391 loss : 0.6935239434242249 weight Parameter containing:\n",
            "tensor([[-0.4088,  0.1460,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 392 loss : 0.6935170888900757 weight Parameter containing:\n",
            "tensor([[-0.4087,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 393 loss : 0.6935102939605713 weight Parameter containing:\n",
            "tensor([[-0.4086,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 394 loss : 0.6935036182403564 weight Parameter containing:\n",
            "tensor([[-0.4085,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 395 loss : 0.6934970021247864 weight Parameter containing:\n",
            "tensor([[-0.4084,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 396 loss : 0.6934902667999268 weight Parameter containing:\n",
            "tensor([[-0.4083,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 397 loss : 0.6934835910797119 weight Parameter containing:\n",
            "tensor([[-0.4082,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 398 loss : 0.6934770345687866 weight Parameter containing:\n",
            "tensor([[-0.4081,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 399 loss : 0.6934705376625061 weight Parameter containing:\n",
            "tensor([[-0.4081,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 400 loss : 0.693463921546936 weight Parameter containing:\n",
            "tensor([[-0.4080,  0.1461,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 401 loss : 0.6934573650360107 weight Parameter containing:\n",
            "tensor([[-0.4079,  0.1462,  0.3992, -0.0812]], requires_grad=True)\n",
            "epoch : 402 loss : 0.693450927734375 weight Parameter containing:\n",
            "tensor([[-0.4078,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 403 loss : 0.693444550037384 weight Parameter containing:\n",
            "tensor([[-0.4077,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 404 loss : 0.6934381723403931 weight Parameter containing:\n",
            "tensor([[-0.4076,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 405 loss : 0.6934317350387573 weight Parameter containing:\n",
            "tensor([[-0.4075,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 406 loss : 0.6934254169464111 weight Parameter containing:\n",
            "tensor([[-0.4074,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 407 loss : 0.6934190988540649 weight Parameter containing:\n",
            "tensor([[-0.4073,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 408 loss : 0.6934128403663635 weight Parameter containing:\n",
            "tensor([[-0.4072,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 409 loss : 0.6934065818786621 weight Parameter containing:\n",
            "tensor([[-0.4072,  0.1462,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 410 loss : 0.6934003829956055 weight Parameter containing:\n",
            "tensor([[-0.4071,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 411 loss : 0.6933943033218384 weight Parameter containing:\n",
            "tensor([[-0.4070,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 412 loss : 0.693388044834137 weight Parameter containing:\n",
            "tensor([[-0.4069,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 413 loss : 0.6933819055557251 weight Parameter containing:\n",
            "tensor([[-0.4068,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 414 loss : 0.693375825881958 weight Parameter containing:\n",
            "tensor([[-0.4067,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 415 loss : 0.6933698058128357 weight Parameter containing:\n",
            "tensor([[-0.4066,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 416 loss : 0.6933637857437134 weight Parameter containing:\n",
            "tensor([[-0.4065,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 417 loss : 0.6933577060699463 weight Parameter containing:\n",
            "tensor([[-0.4064,  0.1463,  0.3992, -0.0811]], requires_grad=True)\n",
            "epoch : 418 loss : 0.6933518052101135 weight Parameter containing:\n",
            "tensor([[-0.4064,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 419 loss : 0.6933457851409912 weight Parameter containing:\n",
            "tensor([[-0.4063,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 420 loss : 0.6933399438858032 weight Parameter containing:\n",
            "tensor([[-0.4062,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 421 loss : 0.6933339834213257 weight Parameter containing:\n",
            "tensor([[-0.4061,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 422 loss : 0.6933280825614929 weight Parameter containing:\n",
            "tensor([[-0.4060,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 423 loss : 0.6933224201202393 weight Parameter containing:\n",
            "tensor([[-0.4059,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 424 loss : 0.6933165788650513 weight Parameter containing:\n",
            "tensor([[-0.4058,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 425 loss : 0.6933107972145081 weight Parameter containing:\n",
            "tensor([[-0.4057,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 426 loss : 0.6933050155639648 weight Parameter containing:\n",
            "tensor([[-0.4057,  0.1464,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 427 loss : 0.6932992339134216 weight Parameter containing:\n",
            "tensor([[-0.4056,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 428 loss : 0.6932935118675232 weight Parameter containing:\n",
            "tensor([[-0.4055,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 429 loss : 0.6932879686355591 weight Parameter containing:\n",
            "tensor([[-0.4054,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 430 loss : 0.6932823061943054 weight Parameter containing:\n",
            "tensor([[-0.4053,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 431 loss : 0.6932767033576965 weight Parameter containing:\n",
            "tensor([[-0.4052,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 432 loss : 0.6932711005210876 weight Parameter containing:\n",
            "tensor([[-0.4051,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 433 loss : 0.6932656168937683 weight Parameter containing:\n",
            "tensor([[-0.4051,  0.1465,  0.3992, -0.0810]], requires_grad=True)\n",
            "epoch : 434 loss : 0.6932600736618042 weight Parameter containing:\n",
            "tensor([[-0.4050,  0.1465,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 435 loss : 0.6932545304298401 weight Parameter containing:\n",
            "tensor([[-0.4049,  0.1465,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 436 loss : 0.6932491064071655 weight Parameter containing:\n",
            "tensor([[-0.4048,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 437 loss : 0.6932436227798462 weight Parameter containing:\n",
            "tensor([[-0.4047,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 438 loss : 0.6932382583618164 weight Parameter containing:\n",
            "tensor([[-0.4046,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 439 loss : 0.6932328939437866 weight Parameter containing:\n",
            "tensor([[-0.4045,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 440 loss : 0.6932275295257568 weight Parameter containing:\n",
            "tensor([[-0.4045,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 441 loss : 0.693222165107727 weight Parameter containing:\n",
            "tensor([[-0.4044,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 442 loss : 0.6932168006896973 weight Parameter containing:\n",
            "tensor([[-0.4043,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 443 loss : 0.6932116150856018 weight Parameter containing:\n",
            "tensor([[-0.4042,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 444 loss : 0.6932063102722168 weight Parameter containing:\n",
            "tensor([[-0.4041,  0.1466,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 445 loss : 0.6932010650634766 weight Parameter containing:\n",
            "tensor([[-0.4040,  0.1467,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 446 loss : 0.6931959390640259 weight Parameter containing:\n",
            "tensor([[-0.4039,  0.1467,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 447 loss : 0.6931907534599304 weight Parameter containing:\n",
            "tensor([[-0.4039,  0.1467,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 448 loss : 0.693185567855835 weight Parameter containing:\n",
            "tensor([[-0.4038,  0.1467,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 449 loss : 0.6931804418563843 weight Parameter containing:\n",
            "tensor([[-0.4037,  0.1467,  0.3992, -0.0809]], requires_grad=True)\n",
            "epoch : 450 loss : 0.6931753754615784 weight Parameter containing:\n",
            "tensor([[-0.4036,  0.1467,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 451 loss : 0.6931702494621277 weight Parameter containing:\n",
            "tensor([[-0.4035,  0.1467,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 452 loss : 0.6931652426719666 weight Parameter containing:\n",
            "tensor([[-0.4034,  0.1467,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 453 loss : 0.6931601762771606 weight Parameter containing:\n",
            "tensor([[-0.4034,  0.1467,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 454 loss : 0.6931552290916443 weight Parameter containing:\n",
            "tensor([[-0.4033,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 455 loss : 0.6931502223014832 weight Parameter containing:\n",
            "tensor([[-0.4032,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 456 loss : 0.693145215511322 weight Parameter containing:\n",
            "tensor([[-0.4031,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 457 loss : 0.6931403279304504 weight Parameter containing:\n",
            "tensor([[-0.4030,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 458 loss : 0.6931354403495789 weight Parameter containing:\n",
            "tensor([[-0.4029,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 459 loss : 0.6931305527687073 weight Parameter containing:\n",
            "tensor([[-0.4028,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 460 loss : 0.6931256651878357 weight Parameter containing:\n",
            "tensor([[-0.4028,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 461 loss : 0.6931208968162537 weight Parameter containing:\n",
            "tensor([[-0.4027,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 462 loss : 0.6931160092353821 weight Parameter containing:\n",
            "tensor([[-0.4026,  0.1468,  0.3992, -0.0808]], requires_grad=True)\n",
            "epoch : 463 loss : 0.6931112408638 weight Parameter containing:\n",
            "tensor([[-0.4025,  0.1469,  0.3993, -0.0808]], requires_grad=True)\n",
            "epoch : 464 loss : 0.6931065320968628 weight Parameter containing:\n",
            "tensor([[-0.4024,  0.1469,  0.3993, -0.0808]], requires_grad=True)\n",
            "epoch : 465 loss : 0.6931017637252808 weight Parameter containing:\n",
            "tensor([[-0.4023,  0.1469,  0.3993, -0.0808]], requires_grad=True)\n",
            "epoch : 466 loss : 0.6930971145629883 weight Parameter containing:\n",
            "tensor([[-0.4023,  0.1469,  0.3993, -0.0808]], requires_grad=True)\n",
            "epoch : 467 loss : 0.6930923461914062 weight Parameter containing:\n",
            "tensor([[-0.4022,  0.1469,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 468 loss : 0.6930876970291138 weight Parameter containing:\n",
            "tensor([[-0.4021,  0.1469,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 469 loss : 0.6930829882621765 weight Parameter containing:\n",
            "tensor([[-0.4020,  0.1469,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 470 loss : 0.6930783987045288 weight Parameter containing:\n",
            "tensor([[-0.4019,  0.1469,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 471 loss : 0.6930738091468811 weight Parameter containing:\n",
            "tensor([[-0.4019,  0.1469,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 472 loss : 0.6930691599845886 weight Parameter containing:\n",
            "tensor([[-0.4018,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 473 loss : 0.6930646300315857 weight Parameter containing:\n",
            "tensor([[-0.4017,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 474 loss : 0.6930601000785828 weight Parameter containing:\n",
            "tensor([[-0.4016,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 475 loss : 0.6930555105209351 weight Parameter containing:\n",
            "tensor([[-0.4015,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 476 loss : 0.6930510401725769 weight Parameter containing:\n",
            "tensor([[-0.4014,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 477 loss : 0.6930466294288635 weight Parameter containing:\n",
            "tensor([[-0.4014,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 478 loss : 0.6930420994758606 weight Parameter containing:\n",
            "tensor([[-0.4013,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 479 loss : 0.693037748336792 weight Parameter containing:\n",
            "tensor([[-0.4012,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 480 loss : 0.6930332183837891 weight Parameter containing:\n",
            "tensor([[-0.4011,  0.1470,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 481 loss : 0.6930290460586548 weight Parameter containing:\n",
            "tensor([[-0.4010,  0.1471,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 482 loss : 0.6930246353149414 weight Parameter containing:\n",
            "tensor([[-0.4010,  0.1471,  0.3993, -0.0807]], requires_grad=True)\n",
            "epoch : 483 loss : 0.693020224571228 weight Parameter containing:\n",
            "tensor([[-0.4009,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 484 loss : 0.693015992641449 weight Parameter containing:\n",
            "tensor([[-0.4008,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 485 loss : 0.6930117011070251 weight Parameter containing:\n",
            "tensor([[-0.4007,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 486 loss : 0.6930073499679565 weight Parameter containing:\n",
            "tensor([[-0.4006,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 487 loss : 0.6930030584335327 weight Parameter containing:\n",
            "tensor([[-0.4005,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 488 loss : 0.6929989457130432 weight Parameter containing:\n",
            "tensor([[-0.4005,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 489 loss : 0.6929945945739746 weight Parameter containing:\n",
            "tensor([[-0.4004,  0.1471,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 490 loss : 0.6929904222488403 weight Parameter containing:\n",
            "tensor([[-0.4003,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 491 loss : 0.6929863095283508 weight Parameter containing:\n",
            "tensor([[-0.4002,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 492 loss : 0.6929820775985718 weight Parameter containing:\n",
            "tensor([[-0.4001,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 493 loss : 0.6929779648780823 weight Parameter containing:\n",
            "tensor([[-0.4001,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 494 loss : 0.6929738521575928 weight Parameter containing:\n",
            "tensor([[-0.4000,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 495 loss : 0.692969799041748 weight Parameter containing:\n",
            "tensor([[-0.3999,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 496 loss : 0.6929657459259033 weight Parameter containing:\n",
            "tensor([[-0.3998,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 497 loss : 0.6929616332054138 weight Parameter containing:\n",
            "tensor([[-0.3997,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 498 loss : 0.6929576396942139 weight Parameter containing:\n",
            "tensor([[-0.3997,  0.1472,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 499 loss : 0.6929535865783691 weight Parameter containing:\n",
            "tensor([[-0.3996,  0.1473,  0.3993, -0.0806]], requires_grad=True)\n",
            "epoch : 500 loss : 0.692949652671814 weight Parameter containing:\n",
            "tensor([[-0.3995,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 501 loss : 0.692945659160614 weight Parameter containing:\n",
            "tensor([[-0.3994,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 502 loss : 0.6929416060447693 weight Parameter containing:\n",
            "tensor([[-0.3993,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 503 loss : 0.6929376721382141 weight Parameter containing:\n",
            "tensor([[-0.3993,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 504 loss : 0.6929337978363037 weight Parameter containing:\n",
            "tensor([[-0.3992,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 505 loss : 0.6929299235343933 weight Parameter containing:\n",
            "tensor([[-0.3991,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 506 loss : 0.6929261088371277 weight Parameter containing:\n",
            "tensor([[-0.3990,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 507 loss : 0.6929221749305725 weight Parameter containing:\n",
            "tensor([[-0.3990,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 508 loss : 0.6929183602333069 weight Parameter containing:\n",
            "tensor([[-0.3989,  0.1473,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 509 loss : 0.6929145455360413 weight Parameter containing:\n",
            "tensor([[-0.3988,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 510 loss : 0.6929107308387756 weight Parameter containing:\n",
            "tensor([[-0.3987,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 511 loss : 0.69290691614151 weight Parameter containing:\n",
            "tensor([[-0.3986,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 512 loss : 0.6929032206535339 weight Parameter containing:\n",
            "tensor([[-0.3986,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 513 loss : 0.6928994059562683 weight Parameter containing:\n",
            "tensor([[-0.3985,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 514 loss : 0.6928957104682922 weight Parameter containing:\n",
            "tensor([[-0.3984,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 515 loss : 0.6928918957710266 weight Parameter containing:\n",
            "tensor([[-0.3983,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 516 loss : 0.6928882002830505 weight Parameter containing:\n",
            "tensor([[-0.3982,  0.1474,  0.3993, -0.0805]], requires_grad=True)\n",
            "epoch : 517 loss : 0.6928845643997192 weight Parameter containing:\n",
            "tensor([[-0.3982,  0.1474,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 518 loss : 0.6928808689117432 weight Parameter containing:\n",
            "tensor([[-0.3981,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 519 loss : 0.6928772926330566 weight Parameter containing:\n",
            "tensor([[-0.3980,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 520 loss : 0.6928737163543701 weight Parameter containing:\n",
            "tensor([[-0.3979,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 521 loss : 0.6928700804710388 weight Parameter containing:\n",
            "tensor([[-0.3979,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 522 loss : 0.6928664445877075 weight Parameter containing:\n",
            "tensor([[-0.3978,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 523 loss : 0.692862868309021 weight Parameter containing:\n",
            "tensor([[-0.3977,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 524 loss : 0.6928592920303345 weight Parameter containing:\n",
            "tensor([[-0.3976,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 525 loss : 0.692855715751648 weight Parameter containing:\n",
            "tensor([[-0.3976,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 526 loss : 0.692852258682251 weight Parameter containing:\n",
            "tensor([[-0.3975,  0.1475,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 527 loss : 0.6928487420082092 weight Parameter containing:\n",
            "tensor([[-0.3974,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 528 loss : 0.6928452253341675 weight Parameter containing:\n",
            "tensor([[-0.3973,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 529 loss : 0.6928417682647705 weight Parameter containing:\n",
            "tensor([[-0.3972,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 530 loss : 0.6928383111953735 weight Parameter containing:\n",
            "tensor([[-0.3972,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 531 loss : 0.6928347945213318 weight Parameter containing:\n",
            "tensor([[-0.3971,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 532 loss : 0.6928314566612244 weight Parameter containing:\n",
            "tensor([[-0.3970,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 533 loss : 0.6928280591964722 weight Parameter containing:\n",
            "tensor([[-0.3969,  0.1476,  0.3993, -0.0804]], requires_grad=True)\n",
            "epoch : 534 loss : 0.6928247213363647 weight Parameter containing:\n",
            "tensor([[-0.3969,  0.1476,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 535 loss : 0.6928212642669678 weight Parameter containing:\n",
            "tensor([[-0.3968,  0.1476,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 536 loss : 0.6928178668022156 weight Parameter containing:\n",
            "tensor([[-0.3967,  0.1476,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 537 loss : 0.6928145885467529 weight Parameter containing:\n",
            "tensor([[-0.3966,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 538 loss : 0.6928113102912903 weight Parameter containing:\n",
            "tensor([[-0.3966,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 539 loss : 0.6928079128265381 weight Parameter containing:\n",
            "tensor([[-0.3965,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 540 loss : 0.6928046941757202 weight Parameter containing:\n",
            "tensor([[-0.3964,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 541 loss : 0.6928013563156128 weight Parameter containing:\n",
            "tensor([[-0.3963,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 542 loss : 0.6927981972694397 weight Parameter containing:\n",
            "tensor([[-0.3963,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 543 loss : 0.6927948594093323 weight Parameter containing:\n",
            "tensor([[-0.3962,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 544 loss : 0.6927917003631592 weight Parameter containing:\n",
            "tensor([[-0.3961,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 545 loss : 0.6927884221076965 weight Parameter containing:\n",
            "tensor([[-0.3960,  0.1477,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 546 loss : 0.6927852630615234 weight Parameter containing:\n",
            "tensor([[-0.3959,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 547 loss : 0.6927820444107056 weight Parameter containing:\n",
            "tensor([[-0.3959,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 548 loss : 0.6927788257598877 weight Parameter containing:\n",
            "tensor([[-0.3958,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 549 loss : 0.6927757859230042 weight Parameter containing:\n",
            "tensor([[-0.3957,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 550 loss : 0.6927726864814758 weight Parameter containing:\n",
            "tensor([[-0.3956,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 551 loss : 0.6927694082260132 weight Parameter containing:\n",
            "tensor([[-0.3956,  0.1478,  0.3993, -0.0803]], requires_grad=True)\n",
            "epoch : 552 loss : 0.6927663683891296 weight Parameter containing:\n",
            "tensor([[-0.3955,  0.1478,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 553 loss : 0.6927632689476013 weight Parameter containing:\n",
            "tensor([[-0.3954,  0.1478,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 554 loss : 0.692760169506073 weight Parameter containing:\n",
            "tensor([[-0.3953,  0.1478,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 555 loss : 0.6927571296691895 weight Parameter containing:\n",
            "tensor([[-0.3953,  0.1478,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 556 loss : 0.6927540302276611 weight Parameter containing:\n",
            "tensor([[-0.3952,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 557 loss : 0.6927511096000671 weight Parameter containing:\n",
            "tensor([[-0.3951,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 558 loss : 0.6927480101585388 weight Parameter containing:\n",
            "tensor([[-0.3950,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 559 loss : 0.6927450299263 weight Parameter containing:\n",
            "tensor([[-0.3950,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 560 loss : 0.692742109298706 weight Parameter containing:\n",
            "tensor([[-0.3949,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 561 loss : 0.6927390694618225 weight Parameter containing:\n",
            "tensor([[-0.3948,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 562 loss : 0.6927360892295837 weight Parameter containing:\n",
            "tensor([[-0.3948,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 563 loss : 0.6927331686019897 weight Parameter containing:\n",
            "tensor([[-0.3947,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 564 loss : 0.692730188369751 weight Parameter containing:\n",
            "tensor([[-0.3946,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 565 loss : 0.6927272081375122 weight Parameter containing:\n",
            "tensor([[-0.3945,  0.1479,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 566 loss : 0.692724347114563 weight Parameter containing:\n",
            "tensor([[-0.3945,  0.1480,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 567 loss : 0.6927214860916138 weight Parameter containing:\n",
            "tensor([[-0.3944,  0.1480,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 568 loss : 0.6927185654640198 weight Parameter containing:\n",
            "tensor([[-0.3943,  0.1480,  0.3993, -0.0802]], requires_grad=True)\n",
            "epoch : 569 loss : 0.6927157640457153 weight Parameter containing:\n",
            "tensor([[-0.3942,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 570 loss : 0.6927128434181213 weight Parameter containing:\n",
            "tensor([[-0.3942,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 571 loss : 0.6927100419998169 weight Parameter containing:\n",
            "tensor([[-0.3941,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 572 loss : 0.6927071809768677 weight Parameter containing:\n",
            "tensor([[-0.3940,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 573 loss : 0.6927043199539185 weight Parameter containing:\n",
            "tensor([[-0.3939,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 574 loss : 0.6927015781402588 weight Parameter containing:\n",
            "tensor([[-0.3939,  0.1480,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 575 loss : 0.6926988363265991 weight Parameter containing:\n",
            "tensor([[-0.3938,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 576 loss : 0.6926960349082947 weight Parameter containing:\n",
            "tensor([[-0.3937,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 577 loss : 0.692693293094635 weight Parameter containing:\n",
            "tensor([[-0.3936,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 578 loss : 0.6926905512809753 weight Parameter containing:\n",
            "tensor([[-0.3936,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 579 loss : 0.6926878690719604 weight Parameter containing:\n",
            "tensor([[-0.3935,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 580 loss : 0.6926851272583008 weight Parameter containing:\n",
            "tensor([[-0.3934,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 581 loss : 0.6926824450492859 weight Parameter containing:\n",
            "tensor([[-0.3934,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 582 loss : 0.6926796436309814 weight Parameter containing:\n",
            "tensor([[-0.3933,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 583 loss : 0.6926769614219666 weight Parameter containing:\n",
            "tensor([[-0.3932,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 584 loss : 0.6926743984222412 weight Parameter containing:\n",
            "tensor([[-0.3931,  0.1481,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 585 loss : 0.6926717162132263 weight Parameter containing:\n",
            "tensor([[-0.3931,  0.1482,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 586 loss : 0.6926690936088562 weight Parameter containing:\n",
            "tensor([[-0.3930,  0.1482,  0.3993, -0.0801]], requires_grad=True)\n",
            "epoch : 587 loss : 0.6926663517951965 weight Parameter containing:\n",
            "tensor([[-0.3929,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 588 loss : 0.6926637291908264 weight Parameter containing:\n",
            "tensor([[-0.3929,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 589 loss : 0.6926611661911011 weight Parameter containing:\n",
            "tensor([[-0.3928,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 590 loss : 0.692658543586731 weight Parameter containing:\n",
            "tensor([[-0.3927,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 591 loss : 0.6926560997962952 weight Parameter containing:\n",
            "tensor([[-0.3926,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 592 loss : 0.6926534175872803 weight Parameter containing:\n",
            "tensor([[-0.3926,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 593 loss : 0.6926508545875549 weight Parameter containing:\n",
            "tensor([[-0.3925,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 594 loss : 0.6926484107971191 weight Parameter containing:\n",
            "tensor([[-0.3924,  0.1482,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 595 loss : 0.692645788192749 weight Parameter containing:\n",
            "tensor([[-0.3923,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 596 loss : 0.6926432251930237 weight Parameter containing:\n",
            "tensor([[-0.3923,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 597 loss : 0.6926407814025879 weight Parameter containing:\n",
            "tensor([[-0.3922,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 598 loss : 0.6926382184028625 weight Parameter containing:\n",
            "tensor([[-0.3921,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 599 loss : 0.6926358342170715 weight Parameter containing:\n",
            "tensor([[-0.3921,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 600 loss : 0.692633330821991 weight Parameter containing:\n",
            "tensor([[-0.3920,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 601 loss : 0.6926308274269104 weight Parameter containing:\n",
            "tensor([[-0.3919,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 602 loss : 0.6926283836364746 weight Parameter containing:\n",
            "tensor([[-0.3919,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 603 loss : 0.6926259994506836 weight Parameter containing:\n",
            "tensor([[-0.3918,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 604 loss : 0.6926235556602478 weight Parameter containing:\n",
            "tensor([[-0.3917,  0.1483,  0.3993, -0.0800]], requires_grad=True)\n",
            "epoch : 605 loss : 0.6926210522651672 weight Parameter containing:\n",
            "tensor([[-0.3916,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 606 loss : 0.6926186084747314 weight Parameter containing:\n",
            "tensor([[-0.3916,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 607 loss : 0.6926162838935852 weight Parameter containing:\n",
            "tensor([[-0.3915,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 608 loss : 0.692613959312439 weight Parameter containing:\n",
            "tensor([[-0.3914,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 609 loss : 0.6926116347312927 weight Parameter containing:\n",
            "tensor([[-0.3914,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 610 loss : 0.6926091909408569 weight Parameter containing:\n",
            "tensor([[-0.3913,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 611 loss : 0.6926068663597107 weight Parameter containing:\n",
            "tensor([[-0.3912,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 612 loss : 0.6926044821739197 weight Parameter containing:\n",
            "tensor([[-0.3911,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 613 loss : 0.6926021575927734 weight Parameter containing:\n",
            "tensor([[-0.3911,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 614 loss : 0.6925999522209167 weight Parameter containing:\n",
            "tensor([[-0.3910,  0.1484,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 615 loss : 0.692597508430481 weight Parameter containing:\n",
            "tensor([[-0.3909,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 616 loss : 0.6925952434539795 weight Parameter containing:\n",
            "tensor([[-0.3909,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 617 loss : 0.692592978477478 weight Parameter containing:\n",
            "tensor([[-0.3908,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 618 loss : 0.6925907731056213 weight Parameter containing:\n",
            "tensor([[-0.3907,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 619 loss : 0.6925884485244751 weight Parameter containing:\n",
            "tensor([[-0.3907,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 620 loss : 0.6925861835479736 weight Parameter containing:\n",
            "tensor([[-0.3906,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 621 loss : 0.6925839781761169 weight Parameter containing:\n",
            "tensor([[-0.3905,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 622 loss : 0.6925817131996155 weight Parameter containing:\n",
            "tensor([[-0.3904,  0.1485,  0.3993, -0.0799]], requires_grad=True)\n",
            "epoch : 623 loss : 0.6925795078277588 weight Parameter containing:\n",
            "tensor([[-0.3904,  0.1485,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 624 loss : 0.6925773024559021 weight Parameter containing:\n",
            "tensor([[-0.3903,  0.1485,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 625 loss : 0.6925750374794006 weight Parameter containing:\n",
            "tensor([[-0.3902,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 626 loss : 0.6925729513168335 weight Parameter containing:\n",
            "tensor([[-0.3902,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 627 loss : 0.6925707459449768 weight Parameter containing:\n",
            "tensor([[-0.3901,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 628 loss : 0.6925685405731201 weight Parameter containing:\n",
            "tensor([[-0.3900,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 629 loss : 0.692566454410553 weight Parameter containing:\n",
            "tensor([[-0.3900,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 630 loss : 0.6925641894340515 weight Parameter containing:\n",
            "tensor([[-0.3899,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 631 loss : 0.6925621628761292 weight Parameter containing:\n",
            "tensor([[-0.3898,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 632 loss : 0.6925599575042725 weight Parameter containing:\n",
            "tensor([[-0.3898,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 633 loss : 0.6925578713417053 weight Parameter containing:\n",
            "tensor([[-0.3897,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 634 loss : 0.6925557255744934 weight Parameter containing:\n",
            "tensor([[-0.3896,  0.1486,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 635 loss : 0.692553699016571 weight Parameter containing:\n",
            "tensor([[-0.3895,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 636 loss : 0.6925516128540039 weight Parameter containing:\n",
            "tensor([[-0.3895,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 637 loss : 0.692549467086792 weight Parameter containing:\n",
            "tensor([[-0.3894,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 638 loss : 0.6925473809242249 weight Parameter containing:\n",
            "tensor([[-0.3893,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 639 loss : 0.6925453543663025 weight Parameter containing:\n",
            "tensor([[-0.3893,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 640 loss : 0.6925433278083801 weight Parameter containing:\n",
            "tensor([[-0.3892,  0.1487,  0.3993, -0.0798]], requires_grad=True)\n",
            "epoch : 641 loss : 0.6925413012504578 weight Parameter containing:\n",
            "tensor([[-0.3891,  0.1487,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 642 loss : 0.6925392746925354 weight Parameter containing:\n",
            "tensor([[-0.3891,  0.1487,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 643 loss : 0.692537248134613 weight Parameter containing:\n",
            "tensor([[-0.3890,  0.1487,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 644 loss : 0.6925352215766907 weight Parameter containing:\n",
            "tensor([[-0.3889,  0.1487,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 645 loss : 0.6925331950187683 weight Parameter containing:\n",
            "tensor([[-0.3889,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 646 loss : 0.6925312280654907 weight Parameter containing:\n",
            "tensor([[-0.3888,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 647 loss : 0.6925291419029236 weight Parameter containing:\n",
            "tensor([[-0.3887,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 648 loss : 0.6925272941589355 weight Parameter containing:\n",
            "tensor([[-0.3887,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 649 loss : 0.6925252676010132 weight Parameter containing:\n",
            "tensor([[-0.3886,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 650 loss : 0.6925233006477356 weight Parameter containing:\n",
            "tensor([[-0.3885,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 651 loss : 0.6925213932991028 weight Parameter containing:\n",
            "tensor([[-0.3885,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 652 loss : 0.6925194263458252 weight Parameter containing:\n",
            "tensor([[-0.3884,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 653 loss : 0.6925174593925476 weight Parameter containing:\n",
            "tensor([[-0.3883,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 654 loss : 0.6925155520439148 weight Parameter containing:\n",
            "tensor([[-0.3882,  0.1488,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 655 loss : 0.6925137042999268 weight Parameter containing:\n",
            "tensor([[-0.3882,  0.1489,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 656 loss : 0.6925117373466492 weight Parameter containing:\n",
            "tensor([[-0.3881,  0.1489,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 657 loss : 0.6925098896026611 weight Parameter containing:\n",
            "tensor([[-0.3880,  0.1489,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 658 loss : 0.6925079226493835 weight Parameter containing:\n",
            "tensor([[-0.3880,  0.1489,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 659 loss : 0.6925060749053955 weight Parameter containing:\n",
            "tensor([[-0.3879,  0.1489,  0.3993, -0.0797]], requires_grad=True)\n",
            "epoch : 660 loss : 0.6925042867660522 weight Parameter containing:\n",
            "tensor([[-0.3878,  0.1489,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 661 loss : 0.6925023198127747 weight Parameter containing:\n",
            "tensor([[-0.3878,  0.1489,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 662 loss : 0.6925004124641418 weight Parameter containing:\n",
            "tensor([[-0.3877,  0.1489,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 663 loss : 0.6924986243247986 weight Parameter containing:\n",
            "tensor([[-0.3876,  0.1489,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 664 loss : 0.6924968361854553 weight Parameter containing:\n",
            "tensor([[-0.3876,  0.1489,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 665 loss : 0.6924950480461121 weight Parameter containing:\n",
            "tensor([[-0.3875,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 666 loss : 0.692493200302124 weight Parameter containing:\n",
            "tensor([[-0.3874,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 667 loss : 0.692491352558136 weight Parameter containing:\n",
            "tensor([[-0.3874,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 668 loss : 0.6924895644187927 weight Parameter containing:\n",
            "tensor([[-0.3873,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 669 loss : 0.6924877762794495 weight Parameter containing:\n",
            "tensor([[-0.3872,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 670 loss : 0.6924859285354614 weight Parameter containing:\n",
            "tensor([[-0.3872,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 671 loss : 0.6924841403961182 weight Parameter containing:\n",
            "tensor([[-0.3871,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 672 loss : 0.6924824118614197 weight Parameter containing:\n",
            "tensor([[-0.3870,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 673 loss : 0.6924806237220764 weight Parameter containing:\n",
            "tensor([[-0.3870,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 674 loss : 0.6924788951873779 weight Parameter containing:\n",
            "tensor([[-0.3869,  0.1490,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 675 loss : 0.6924771070480347 weight Parameter containing:\n",
            "tensor([[-0.3868,  0.1491,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 676 loss : 0.6924753189086914 weight Parameter containing:\n",
            "tensor([[-0.3868,  0.1491,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 677 loss : 0.6924736499786377 weight Parameter containing:\n",
            "tensor([[-0.3867,  0.1491,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 678 loss : 0.6924718618392944 weight Parameter containing:\n",
            "tensor([[-0.3866,  0.1491,  0.3993, -0.0796]], requires_grad=True)\n",
            "epoch : 679 loss : 0.6924702525138855 weight Parameter containing:\n",
            "tensor([[-0.3866,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 680 loss : 0.6924685835838318 weight Parameter containing:\n",
            "tensor([[-0.3865,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 681 loss : 0.6924667954444885 weight Parameter containing:\n",
            "tensor([[-0.3864,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 682 loss : 0.69246506690979 weight Parameter containing:\n",
            "tensor([[-0.3864,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 683 loss : 0.6924634575843811 weight Parameter containing:\n",
            "tensor([[-0.3863,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 684 loss : 0.6924617290496826 weight Parameter containing:\n",
            "tensor([[-0.3863,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 685 loss : 0.6924600601196289 weight Parameter containing:\n",
            "tensor([[-0.3862,  0.1491,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 686 loss : 0.6924585103988647 weight Parameter containing:\n",
            "tensor([[-0.3861,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 687 loss : 0.6924567818641663 weight Parameter containing:\n",
            "tensor([[-0.3861,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 688 loss : 0.6924551725387573 weight Parameter containing:\n",
            "tensor([[-0.3860,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 689 loss : 0.6924535632133484 weight Parameter containing:\n",
            "tensor([[-0.3859,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 690 loss : 0.6924518942832947 weight Parameter containing:\n",
            "tensor([[-0.3859,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 691 loss : 0.692450225353241 weight Parameter containing:\n",
            "tensor([[-0.3858,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 692 loss : 0.692448616027832 weight Parameter containing:\n",
            "tensor([[-0.3857,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 693 loss : 0.6924470067024231 weight Parameter containing:\n",
            "tensor([[-0.3857,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 694 loss : 0.6924454569816589 weight Parameter containing:\n",
            "tensor([[-0.3856,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 695 loss : 0.69244384765625 weight Parameter containing:\n",
            "tensor([[-0.3855,  0.1492,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 696 loss : 0.6924421787261963 weight Parameter containing:\n",
            "tensor([[-0.3855,  0.1493,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 697 loss : 0.6924406886100769 weight Parameter containing:\n",
            "tensor([[-0.3854,  0.1493,  0.3993, -0.0795]], requires_grad=True)\n",
            "epoch : 698 loss : 0.692439079284668 weight Parameter containing:\n",
            "tensor([[-0.3853,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 699 loss : 0.6924375295639038 weight Parameter containing:\n",
            "tensor([[-0.3853,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 700 loss : 0.6924358606338501 weight Parameter containing:\n",
            "tensor([[-0.3852,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 701 loss : 0.6924343705177307 weight Parameter containing:\n",
            "tensor([[-0.3851,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 702 loss : 0.6924329400062561 weight Parameter containing:\n",
            "tensor([[-0.3851,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 703 loss : 0.6924312710762024 weight Parameter containing:\n",
            "tensor([[-0.3850,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 704 loss : 0.6924296617507935 weight Parameter containing:\n",
            "tensor([[-0.3849,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 705 loss : 0.6924282312393188 weight Parameter containing:\n",
            "tensor([[-0.3849,  0.1493,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 706 loss : 0.6924266815185547 weight Parameter containing:\n",
            "tensor([[-0.3848,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 707 loss : 0.6924251317977905 weight Parameter containing:\n",
            "tensor([[-0.3848,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 708 loss : 0.6924237012863159 weight Parameter containing:\n",
            "tensor([[-0.3847,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 709 loss : 0.6924222111701965 weight Parameter containing:\n",
            "tensor([[-0.3846,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 710 loss : 0.6924206614494324 weight Parameter containing:\n",
            "tensor([[-0.3846,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 711 loss : 0.6924192309379578 weight Parameter containing:\n",
            "tensor([[-0.3845,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 712 loss : 0.6924177408218384 weight Parameter containing:\n",
            "tensor([[-0.3844,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 713 loss : 0.6924163699150085 weight Parameter containing:\n",
            "tensor([[-0.3844,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 714 loss : 0.6924148201942444 weight Parameter containing:\n",
            "tensor([[-0.3843,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 715 loss : 0.6924133896827698 weight Parameter containing:\n",
            "tensor([[-0.3842,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 716 loss : 0.6924118995666504 weight Parameter containing:\n",
            "tensor([[-0.3842,  0.1494,  0.3993, -0.0794]], requires_grad=True)\n",
            "epoch : 717 loss : 0.6924104690551758 weight Parameter containing:\n",
            "tensor([[-0.3841,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 718 loss : 0.6924089789390564 weight Parameter containing:\n",
            "tensor([[-0.3841,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 719 loss : 0.6924075484275818 weight Parameter containing:\n",
            "tensor([[-0.3840,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 720 loss : 0.6924061179161072 weight Parameter containing:\n",
            "tensor([[-0.3839,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 721 loss : 0.6924047470092773 weight Parameter containing:\n",
            "tensor([[-0.3839,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 722 loss : 0.6924033164978027 weight Parameter containing:\n",
            "tensor([[-0.3838,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 723 loss : 0.6924019455909729 weight Parameter containing:\n",
            "tensor([[-0.3837,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 724 loss : 0.6924004554748535 weight Parameter containing:\n",
            "tensor([[-0.3837,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 725 loss : 0.6923990249633789 weight Parameter containing:\n",
            "tensor([[-0.3836,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 726 loss : 0.6923977136611938 weight Parameter containing:\n",
            "tensor([[-0.3835,  0.1495,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 727 loss : 0.6923962831497192 weight Parameter containing:\n",
            "tensor([[-0.3835,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 728 loss : 0.6923949718475342 weight Parameter containing:\n",
            "tensor([[-0.3834,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 729 loss : 0.6923935413360596 weight Parameter containing:\n",
            "tensor([[-0.3834,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 730 loss : 0.6923921704292297 weight Parameter containing:\n",
            "tensor([[-0.3833,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 731 loss : 0.6923908591270447 weight Parameter containing:\n",
            "tensor([[-0.3832,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 732 loss : 0.6923894882202148 weight Parameter containing:\n",
            "tensor([[-0.3832,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 733 loss : 0.6923881769180298 weight Parameter containing:\n",
            "tensor([[-0.3831,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 734 loss : 0.6923868656158447 weight Parameter containing:\n",
            "tensor([[-0.3830,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 735 loss : 0.6923854351043701 weight Parameter containing:\n",
            "tensor([[-0.3830,  0.1496,  0.3993, -0.0793]], requires_grad=True)\n",
            "epoch : 736 loss : 0.6923841238021851 weight Parameter containing:\n",
            "tensor([[-0.3829,  0.1496,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 737 loss : 0.6923828125 weight Parameter containing:\n",
            "tensor([[-0.3828,  0.1496,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 738 loss : 0.6923815011978149 weight Parameter containing:\n",
            "tensor([[-0.3828,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 739 loss : 0.6923801898956299 weight Parameter containing:\n",
            "tensor([[-0.3827,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 740 loss : 0.6923788189888 weight Parameter containing:\n",
            "tensor([[-0.3827,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 741 loss : 0.6923775672912598 weight Parameter containing:\n",
            "tensor([[-0.3826,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 742 loss : 0.6923762559890747 weight Parameter containing:\n",
            "tensor([[-0.3825,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 743 loss : 0.6923750042915344 weight Parameter containing:\n",
            "tensor([[-0.3825,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 744 loss : 0.6923736929893494 weight Parameter containing:\n",
            "tensor([[-0.3824,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 745 loss : 0.6923724412918091 weight Parameter containing:\n",
            "tensor([[-0.3823,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 746 loss : 0.692371129989624 weight Parameter containing:\n",
            "tensor([[-0.3823,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 747 loss : 0.6923698782920837 weight Parameter containing:\n",
            "tensor([[-0.3822,  0.1497,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 748 loss : 0.6923685669898987 weight Parameter containing:\n",
            "tensor([[-0.3822,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 749 loss : 0.692367434501648 weight Parameter containing:\n",
            "tensor([[-0.3821,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 750 loss : 0.6923661231994629 weight Parameter containing:\n",
            "tensor([[-0.3820,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 751 loss : 0.6923648715019226 weight Parameter containing:\n",
            "tensor([[-0.3820,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 752 loss : 0.6923636198043823 weight Parameter containing:\n",
            "tensor([[-0.3819,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 753 loss : 0.6923623085021973 weight Parameter containing:\n",
            "tensor([[-0.3819,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 754 loss : 0.6923611164093018 weight Parameter containing:\n",
            "tensor([[-0.3818,  0.1498,  0.3993, -0.0792]], requires_grad=True)\n",
            "epoch : 755 loss : 0.6923598647117615 weight Parameter containing:\n",
            "tensor([[-0.3817,  0.1498,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 756 loss : 0.6923586130142212 weight Parameter containing:\n",
            "tensor([[-0.3817,  0.1498,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 757 loss : 0.6923575401306152 weight Parameter containing:\n",
            "tensor([[-0.3816,  0.1498,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 758 loss : 0.692356288433075 weight Parameter containing:\n",
            "tensor([[-0.3815,  0.1498,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 759 loss : 0.6923550367355347 weight Parameter containing:\n",
            "tensor([[-0.3815,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 760 loss : 0.6923539042472839 weight Parameter containing:\n",
            "tensor([[-0.3814,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 761 loss : 0.6923526525497437 weight Parameter containing:\n",
            "tensor([[-0.3814,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 762 loss : 0.6923514604568481 weight Parameter containing:\n",
            "tensor([[-0.3813,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 763 loss : 0.6923503875732422 weight Parameter containing:\n",
            "tensor([[-0.3812,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 764 loss : 0.6923491358757019 weight Parameter containing:\n",
            "tensor([[-0.3812,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 765 loss : 0.6923478841781616 weight Parameter containing:\n",
            "tensor([[-0.3811,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 766 loss : 0.6923468112945557 weight Parameter containing:\n",
            "tensor([[-0.3810,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 767 loss : 0.6923455595970154 weight Parameter containing:\n",
            "tensor([[-0.3810,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 768 loss : 0.6923443675041199 weight Parameter containing:\n",
            "tensor([[-0.3809,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 769 loss : 0.6923432350158691 weight Parameter containing:\n",
            "tensor([[-0.3809,  0.1499,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 770 loss : 0.6923421025276184 weight Parameter containing:\n",
            "tensor([[-0.3808,  0.1500,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 771 loss : 0.6923410296440125 weight Parameter containing:\n",
            "tensor([[-0.3807,  0.1500,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 772 loss : 0.6923398375511169 weight Parameter containing:\n",
            "tensor([[-0.3807,  0.1500,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 773 loss : 0.6923387050628662 weight Parameter containing:\n",
            "tensor([[-0.3806,  0.1500,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 774 loss : 0.6923375725746155 weight Parameter containing:\n",
            "tensor([[-0.3806,  0.1500,  0.3993, -0.0791]], requires_grad=True)\n",
            "epoch : 775 loss : 0.6923364400863647 weight Parameter containing:\n",
            "tensor([[-0.3805,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 776 loss : 0.692335307598114 weight Parameter containing:\n",
            "tensor([[-0.3804,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 777 loss : 0.6923342347145081 weight Parameter containing:\n",
            "tensor([[-0.3804,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 778 loss : 0.6923331022262573 weight Parameter containing:\n",
            "tensor([[-0.3803,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 779 loss : 0.6923320889472961 weight Parameter containing:\n",
            "tensor([[-0.3803,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 780 loss : 0.6923308968544006 weight Parameter containing:\n",
            "tensor([[-0.3802,  0.1500,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 781 loss : 0.6923298239707947 weight Parameter containing:\n",
            "tensor([[-0.3801,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 782 loss : 0.692328691482544 weight Parameter containing:\n",
            "tensor([[-0.3801,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 783 loss : 0.6923276782035828 weight Parameter containing:\n",
            "tensor([[-0.3800,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 784 loss : 0.692326545715332 weight Parameter containing:\n",
            "tensor([[-0.3800,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 785 loss : 0.6923254132270813 weight Parameter containing:\n",
            "tensor([[-0.3799,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 786 loss : 0.6923244595527649 weight Parameter containing:\n",
            "tensor([[-0.3798,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 787 loss : 0.6923232674598694 weight Parameter containing:\n",
            "tensor([[-0.3798,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 788 loss : 0.692322313785553 weight Parameter containing:\n",
            "tensor([[-0.3797,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 789 loss : 0.692321240901947 weight Parameter containing:\n",
            "tensor([[-0.3797,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 790 loss : 0.6923201084136963 weight Parameter containing:\n",
            "tensor([[-0.3796,  0.1501,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 791 loss : 0.6923190951347351 weight Parameter containing:\n",
            "tensor([[-0.3795,  0.1502,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 792 loss : 0.6923180818557739 weight Parameter containing:\n",
            "tensor([[-0.3795,  0.1502,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 793 loss : 0.692317008972168 weight Parameter containing:\n",
            "tensor([[-0.3794,  0.1502,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 794 loss : 0.6923159956932068 weight Parameter containing:\n",
            "tensor([[-0.3793,  0.1502,  0.3993, -0.0790]], requires_grad=True)\n",
            "epoch : 795 loss : 0.6923149228096008 weight Parameter containing:\n",
            "tensor([[-0.3793,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 796 loss : 0.6923138499259949 weight Parameter containing:\n",
            "tensor([[-0.3792,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 797 loss : 0.6923128962516785 weight Parameter containing:\n",
            "tensor([[-0.3792,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 798 loss : 0.6923118829727173 weight Parameter containing:\n",
            "tensor([[-0.3791,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 799 loss : 0.6923109292984009 weight Parameter containing:\n",
            "tensor([[-0.3791,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 800 loss : 0.6923097968101501 weight Parameter containing:\n",
            "tensor([[-0.3790,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 801 loss : 0.6923088431358337 weight Parameter containing:\n",
            "tensor([[-0.3789,  0.1502,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 802 loss : 0.6923077702522278 weight Parameter containing:\n",
            "tensor([[-0.3789,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 803 loss : 0.6923068761825562 weight Parameter containing:\n",
            "tensor([[-0.3788,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 804 loss : 0.6923057436943054 weight Parameter containing:\n",
            "tensor([[-0.3788,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 805 loss : 0.692304790019989 weight Parameter containing:\n",
            "tensor([[-0.3787,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 806 loss : 0.6923038363456726 weight Parameter containing:\n",
            "tensor([[-0.3786,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 807 loss : 0.6923028230667114 weight Parameter containing:\n",
            "tensor([[-0.3786,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 808 loss : 0.692301869392395 weight Parameter containing:\n",
            "tensor([[-0.3785,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 809 loss : 0.6923009753227234 weight Parameter containing:\n",
            "tensor([[-0.3785,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 810 loss : 0.6922999024391174 weight Parameter containing:\n",
            "tensor([[-0.3784,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 811 loss : 0.692298948764801 weight Parameter containing:\n",
            "tensor([[-0.3783,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 812 loss : 0.6922980546951294 weight Parameter containing:\n",
            "tensor([[-0.3783,  0.1503,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 813 loss : 0.6922970414161682 weight Parameter containing:\n",
            "tensor([[-0.3782,  0.1504,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 814 loss : 0.6922960877418518 weight Parameter containing:\n",
            "tensor([[-0.3782,  0.1504,  0.3993, -0.0789]], requires_grad=True)\n",
            "epoch : 815 loss : 0.6922951340675354 weight Parameter containing:\n",
            "tensor([[-0.3781,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 816 loss : 0.6922941207885742 weight Parameter containing:\n",
            "tensor([[-0.3780,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 817 loss : 0.6922933459281921 weight Parameter containing:\n",
            "tensor([[-0.3780,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 818 loss : 0.6922922730445862 weight Parameter containing:\n",
            "tensor([[-0.3779,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 819 loss : 0.6922913789749146 weight Parameter containing:\n",
            "tensor([[-0.3779,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 820 loss : 0.6922904253005981 weight Parameter containing:\n",
            "tensor([[-0.3778,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 821 loss : 0.6922894716262817 weight Parameter containing:\n",
            "tensor([[-0.3777,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 822 loss : 0.6922885179519653 weight Parameter containing:\n",
            "tensor([[-0.3777,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 823 loss : 0.6922876238822937 weight Parameter containing:\n",
            "tensor([[-0.3776,  0.1504,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 824 loss : 0.6922867298126221 weight Parameter containing:\n",
            "tensor([[-0.3776,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 825 loss : 0.6922858357429504 weight Parameter containing:\n",
            "tensor([[-0.3775,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 826 loss : 0.692284882068634 weight Parameter containing:\n",
            "tensor([[-0.3775,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 827 loss : 0.6922840476036072 weight Parameter containing:\n",
            "tensor([[-0.3774,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 828 loss : 0.6922830939292908 weight Parameter containing:\n",
            "tensor([[-0.3773,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 829 loss : 0.6922821998596191 weight Parameter containing:\n",
            "tensor([[-0.3773,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 830 loss : 0.6922813057899475 weight Parameter containing:\n",
            "tensor([[-0.3772,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 831 loss : 0.6922804117202759 weight Parameter containing:\n",
            "tensor([[-0.3772,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 832 loss : 0.692279577255249 weight Parameter containing:\n",
            "tensor([[-0.3771,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 833 loss : 0.6922786235809326 weight Parameter containing:\n",
            "tensor([[-0.3770,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 834 loss : 0.692277729511261 weight Parameter containing:\n",
            "tensor([[-0.3770,  0.1505,  0.3993, -0.0788]], requires_grad=True)\n",
            "epoch : 835 loss : 0.6922768354415894 weight Parameter containing:\n",
            "tensor([[-0.3769,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 836 loss : 0.6922760009765625 weight Parameter containing:\n",
            "tensor([[-0.3769,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 837 loss : 0.6922750473022461 weight Parameter containing:\n",
            "tensor([[-0.3768,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 838 loss : 0.6922742128372192 weight Parameter containing:\n",
            "tensor([[-0.3768,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 839 loss : 0.6922733783721924 weight Parameter containing:\n",
            "tensor([[-0.3767,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 840 loss : 0.6922725439071655 weight Parameter containing:\n",
            "tensor([[-0.3766,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 841 loss : 0.6922716498374939 weight Parameter containing:\n",
            "tensor([[-0.3766,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 842 loss : 0.6922708749771118 weight Parameter containing:\n",
            "tensor([[-0.3765,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 843 loss : 0.6922699809074402 weight Parameter containing:\n",
            "tensor([[-0.3765,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 844 loss : 0.6922691464424133 weight Parameter containing:\n",
            "tensor([[-0.3764,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 845 loss : 0.6922682523727417 weight Parameter containing:\n",
            "tensor([[-0.3763,  0.1506,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 846 loss : 0.6922673583030701 weight Parameter containing:\n",
            "tensor([[-0.3763,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 847 loss : 0.692266583442688 weight Parameter containing:\n",
            "tensor([[-0.3762,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 848 loss : 0.6922657489776611 weight Parameter containing:\n",
            "tensor([[-0.3762,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 849 loss : 0.6922649145126343 weight Parameter containing:\n",
            "tensor([[-0.3761,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 850 loss : 0.6922641396522522 weight Parameter containing:\n",
            "tensor([[-0.3761,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 851 loss : 0.6922632455825806 weight Parameter containing:\n",
            "tensor([[-0.3760,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 852 loss : 0.6922624111175537 weight Parameter containing:\n",
            "tensor([[-0.3759,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 853 loss : 0.6922616362571716 weight Parameter containing:\n",
            "tensor([[-0.3759,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 854 loss : 0.6922608017921448 weight Parameter containing:\n",
            "tensor([[-0.3758,  0.1507,  0.3993, -0.0787]], requires_grad=True)\n",
            "epoch : 855 loss : 0.6922599673271179 weight Parameter containing:\n",
            "tensor([[-0.3758,  0.1507,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 856 loss : 0.6922592520713806 weight Parameter containing:\n",
            "tensor([[-0.3757,  0.1507,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 857 loss : 0.6922584176063538 weight Parameter containing:\n",
            "tensor([[-0.3757,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 858 loss : 0.6922575831413269 weight Parameter containing:\n",
            "tensor([[-0.3756,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 859 loss : 0.6922567486763 weight Parameter containing:\n",
            "tensor([[-0.3755,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 860 loss : 0.6922559142112732 weight Parameter containing:\n",
            "tensor([[-0.3755,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 861 loss : 0.6922550797462463 weight Parameter containing:\n",
            "tensor([[-0.3754,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 862 loss : 0.6922544240951538 weight Parameter containing:\n",
            "tensor([[-0.3754,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 863 loss : 0.692253589630127 weight Parameter containing:\n",
            "tensor([[-0.3753,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 864 loss : 0.6922528147697449 weight Parameter containing:\n",
            "tensor([[-0.3753,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 865 loss : 0.6922519207000732 weight Parameter containing:\n",
            "tensor([[-0.3752,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 866 loss : 0.6922512054443359 weight Parameter containing:\n",
            "tensor([[-0.3751,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 867 loss : 0.6922504305839539 weight Parameter containing:\n",
            "tensor([[-0.3751,  0.1508,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 868 loss : 0.6922496557235718 weight Parameter containing:\n",
            "tensor([[-0.3750,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 869 loss : 0.6922490000724792 weight Parameter containing:\n",
            "tensor([[-0.3750,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 870 loss : 0.6922481060028076 weight Parameter containing:\n",
            "tensor([[-0.3749,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 871 loss : 0.6922473311424255 weight Parameter containing:\n",
            "tensor([[-0.3749,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 872 loss : 0.692246675491333 weight Parameter containing:\n",
            "tensor([[-0.3748,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 873 loss : 0.6922459006309509 weight Parameter containing:\n",
            "tensor([[-0.3747,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 874 loss : 0.6922450661659241 weight Parameter containing:\n",
            "tensor([[-0.3747,  0.1509,  0.3993, -0.0786]], requires_grad=True)\n",
            "epoch : 875 loss : 0.6922444105148315 weight Parameter containing:\n",
            "tensor([[-0.3746,  0.1509,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 876 loss : 0.6922436356544495 weight Parameter containing:\n",
            "tensor([[-0.3746,  0.1509,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 877 loss : 0.6922429203987122 weight Parameter containing:\n",
            "tensor([[-0.3745,  0.1509,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 878 loss : 0.6922420859336853 weight Parameter containing:\n",
            "tensor([[-0.3745,  0.1509,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 879 loss : 0.692241370677948 weight Parameter containing:\n",
            "tensor([[-0.3744,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 880 loss : 0.6922406554222107 weight Parameter containing:\n",
            "tensor([[-0.3743,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 881 loss : 0.6922399401664734 weight Parameter containing:\n",
            "tensor([[-0.3743,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 882 loss : 0.6922392249107361 weight Parameter containing:\n",
            "tensor([[-0.3742,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 883 loss : 0.692238450050354 weight Parameter containing:\n",
            "tensor([[-0.3742,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 884 loss : 0.6922377347946167 weight Parameter containing:\n",
            "tensor([[-0.3741,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 885 loss : 0.6922370195388794 weight Parameter containing:\n",
            "tensor([[-0.3741,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 886 loss : 0.6922362446784973 weight Parameter containing:\n",
            "tensor([[-0.3740,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 887 loss : 0.6922355890274048 weight Parameter containing:\n",
            "tensor([[-0.3739,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 888 loss : 0.6922348737716675 weight Parameter containing:\n",
            "tensor([[-0.3739,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 889 loss : 0.6922340989112854 weight Parameter containing:\n",
            "tensor([[-0.3738,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 890 loss : 0.6922334432601929 weight Parameter containing:\n",
            "tensor([[-0.3738,  0.1510,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 891 loss : 0.6922327280044556 weight Parameter containing:\n",
            "tensor([[-0.3737,  0.1511,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 892 loss : 0.6922319531440735 weight Parameter containing:\n",
            "tensor([[-0.3737,  0.1511,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 893 loss : 0.692231297492981 weight Parameter containing:\n",
            "tensor([[-0.3736,  0.1511,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 894 loss : 0.6922305822372437 weight Parameter containing:\n",
            "tensor([[-0.3736,  0.1511,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 895 loss : 0.6922299265861511 weight Parameter containing:\n",
            "tensor([[-0.3735,  0.1511,  0.3993, -0.0785]], requires_grad=True)\n",
            "epoch : 896 loss : 0.6922292113304138 weight Parameter containing:\n",
            "tensor([[-0.3734,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 897 loss : 0.6922284960746765 weight Parameter containing:\n",
            "tensor([[-0.3734,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 898 loss : 0.692227840423584 weight Parameter containing:\n",
            "tensor([[-0.3733,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 899 loss : 0.6922271847724915 weight Parameter containing:\n",
            "tensor([[-0.3733,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 900 loss : 0.6922264695167542 weight Parameter containing:\n",
            "tensor([[-0.3732,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 901 loss : 0.6922258138656616 weight Parameter containing:\n",
            "tensor([[-0.3732,  0.1511,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 902 loss : 0.6922250986099243 weight Parameter containing:\n",
            "tensor([[-0.3731,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 903 loss : 0.6922244429588318 weight Parameter containing:\n",
            "tensor([[-0.3731,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 904 loss : 0.6922236680984497 weight Parameter containing:\n",
            "tensor([[-0.3730,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 905 loss : 0.6922230124473572 weight Parameter containing:\n",
            "tensor([[-0.3729,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 906 loss : 0.6922224760055542 weight Parameter containing:\n",
            "tensor([[-0.3729,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 907 loss : 0.6922216415405273 weight Parameter containing:\n",
            "tensor([[-0.3728,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 908 loss : 0.6922209858894348 weight Parameter containing:\n",
            "tensor([[-0.3728,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 909 loss : 0.6922203898429871 weight Parameter containing:\n",
            "tensor([[-0.3727,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 910 loss : 0.6922197341918945 weight Parameter containing:\n",
            "tensor([[-0.3727,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 911 loss : 0.692219078540802 weight Parameter containing:\n",
            "tensor([[-0.3726,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 912 loss : 0.6922184824943542 weight Parameter containing:\n",
            "tensor([[-0.3725,  0.1512,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 913 loss : 0.6922177672386169 weight Parameter containing:\n",
            "tensor([[-0.3725,  0.1513,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 914 loss : 0.6922171711921692 weight Parameter containing:\n",
            "tensor([[-0.3724,  0.1513,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 915 loss : 0.6922164559364319 weight Parameter containing:\n",
            "tensor([[-0.3724,  0.1513,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 916 loss : 0.6922158002853394 weight Parameter containing:\n",
            "tensor([[-0.3723,  0.1513,  0.3993, -0.0784]], requires_grad=True)\n",
            "epoch : 917 loss : 0.692215085029602 weight Parameter containing:\n",
            "tensor([[-0.3723,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 918 loss : 0.6922145485877991 weight Parameter containing:\n",
            "tensor([[-0.3722,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 919 loss : 0.6922139525413513 weight Parameter containing:\n",
            "tensor([[-0.3722,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 920 loss : 0.692213237285614 weight Parameter containing:\n",
            "tensor([[-0.3721,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 921 loss : 0.6922126412391663 weight Parameter containing:\n",
            "tensor([[-0.3721,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 922 loss : 0.692211925983429 weight Parameter containing:\n",
            "tensor([[-0.3720,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 923 loss : 0.6922113299369812 weight Parameter containing:\n",
            "tensor([[-0.3719,  0.1513,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 924 loss : 0.6922107338905334 weight Parameter containing:\n",
            "tensor([[-0.3719,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 925 loss : 0.6922101378440857 weight Parameter containing:\n",
            "tensor([[-0.3718,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 926 loss : 0.6922095417976379 weight Parameter containing:\n",
            "tensor([[-0.3718,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 927 loss : 0.6922088265419006 weight Parameter containing:\n",
            "tensor([[-0.3717,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 928 loss : 0.6922082304954529 weight Parameter containing:\n",
            "tensor([[-0.3717,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 929 loss : 0.6922076344490051 weight Parameter containing:\n",
            "tensor([[-0.3716,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 930 loss : 0.6922070384025574 weight Parameter containing:\n",
            "tensor([[-0.3716,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 931 loss : 0.6922064423561096 weight Parameter containing:\n",
            "tensor([[-0.3715,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 932 loss : 0.6922058463096619 weight Parameter containing:\n",
            "tensor([[-0.3714,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 933 loss : 0.6922051906585693 weight Parameter containing:\n",
            "tensor([[-0.3714,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 934 loss : 0.6922045350074768 weight Parameter containing:\n",
            "tensor([[-0.3713,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 935 loss : 0.692203938961029 weight Parameter containing:\n",
            "tensor([[-0.3713,  0.1514,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 936 loss : 0.6922032833099365 weight Parameter containing:\n",
            "tensor([[-0.3712,  0.1515,  0.3993, -0.0783]], requires_grad=True)\n",
            "epoch : 937 loss : 0.6922027468681335 weight Parameter containing:\n",
            "tensor([[-0.3712,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 938 loss : 0.692202091217041 weight Parameter containing:\n",
            "tensor([[-0.3711,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 939 loss : 0.692201554775238 weight Parameter containing:\n",
            "tensor([[-0.3711,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 940 loss : 0.6922010183334351 weight Parameter containing:\n",
            "tensor([[-0.3710,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 941 loss : 0.6922004222869873 weight Parameter containing:\n",
            "tensor([[-0.3710,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 942 loss : 0.6921997666358948 weight Parameter containing:\n",
            "tensor([[-0.3709,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 943 loss : 0.6921992301940918 weight Parameter containing:\n",
            "tensor([[-0.3708,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 944 loss : 0.6921986937522888 weight Parameter containing:\n",
            "tensor([[-0.3708,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 945 loss : 0.6921980381011963 weight Parameter containing:\n",
            "tensor([[-0.3707,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 946 loss : 0.6921974420547485 weight Parameter containing:\n",
            "tensor([[-0.3707,  0.1515,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 947 loss : 0.6921968460083008 weight Parameter containing:\n",
            "tensor([[-0.3706,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 948 loss : 0.692196249961853 weight Parameter containing:\n",
            "tensor([[-0.3706,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 949 loss : 0.69219571352005 weight Parameter containing:\n",
            "tensor([[-0.3705,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 950 loss : 0.6921951174736023 weight Parameter containing:\n",
            "tensor([[-0.3705,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 951 loss : 0.6921945810317993 weight Parameter containing:\n",
            "tensor([[-0.3704,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 952 loss : 0.6921939849853516 weight Parameter containing:\n",
            "tensor([[-0.3704,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 953 loss : 0.6921934485435486 weight Parameter containing:\n",
            "tensor([[-0.3703,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 954 loss : 0.6921929121017456 weight Parameter containing:\n",
            "tensor([[-0.3702,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 955 loss : 0.6921922564506531 weight Parameter containing:\n",
            "tensor([[-0.3702,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 956 loss : 0.6921917200088501 weight Parameter containing:\n",
            "tensor([[-0.3701,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 957 loss : 0.6921912431716919 weight Parameter containing:\n",
            "tensor([[-0.3701,  0.1516,  0.3993, -0.0782]], requires_grad=True)\n",
            "epoch : 958 loss : 0.6921905875205994 weight Parameter containing:\n",
            "tensor([[-0.3700,  0.1516,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 959 loss : 0.6921901702880859 weight Parameter containing:\n",
            "tensor([[-0.3700,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 960 loss : 0.6921893954277039 weight Parameter containing:\n",
            "tensor([[-0.3699,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 961 loss : 0.6921889185905457 weight Parameter containing:\n",
            "tensor([[-0.3699,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 962 loss : 0.6921883821487427 weight Parameter containing:\n",
            "tensor([[-0.3698,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 963 loss : 0.6921878457069397 weight Parameter containing:\n",
            "tensor([[-0.3698,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 964 loss : 0.6921872496604919 weight Parameter containing:\n",
            "tensor([[-0.3697,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 965 loss : 0.6921867728233337 weight Parameter containing:\n",
            "tensor([[-0.3697,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 966 loss : 0.6921862363815308 weight Parameter containing:\n",
            "tensor([[-0.3696,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 967 loss : 0.6921856999397278 weight Parameter containing:\n",
            "tensor([[-0.3695,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 968 loss : 0.6921850442886353 weight Parameter containing:\n",
            "tensor([[-0.3695,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 969 loss : 0.692184567451477 weight Parameter containing:\n",
            "tensor([[-0.3694,  0.1517,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 970 loss : 0.6921839714050293 weight Parameter containing:\n",
            "tensor([[-0.3694,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 971 loss : 0.6921835541725159 weight Parameter containing:\n",
            "tensor([[-0.3693,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 972 loss : 0.6921829581260681 weight Parameter containing:\n",
            "tensor([[-0.3693,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 973 loss : 0.6921823620796204 weight Parameter containing:\n",
            "tensor([[-0.3692,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 974 loss : 0.6921819448471069 weight Parameter containing:\n",
            "tensor([[-0.3692,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 975 loss : 0.692181408405304 weight Parameter containing:\n",
            "tensor([[-0.3691,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 976 loss : 0.692180871963501 weight Parameter containing:\n",
            "tensor([[-0.3691,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 977 loss : 0.6921802759170532 weight Parameter containing:\n",
            "tensor([[-0.3690,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 978 loss : 0.692179799079895 weight Parameter containing:\n",
            "tensor([[-0.3690,  0.1518,  0.3993, -0.0781]], requires_grad=True)\n",
            "epoch : 979 loss : 0.6921793222427368 weight Parameter containing:\n",
            "tensor([[-0.3689,  0.1518,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 980 loss : 0.6921787858009338 weight Parameter containing:\n",
            "tensor([[-0.3689,  0.1518,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 981 loss : 0.6921781897544861 weight Parameter containing:\n",
            "tensor([[-0.3688,  0.1518,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 982 loss : 0.6921777129173279 weight Parameter containing:\n",
            "tensor([[-0.3687,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 983 loss : 0.6921772360801697 weight Parameter containing:\n",
            "tensor([[-0.3687,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 984 loss : 0.6921766996383667 weight Parameter containing:\n",
            "tensor([[-0.3686,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 985 loss : 0.692176103591919 weight Parameter containing:\n",
            "tensor([[-0.3686,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 986 loss : 0.6921757459640503 weight Parameter containing:\n",
            "tensor([[-0.3685,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 987 loss : 0.6921751499176025 weight Parameter containing:\n",
            "tensor([[-0.3685,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 988 loss : 0.6921746134757996 weight Parameter containing:\n",
            "tensor([[-0.3684,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 989 loss : 0.6921741366386414 weight Parameter containing:\n",
            "tensor([[-0.3684,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 990 loss : 0.6921736598014832 weight Parameter containing:\n",
            "tensor([[-0.3683,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 991 loss : 0.692173182964325 weight Parameter containing:\n",
            "tensor([[-0.3683,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 992 loss : 0.692172646522522 weight Parameter containing:\n",
            "tensor([[-0.3682,  0.1519,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 993 loss : 0.6921721696853638 weight Parameter containing:\n",
            "tensor([[-0.3682,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 994 loss : 0.6921716928482056 weight Parameter containing:\n",
            "tensor([[-0.3681,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 995 loss : 0.6921710968017578 weight Parameter containing:\n",
            "tensor([[-0.3681,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 996 loss : 0.6921706199645996 weight Parameter containing:\n",
            "tensor([[-0.3680,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 997 loss : 0.6921701431274414 weight Parameter containing:\n",
            "tensor([[-0.3679,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 998 loss : 0.6921696662902832 weight Parameter containing:\n",
            "tensor([[-0.3679,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 999 loss : 0.692169189453125 weight Parameter containing:\n",
            "tensor([[-0.3678,  0.1520,  0.3993, -0.0780]], requires_grad=True)\n",
            "epoch : 1000 loss : 0.6921687126159668 weight Parameter containing:\n",
            "tensor([[-0.3678,  0.1520,  0.3993, -0.0779]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quHha0uBZVIY"
      },
      "source": [
        ""
      ],
      "execution_count": 99,
      "outputs": []
    }
  ]
}